{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21f2073a-9cd9-4948-b75d-6f5e92b038ce",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1233f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "188fe140-c5a1-415e-910c-fa294de68935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from incontext import *\n",
    "\n",
    "import os\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fba2af19-a0bb-4e15-b392-94824b7ffee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_sample = {\n",
    "    'repo': 'adaptive-code-completion',\n",
    "    'completion_file': {\n",
    "        'filename': None,\n",
    "        'content': None,\n",
    "    },\n",
    "    'repo_snapshot': {\n",
    "        'filename': [],\n",
    "        'content': [],\n",
    "    },\n",
    "}\n",
    "\n",
    "path_to_configs = '../configs'\n",
    "path_to_evaluation = '../evaluation'\n",
    "path_to_incontext = '../incontext'\n",
    "path_to_pipeline = '../pipeline'\n",
    "\n",
    "path_to_completion_file = '../incontext/__init__.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b449dcba-b869-4ec1-ad25-53275d3c60dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory, _, filenames in chain(*map(os.walk, (path_to_configs, path_to_evaluation, path_to_incontext, path_to_pipeline))):\n",
    "    if '__pycache__' in directory:\n",
    "        continue\n",
    "    \n",
    "    for filename in filenames:\n",
    "        if filename == 'adaptive_code_completion.py':\n",
    "            continue\n",
    "\n",
    "        filename = os.path.join(directory, filename)\n",
    "\n",
    "        with open(filename) as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        if filename == path_to_completion_file:\n",
    "            toy_sample['completion_file']['filename'] = filename\n",
    "            toy_sample['completion_file']['content'] = content\n",
    "        else:\n",
    "            toy_sample['repo_snapshot']['filename'].append(filename)\n",
    "            toy_sample['repo_snapshot']['content'].append(content)\n",
    "\n",
    "assert toy_sample['completion_file']['filename'] is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a5f1055-a5ac-469a-8051-3e4a6cf97fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "composer_kwargs = dict(\n",
    "    pre_context_prompt='<repo_name>{}\\n<file_sep>',\n",
    "    post_context_prompt='<file_sep>',\n",
    "    path_comment_template='# {filename}\\n{content}',  # to format completion file\n",
    ")\n",
    "ocoder_assembler = PathCommentAssembler(chunks_sep='<file_sep>', path_comment_template='# {filename}\\n{content}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c52a8d",
   "metadata": {},
   "source": [
    "### File-Level Composer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fc11978",
   "metadata": {},
   "outputs": [],
   "source": [
    "composer = ChainedComposer([\n",
    "    NullFileFilter(),\n",
    "    FileGrainedChunker(),\n",
    "    ocoder_assembler,\n",
    "],\n",
    "    **composer_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67c7051d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ChainedComposer([NullFileFilter(), FileGrainedChunker(), PathCommentAssembler(chunks_sep='<file_sep>', path_comment_template='# {filename}\\n{content}')], pre_context_prompt='<repo_name>{}\\n<file_sep>', post_context_prompt='<file_sep>', path_comment_template='# {filename}\\n{content}')\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can access the composer initialization code by using its __repr__\n",
    "repr(composer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ab5ea59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pre_context_prompt', 'composed_context', 'composed_completion'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composed_sample = composer.compose(toy_sample)\n",
    "composed_sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1ec96fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<repo_name>adaptive-code-completion\\n<file_sep>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repo identifier\n",
    "composed_sample['pre_context_prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5397eac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ../incontext/__init__.py\n",
      "# abstract base classes\n",
      "from incontext.blocks.block import ComposerBlock\n",
      "from incontext.composer.composer_base import ComposerBase\n",
      "\n",
      "# abstract block types\n",
      "from incontext.blocks.file_filtering import FileFilter\n",
      "from incontext.blocks.file_preprocessing import FilePreprocessor\n",
      "from incontext.blocks.file_chunking import FileChunker\n",
      "from incontext.blocks.chunk_ranking import ChunkRanker\n",
      "from incontext.blocks.chunk_sorting import ChunkSorter\n",
      "from incontext.blocks.chunk_assembling import ChunkAssembler\n",
      "from incontext.blocks.context_postprocessing import ContextPostprocessor\n",
      "\n",
      "# blocks\n",
      "from incontext.blocks.file_filtering import (\n",
      "    NullFileFilter,\n",
      "    InclusiveFileExtensionFilter,\n",
      "    ExclusiveFileExtensionFilter,\n",
      "    EmptyFileFilter,\n",
      "    FileLengthFilter,\n",
      ")\n",
      "from incontext.blocks.file_preprocessing import (\n",
      "    EmptyLinesRemovalPreprocessor,\n",
      "    NewlinePreprocessor,\n",
      "    DeclarationOnlyPreprocessor,\n",
      ")\n",
      "from incontext.blocks.file_chunking import (\n",
      "    FileGrainedChunker,\n",
      "    CodeSegmentGrainedChunker,\n",
      "    DocstringAndCommentOnlyChunker,\n",
      "    CodeOnlyChunker,\n",
      "    FixedLineChunker,\n",
      "    CompletionDuplicationChunker,\n",
      ")\n",
      "from incontext.blocks.chunk_ranking import (\n",
      "    NegativePathDistanceRanker,\n",
      "    FileExtensionRanker,\n",
      "    FunctionCallRanker,\n",
      "    RandomRanker,\n",
      "    IoURanker,\n",
      ")\n",
      "from incontext.blocks.chunk_sorting import (\n",
      "    LexicographicSorter,\n",
      "    ReverseLexicographicSorter,\n",
      "    MixedSorter,\n",
      ")\n",
      "from incontext.blocks.chunk_assembling import (\n",
      "    JoiningAssembler,\n",
      "    PathCommentAssembler,\n",
      ")\n",
      "from incontext.blocks.context_postprocessing import (\n",
      "    PartialMemoryPostprocessor,\n",
      "    LineLengthPostprocessor,\n",
      "    LineStripPostprocessor,\n",
      "    CompletionLeakPostprocessor,\n",
      "    DseekCompletionLeakPostprocessor,\n",
      "    OCoderCompletionLeakPostprocessor,\n",
      "    ReversedContextPostprocessor,\n",
      "    OCoderReversedContextPostprocessor,\n",
      "    RandomTokensPostprocessor,\n",
      "    DseekRandomTokensPostprocessor,\n",
      "    OCoderRandomTokensPostprocessor,\n",
      ")\n",
      "\n",
      "# composers\n",
      "from incontext.composer.chained_composer import ChainedComposer\n",
      "\n",
      "from incontext.init_from_config import init_from_config\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# default way to compose a completion part\n",
    "print(composed_sample['composed_completion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "870be64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<file_sep>\n"
     ]
    }
   ],
   "source": [
    "# empty context\n",
    "print(composed_sample['composed_context'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046c7a08-6377-49b3-a7d3-67d3ba787f39",
   "metadata": {},
   "source": [
    "### Path Distance `.py` Composer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18feca98-7725-4c2f-bb84-509c3344fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "composer = ChainedComposer([\n",
    "    EmptyFileFilter(),\n",
    "    InclusiveFileExtensionFilter(whitelist=['.py']),\n",
    "    NewlinePreprocessor(),\n",
    "    FileGrainedChunker(),\n",
    "    NegativePathDistanceRanker(),\n",
    "    IoURanker(min_len=5),\n",
    "    LexicographicSorter(),\n",
    "    ocoder_assembler,\n",
    "],\n",
    "    **composer_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea18b545-b4fb-4abe-b316-1108794a3fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ../pipeline/trainers/utils/schedulers.py\n",
      "import math\n",
      "\n",
      "\n",
      "def get_lr_from_cosine_scheduler_with_linear_warmup(iter_num: int,\n",
      "                                                    min_lr: float,\n",
      "                                                    max_lr: float,\n",
      "                                                    warmup_iters: int,\n",
      "                                                    lr_decay_iters: int,\n",
      "                                                    ) -> float:\n",
      "    if iter_num < warmup_iters:  # warmup\n",
      "        return max_lr * (iter_num + 1) / warmup_iters\n",
      "    elif iter_num > lr_decay_iters:  # constant lr\n",
      "        return min_lr\n",
      "    else:  # cosine wave\n",
      "        decay_ratio = (iter_num - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
      "        return min_lr + (max_lr - min_lr) / 2 * (1 + math.cos(math.pi * decay_ratio))\n",
      "<file_sep># ../pipeline/trainers/utils/fused_sampler.py\n",
      "import math\n",
      "from typing import Iterator\n",
      "\n",
      "import torch\n",
      "from torch.utils.data import Sampler\n",
      "\n",
      "\n",
      "class FusedSampler(Sampler[int]):\n",
      "    def __init__(self,\n",
      "                 start_sample_idx: int,\n",
      "                 end_sample_idx: int,\n",
      "                 dataset_length: int,\n",
      "                 generator: torch.Generator | None = None,\n",
      "                 ) -> None:\n",
      "        super().__init__()\n",
      "\n",
      "        self.start_sample_idx = start_sample_idx\n",
      "        self.end_sample_idx = end_sample_idx\n",
      "        self.dataset_length = dataset_length\n",
      "        self.max_epochs = math.ceil(end_sample_idx / dataset_length)\n",
      "        self.generator = generator\n",
      "\n",
      "    def __iter__(self) -> Iterator[int]:\n",
      "        fused_weights = torch.rand(self.max_epochs, self.dataset_length, generator=self.generator)\n",
      "        fused_indices = torch.argsort(fused_weights, dim=-1).flatten().tolist()\n",
      "        yield from fused_indices[self.start_sample_idx:self.end_sample_idx]\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        return self.end_sample_idx - self.start_sample_idx\n",
      "<file_sep># ../pipeline/model/adapters/adapter_base.py\n",
      "import re\n",
      "from abc import ABC, abstractmethod\n",
      "from typing import Any, Iterable\n",
      "\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "from transformers.models.auto import MODEL_FOR_CAUSAL_LM_MAPPING\n",
      "from transformers import AutoConfig, LlamaForCausalLM\n",
      "\n",
      "\n",
      "class AdapterBase(ABC):\n",
      "    def __init__(self, model_name: str, params_pattern: str | None) -> None:\n",
      "        self.model_name = model_name\n",
      "        self.params_pattern = params_pattern\n",
      "\n",
      "        hf_model_config = AutoConfig.from_pretrained(model_name)\n",
      "        model_class = MODEL_FOR_CAUSAL_LM_MAPPING[type(hf_model_config)]\n",
      "\n",
      "        assert type(self).__name__ == 'IdentityAdapter' or model_class == LlamaForCausalLM, (\n",
      "            'Different architectures may require individual adaptations.')\n",
      "\n",
      "    def get_trainable_parameters(self, model: nn.Module) -> Iterable[torch.Tensor]:\n",
      "        return [\n",
      "            params for name, params in model.named_parameters()\n",
      "            if re.search(self.params_pattern, name)\n",
      "        ] if self.params_pattern is not None else model.parameters()\n",
      "\n",
      "    def init_optimizer(self, model: nn.Module, **optim_kwargs) -> torch.optim.AdamW:\n",
      "        weight_decay = optim_kwargs.pop('weight_decay', 0)\n",
      "\n",
      "        decay_params = list()\n",
      "        no_decay_params = list()\n",
      "\n",
      "        for params in self.get_trainable_parameters(model):\n",
      "            if params.dim() >= 2:\n",
      "                decay_params.append(params)\n",
      "            else:\n",
      "                no_decay_params.append(params)\n",
      "\n",
      "        return torch.optim.AdamW(params=[\n",
      "            {'name': 'decay_params', 'params': decay_params, 'weight_decay': weight_decay},\n",
      "            {'name': 'no_decay_params', 'params': no_decay_params, 'weight_decay': 0},\n",
      "        ], **optim_kwargs)\n",
      "\n",
      "    @abstractmethod\n",
      "    def get_args_kwargs(self,\n",
      "                        input_ids: torch.Tensor,\n",
      "                        target_ids: torch.Tensor,\n",
      "                        loss_mask: torch.Tensor,\n",
      "                        completion_mask: torch.Tensor,\n",
      "                        input_attn_mask: torch.Tensor,\n",
      "                        target_attn_mask: torch.Tensor,\n",
      "                        ) -> tuple[tuple[Any], dict[str, Any]]:\n",
      "        raise NotImplementedError\n",
      "\n",
      "    @abstractmethod\n",
      "    def adapt(self, model: nn.Module) -> nn.Module:\n",
      "        raise NotImplementedError\n",
      "<file_sep># ../pipeline/model/adapters/identity_adapter.py\n",
      "from pipeline.model.adapters.adapter_base import AdapterBase\n",
      "\n",
      "from typing import Any\n",
      "\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "\n",
      "\n",
      "class IdentityAdapter(AdapterBase):\n",
      "    def get_args_kwargs(self,\n",
      "                        input_ids: torch.Tensor,\n",
      "                        _target_ids: torch.Tensor,\n",
      "                        _loss_mask: torch.Tensor,\n",
      "                        _completion_mask: torch.Tensor,\n",
      "                        input_attn_mask: torch.Tensor,\n",
      "                        _target_attn_mask: torch.Tensor,\n",
      "                        ) -> tuple[tuple[Any], dict[str, Any]]:\n",
      "        args = (input_ids,)\n",
      "        kwargs = dict(attention_mask=input_attn_mask)\n",
      "        return args, kwargs\n",
      "\n",
      "    def adapt(self, model: nn.Module) -> nn.Module:\n",
      "        return model\n",
      "<file_sep># ../pipeline/model/adapters/__init__.py\n",
      "from pipeline.model.adapters.identity_adapter import IdentityAdapter\n",
      "<file_sep># ../pipeline/outputs/loggers/local_logger.py\n",
      "from pipeline.outputs.loggers.logger_base import Message, Log, LoggerBase\n",
      "from pipeline.outputs.metrics.statistic_base import StatisticName, StatisticValue\n",
      "\n",
      "import csv\n",
      "import json\n",
      "import logging\n",
      "import os\n",
      "import sys\n",
      "import traceback\n",
      "import warnings\n",
      "from types import TracebackType\n",
      "from typing import NoReturn\n",
      "\n",
      "import datasets.utils.logging\n",
      "import transformers.utils.logging\n",
      "\n",
      "\n",
      "class JsonFormatter(logging.Formatter):\n",
      "    def format(self, record: logging.LogRecord) -> str:\n",
      "        message_dict = {\n",
      "            'timestamp': self.formatTime(record, self.datefmt),\n",
      "            'level': record.levelname,\n",
      "            'content': record.msg,\n",
      "        }\n",
      "\n",
      "        indent = '    '\n",
      "        json_string = json.dumps(message_dict, indent=4)\n",
      "        json_string = indent.join(json_string.splitlines(keepends=True))\n",
      "        json_string = indent + json_string\n",
      "\n",
      "        return json_string\n",
      "\n",
      "\n",
      "class JsonHandler(logging.FileHandler):\n",
      "    def emit(self, record: logging.LogRecord) -> None:\n",
      "        if not os.path.exists(self.baseFilename) or os.stat(self.baseFilename).st_size == 0:\n",
      "            self.stream.write('[\\n')\n",
      "        else:\n",
      "            self.stream.seek(self.stream.tell() - 1)\n",
      "            self.stream.truncate()\n",
      "            self.stream.write(',\\n')\n",
      "\n",
      "        super().emit(record)\n",
      "\n",
      "    def close(self) -> None:\n",
      "        self.stream.seek(self.stream.tell() - 1)\n",
      "        self.stream.write(']')\n",
      "\n",
      "        super().close()\n",
      "\n",
      "\n",
      "class LocalLogger(LoggerBase):\n",
      "    def __init__(self,\n",
      "                 train_csv: str,\n",
      "                 valid_csv: str,\n",
      "                 stdout_file: str,\n",
      "                 stderr_file: str,\n",
      "                 directory: str,\n",
      "                 **_kwargs,\n",
      "                 ) -> None:\n",
      "        if train_csv == valid_csv:\n",
      "            raise ValueError('The names of the train_csv and valid_csv files must be different.')\n",
      "\n",
      "        train_csv, valid_csv, stdout_file, stderr_file = map(\n",
      "            lambda x: os.path.join(directory, x),\n",
      "            [train_csv, valid_csv, stdout_file, stderr_file],\n",
      "        )\n",
      "\n",
      "        if os.path.exists(train_csv):\n",
      "            os.remove(train_csv)\n",
      "        if os.path.exists(valid_csv):\n",
      "            os.remove(valid_csv)\n",
      "\n",
      "        self.train_csv = train_csv\n",
      "        self.valid_csv = valid_csv\n",
      "\n",
      "        self.logger = logging.getLogger(__name__)\n",
      "        self.logger.propagate = False\n",
      "        self.logger.setLevel(logging.DEBUG)\n",
      "        formatter = JsonFormatter()\n",
      "\n",
      "        stdout_handler = JsonHandler(stdout_file)\n",
      "        stdout_handler.setLevel(logging.INFO)\n",
      "        stdout_handler.setFormatter(formatter)\n",
      "        stdout_handler.addFilter(lambda record: record.levelno < logging.WARNING)\n",
      "\n",
      "        if stderr_file == stdout_file:\n",
      "            stderr_handler = stdout_handler\n",
      "        else:\n",
      "            stderr_handler = JsonHandler(stderr_file)\n",
      "            stderr_handler.setLevel(logging.WARNING)\n",
      "            stderr_handler.setFormatter(formatter)\n",
      "            stderr_handler.addFilter(lambda record: record.levelno >= logging.WARNING)\n",
      "\n",
      "        # self.logger.handlers.clear()\n",
      "        self.logger.addHandler(stdout_handler)\n",
      "        self.logger.addHandler(stderr_handler)\n",
      "\n",
      "        warnings.showwarning = self.warning_handler\n",
      "        sys.excepthook = self.exception_handler\n",
      "\n",
      "        # redirect all HF logs (at least datasets and transformers)\n",
      "        datasets_logger = datasets.utils.logging.get_logger()\n",
      "        transformers_logger = transformers.utils.logging.get_logger()\n",
      "\n",
      "        datasets_logger.handlers = self.logger.handlers\n",
      "        transformers_logger.handlers = self.logger.handlers\n",
      "\n",
      "    @staticmethod\n",
      "    def write_metrics_to_csv(metrics: dict[StatisticName, StatisticValue], path: str) -> None:\n",
      "        with open(path, mode='a', newline='') as stream:\n",
      "            writer = csv.DictWriter(stream, fieldnames=metrics.keys())\n",
      "            if stream.tell() == 0:\n",
      "                writer.writeheader()\n",
      "            writer.writerow(metrics)\n",
      "\n",
      "    def log(self, metrics: Log) -> Log:\n",
      "        iter_num = {'iter_num': metrics['iteration_number']}\n",
      "\n",
      "        if 'train_metrics' in metrics:\n",
      "            self.write_metrics_to_csv(iter_num | metrics['train_metrics'], self.train_csv)\n",
      "        if 'valid_metrics' in metrics:\n",
      "            self.write_metrics_to_csv(iter_num | metrics['valid_metrics'], self.valid_csv)\n",
      "\n",
      "        return metrics\n",
      "\n",
      "    def message(self, message: Message) -> Message:\n",
      "        self.logger.info(message)\n",
      "        return message\n",
      "\n",
      "    def warning_handler(self, message: Warning, category: type, path: str, lineno: int, *_kwargs) -> None:\n",
      "        self.logger.warning({\n",
      "            'category': category.__name__,\n",
      "            'location': f'{path}:{lineno}',\n",
      "            'message': str(message),\n",
      "        })\n",
      "\n",
      "    def exception_handler(self, exc_type: type, exc_value: Exception, exc_traceback: TracebackType) -> NoReturn:\n",
      "        if issubclass(exc_type, KeyboardInterrupt):\n",
      "            self.message('Process was stopped due to a keyboard interrupt.')\n",
      "        else:\n",
      "            self.logger.error({\n",
      "                'category': exc_type.__name__,\n",
      "                'traceback': [{\n",
      "                    'location': f'{filename}:{lineno} in {func_name}',\n",
      "                    'line': line,\n",
      "                } for filename, lineno, func_name, line in traceback.extract_tb(exc_traceback)],\n",
      "                'message': str(exc_value),\n",
      "            })\n",
      "            self.message('Process finished with a non-zero exit code.')\n",
      "        sys.__excepthook__(exc_type, exc_value, exc_traceback)\n",
      "<file_sep># ../pipeline/outputs/loggers/logger_base.py\n",
      "from pipeline.outputs.metrics.statistic_base import StatisticName, StatisticValue\n",
      "\n",
      "from abc import ABC, abstractmethod\n",
      "from typing import NotRequired, TypedDict, TypeVar, Type\n",
      "\n",
      "T = TypeVar('T')\n",
      "JsonAllowedTypes = dict | list | tuple | str | int | float | bool | None\n",
      "Message = str | int | float | dict[str, JsonAllowedTypes]\n",
      "\n",
      "\n",
      "class Log(TypedDict):\n",
      "    iteration_number: int\n",
      "    train_metrics: NotRequired[dict[StatisticName, StatisticValue]]\n",
      "    valid_metrics: NotRequired[dict[StatisticName, StatisticValue]]\n",
      "\n",
      "\n",
      "class LoggerBase(ABC):\n",
      "    _instance = None  # singleton pattern\n",
      "\n",
      "    def __new__(cls: Type[T], *args, **kwargs) -> T:\n",
      "        if cls._instance is None:\n",
      "            cls._instance = super().__new__(cls)\n",
      "        return cls._instance\n",
      "\n",
      "    @abstractmethod\n",
      "    def log(self, metrics: Log) -> Log:\n",
      "        raise NotImplementedError\n",
      "\n",
      "    @abstractmethod\n",
      "    def message(self, message: Message) -> Message:\n",
      "        raise NotImplementedError\n",
      "<file_sep># ../pipeline/outputs/loggers/wandb_logger.py\n",
      "from pipeline.outputs.loggers.local_logger import LocalLogger\n",
      "from pipeline.outputs.loggers.logger_base import Log\n",
      "\n",
      "import wandb\n",
      "\n",
      "\n",
      "class WandbLogger(LocalLogger):\n",
      "    def __init__(self,\n",
      "                 train_csv: str,\n",
      "                 valid_csv: str,\n",
      "                 stdout_file: str,\n",
      "                 stderr_file: str,\n",
      "                 directory: str,\n",
      "                 **wandb_init_kwargs,\n",
      "                 ) -> None:\n",
      "        super().__init__(train_csv, valid_csv, stdout_file, stderr_file, directory)\n",
      "        wandb_init_kwargs['id'] = wandb_init_kwargs.get('id', wandb_init_kwargs['name'])\n",
      "        wandb.init(**wandb_init_kwargs)\n",
      "\n",
      "    def log(self, metrics: Log) -> Log:\n",
      "        # TODO: nesting: don't forget the additional validation loop case\n",
      "\n",
      "        wandb_log = dict()\n",
      "        if 'train_metrics' in metrics:\n",
      "            wandb_log['train'] = metrics['train_metrics']\n",
      "        if 'valid_metrics' in metrics:\n",
      "            wandb_log['validation'] = metrics['valid_metrics']\n",
      "\n",
      "        wandb.log(wandb_log, step=metrics['iteration_number'])\n",
      "        return super().log(metrics)\n",
      "<file_sep># ../pipeline/outputs/loggers/dummy_logger.py\n",
      "from pipeline.outputs.loggers.logger_base import Message, Log, LoggerBase\n",
      "\n",
      "\n",
      "class DummyLogger(LoggerBase):\n",
      "    def __init__(self, *_args, **_kwargs) -> None:\n",
      "        pass\n",
      "\n",
      "    def log(self, metrics: Log) -> Log:\n",
      "        return metrics\n",
      "\n",
      "    def message(self, message: Message) -> Message:\n",
      "        return message\n",
      "<file_sep># ../pipeline/outputs/loggers/__init__.py\n",
      "from pipeline.outputs.loggers.dummy_logger import DummyLogger\n",
      "from pipeline.outputs.loggers.local_logger import LocalLogger\n",
      "from pipeline.outputs.loggers.wandb_logger import WandbLogger\n",
      "<file_sep># ../pipeline/outputs/checkpointers/top_k_checkpointer.py\n",
      "from pipeline.outputs.checkpointers.checkpoint import Checkpoint\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "\n",
      "import os\n",
      "import shutil\n",
      "\n",
      "\n",
      "class TopKCheckpointManager(CheckpointManager):\n",
      "    def __init__(self, max_checkpoints_num: int, *args, **kwargs) -> None:\n",
      "        super().__init__(*args, **kwargs)\n",
      "        self.max_checkpoints_num = max_checkpoints_num\n",
      "\n",
      "    def save_checkpoint(self, checkpoint: Checkpoint) -> None:\n",
      "        super().save_checkpoint(checkpoint)\n",
      "\n",
      "        checkpoints = next(os.walk(self.directory))[1]\n",
      "        checkpoints = sorted(checkpoints, key=self.get_checkpoint_score)\n",
      "\n",
      "        while len(checkpoints) > self.max_checkpoints_num:\n",
      "            checkpoint_to_delete = checkpoints.pop()\n",
      "            checkpoint_to_delete = os.path.join(self.directory, checkpoint_to_delete)\n",
      "            shutil.rmtree(checkpoint_to_delete)\n",
      "<file_sep># ../pipeline/outputs/checkpointers/checkpointer.py\n",
      "from pipeline.outputs.checkpointers.checkpoint import Checkpoint\n",
      "from pipeline.outputs.loggers.logger_base import Log\n",
      "from pipeline.outputs.metrics import find_metric_class\n",
      "from pipeline.outputs.metrics.metric_base import OptimizationMode\n",
      "from pipeline.outputs.metrics.statistic_base import StatisticName, StatisticValue\n",
      "\n",
      "import json\n",
      "import os\n",
      "import warnings\n",
      "\n",
      "import torch\n",
      "\n",
      "\n",
      "class CheckpointManager:  # aka checkpointer\n",
      "    def __init__(self,\n",
      "                 main_metric: StatisticName,\n",
      "                 directory: str,\n",
      "                 checkpoint_directory_template: str = '{iteration_number:04d}',\n",
      "                 model_subdirectory: str = 'model',\n",
      "                 optim_state_filename: str = 'optim.pt',\n",
      "                 metrics_filename: str = 'metrics.json',  # should be .json\n",
      "                 ) -> None:\n",
      "        self.main_metric_name = main_metric\n",
      "        self.main_metric = find_metric_class(main_metric)\n",
      "        self.directory = directory\n",
      "\n",
      "        self._checkpoint_directory_template = checkpoint_directory_template\n",
      "        self._model_subdirectory = model_subdirectory\n",
      "        self._optim_state_filename = optim_state_filename\n",
      "        self._metrics_filename = metrics_filename\n",
      "\n",
      "    def load_metrics(self, checkpoint_dir: str) -> Log:\n",
      "        metrics_file = os.path.join(checkpoint_dir, self._metrics_filename)\n",
      "        with open(metrics_file) as stream:\n",
      "            return Log(**json.load(stream))\n",
      "\n",
      "    def get_checkpoint_score(self, checkpoint_dir: str) -> StatisticValue:\n",
      "        checkpoint_dir = os.path.join(self.directory, checkpoint_dir)\n",
      "        metrics = self.load_metrics(checkpoint_dir)\n",
      "        metric_value = metrics.get('valid_metrics', metrics['train_metrics']).get(self.main_metric_name)\n",
      "\n",
      "        if metric_value is None:\n",
      "            raise RuntimeError(f'The {checkpoint_dir} does not contain information '\n",
      "                               'about the specified main_metric.')\n",
      "        elif self.main_metric.mode == OptimizationMode.MIN:\n",
      "            return metric_value\n",
      "        else:\n",
      "            return -metric_value\n",
      "\n",
      "    def save_checkpoint(self, checkpoint: Checkpoint) -> None:\n",
      "        checkpoint_dir = os.path.join(\n",
      "            self.directory,\n",
      "            self._checkpoint_directory_template.format(\n",
      "                iteration_number=checkpoint.metrics['iteration_number']),\n",
      "        )\n",
      "\n",
      "        if os.path.exists(checkpoint_dir):\n",
      "            warnings.warn(f'The contents of the checkpoint {checkpoint_dir} have been overwritten.')\n",
      "\n",
      "        model_save_dir, optim_file, metrics_file = map(\n",
      "            lambda x: os.path.join(checkpoint_dir, x),\n",
      "            [self._model_subdirectory, self._optim_state_filename, self._metrics_filename],\n",
      "        )\n",
      "\n",
      "        checkpoint.model.save_pretrained(model_save_dir)\n",
      "        torch.save(checkpoint.optimizer_state, optim_file)\n",
      "\n",
      "        with open(metrics_file, 'w') as stream:\n",
      "            json.dump(checkpoint.metrics, stream, indent=4)\n",
      "<file_sep># ../pipeline/outputs/checkpointers/checkpoint.py\n",
      "from pipeline.outputs.loggers.logger_base import Log\n",
      "\n",
      "from dataclasses import dataclass\n",
      "\n",
      "import torch.nn as nn\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class Checkpoint:\n",
      "    metrics: Log\n",
      "    model: nn.Module\n",
      "    optimizer_state: dict\n",
      "<file_sep># ../pipeline/outputs/checkpointers/__init__.py\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "from pipeline.outputs.checkpointers.top_k_checkpointer import TopKCheckpointManager\n",
      "<file_sep># ../pipeline/outputs/metrics/top_k_accuracy.py\n",
      "from pipeline.outputs.metrics.metric_base import OptimizationMode, MaskBasedMetric\n",
      "from pipeline.outputs.metrics.statistic_base import StatisticName, StatisticValue\n",
      "\n",
      "import torch\n",
      "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
      "\n",
      "\n",
      "class TopKAccuracy(MaskBasedMetric):\n",
      "    mode = OptimizationMode.MAX\n",
      "\n",
      "    def __init__(self, k: int, *args, **kwargs) -> None:\n",
      "        super().__init__(*args, **kwargs)\n",
      "        self.k = k\n",
      "        self.tp_plus_tn = 0\n",
      "        self.num_tokens = 0\n",
      "\n",
      "    @property\n",
      "    def name(self) -> StatisticName:\n",
      "        return super().name.replace('_k_', f'_{self.k}_')\n",
      "\n",
      "    @torch.inference_mode()\n",
      "    def micro_batch_update(self,\n",
      "                           model_output: CausalLMOutputWithPast,\n",
      "                           target_ids: torch.Tensor,\n",
      "                           **kwargs,\n",
      "                           ) -> None:\n",
      "        mask = self.get_mask(**kwargs)\n",
      "        logits = model_output.logits[mask]\n",
      "        target_ids = target_ids[mask].unsqueeze(-1)\n",
      "        pred_ids = logits.topk(self.k, dim=-1).indices\n",
      "\n",
      "        self.tp_plus_tn += (pred_ids == target_ids).any(-1).sum().item()\n",
      "        self.num_tokens += mask.sum().item()\n",
      "\n",
      "    def batch_commit(self, **_kwargs) -> StatisticValue:\n",
      "        batch_metric = float('nan') if not self.num_tokens else (self.tp_plus_tn / self.num_tokens)\n",
      "        self.tp_plus_tn = 0\n",
      "        self.num_tokens = 0\n",
      "        return batch_metric\n",
      "<file_sep># ../pipeline/outputs/metrics/exact_match.py\n",
      "from pipeline.outputs.metrics.metric_base import OptimizationMode, MaskBasedMetric\n",
      "from pipeline.outputs.metrics.statistic_base import StatisticValue\n",
      "\n",
      "import torch\n",
      "from transformers import PreTrainedTokenizerBase\n",
      "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
      "\n",
      "\n",
      "class ExactMatch(MaskBasedMetric):\n",
      "    mode = OptimizationMode.MAX\n",
      "    requires_tokenizer = True\n",
      "\n",
      "    def __init__(self, tokenizer: PreTrainedTokenizerBase, min_tokens: int, *args, **kwargs) -> None:\n",
      "        super().__init__(*args, **kwargs)\n",
      "        if min_tokens < 1:\n",
      "            raise ValueError('min_tokens must be a natural number.')\n",
      "\n",
      "        self.vocab_size = len(tokenizer)\n",
      "        self.list_newline_ids = [\n",
      "            token_id for token_id in range(self.vocab_size)\n",
      "            if '\\n' in tokenizer.decode(token_id)]\n",
      "        self.set_newline_ids = set(self.list_newline_ids)\n",
      "\n",
      "        self.min_tokens = min_tokens\n",
      "        self.num_matches = 0\n",
      "        self.num_lines = 0\n",
      "\n",
      "    @torch.inference_mode()\n",
      "    def micro_batch_update(self,\n",
      "                           model_output: CausalLMOutputWithPast,\n",
      "                           target_ids: torch.Tensor,\n",
      "                           **kwargs,\n",
      "                           ) -> None:\n",
      "        mask = self.get_mask(**kwargs)\n",
      "        logits = model_output.logits[mask]\n",
      "        logits[:, self.vocab_size:] = -torch.inf\n",
      "        target_ids = target_ids[mask].tolist()\n",
      "\n",
      "        gt_line_ids = [[]]\n",
      "\n",
      "        for token_id in target_ids:\n",
      "            gt_line_ids[-1].append(token_id)\n",
      "            if token_id in self.set_newline_ids:\n",
      "                gt_line_ids.append([])\n",
      "\n",
      "        if not gt_line_ids[-1]:\n",
      "            gt_line_ids.pop(-1)\n",
      "\n",
      "        start_idx = 0\n",
      "        for line in gt_line_ids:\n",
      "            line_length = len(line)\n",
      "            line_logits = logits[start_idx:(start_idx + line_length)]\n",
      "            pred_line = line_logits.argmax(-1).tolist()\n",
      "\n",
      "            start_idx += line_length\n",
      "\n",
      "            interruption = bool(self.set_newline_ids & set(pred_line[:(self.min_tokens - 1)]))\n",
      "            short_line = (line_length < self.min_tokens)\n",
      "\n",
      "            if interruption and not short_line:  # give the model a second chance\n",
      "                line_logits[:(self.min_tokens - 1), self.list_newline_ids] = -torch.inf\n",
      "                pred_line = line_logits.argmax(-1).tolist()\n",
      "            elif interruption and short_line:\n",
      "                continue  # ignore model performance on uninteresting lines\n",
      "\n",
      "            self.num_matches += (pred_line == line)\n",
      "            self.num_lines += 1\n",
      "\n",
      "    def batch_commit(self, **_kwargs) -> StatisticValue:\n",
      "        batch_metric = float('nan') if not self.num_lines else (self.num_matches / self.num_lines)\n",
      "        self.num_matches = 0\n",
      "        self.num_lines = 0\n",
      "        return batch_metric\n",
      "<file_sep># ../pipeline/outputs/metrics/cross_entropy.py\n",
      "from pipeline.outputs.metrics.metric_base import OptimizationMode, MaskBasedMetric\n",
      "from pipeline.outputs.metrics.statistic_base import StatisticValue\n",
      "\n",
      "import torch\n",
      "\n",
      "\n",
      "class CrossEntropy(MaskBasedMetric):\n",
      "    mode = OptimizationMode.MIN\n",
      "\n",
      "    def __init__(self, *args, **kwargs) -> None:\n",
      "        super().__init__(*args, **kwargs)\n",
      "        self.mean_loss = 0\n",
      "        self.num_tokens = 0\n",
      "\n",
      "    @torch.inference_mode()\n",
      "    def micro_batch_update(self, loss_per_token: torch.Tensor, **kwargs) -> None:\n",
      "        mask = self.get_mask(**kwargs)\n",
      "        loss_update = torch.nan_to_num(loss_per_token[mask].mean()).item()\n",
      "        num_tokens_update = mask.sum().item()\n",
      "\n",
      "        # loss correction w.r.t. number of masked tokens (for unbalanced batches)\n",
      "        if not self.num_tokens:\n",
      "            self.mean_loss += loss_update\n",
      "            self.num_tokens = 0\n",
      "        else:\n",
      "            tokens_ratio = num_tokens_update / self.num_tokens\n",
      "            self.mean_loss += tokens_ratio * loss_update\n",
      "            self.mean_loss /= tokens_ratio + 1\n",
      "\n",
      "        self.num_tokens += num_tokens_update\n",
      "\n",
      "    def batch_commit(self, **_kwargs) -> StatisticValue:\n",
      "        batch_metric = float('nan') if not self.num_tokens else self.mean_loss\n",
      "        self.mean_loss = 0\n",
      "        self.num_tokens = 0\n",
      "        return batch_metric\n",
      "<file_sep># ../pipeline/outputs/metrics/statistic_base.py\n",
      "import re\n",
      "from abc import ABC, abstractmethod\n",
      "\n",
      "import torch\n",
      "\n",
      "StatisticName = str\n",
      "StatisticValue = int | float\n",
      "\n",
      "\n",
      "class StatisticBase(ABC):\n",
      "    requires_tokenizer: bool = False\n",
      "\n",
      "    @property\n",
      "    def name(self) -> StatisticName:\n",
      "        return re.sub(r'(?<!^)(?=[A-Z])', '_', type(self).__name__).lower()\n",
      "\n",
      "    def __repr__(self) -> str:\n",
      "        return self.name\n",
      "\n",
      "    @abstractmethod\n",
      "    @torch.inference_mode()\n",
      "    def micro_batch_update(self, **kwargs) -> None:\n",
      "        raise NotImplementedError\n",
      "\n",
      "    @abstractmethod\n",
      "    def batch_commit(self, **kwargs) -> StatisticValue:\n",
      "        raise NotImplementedError\n",
      "\n",
      "\n",
      "class LazyStatistic(StatisticBase):\n",
      "    def __init__(self, statistic_name: StatisticName) -> None:\n",
      "        self.statistic_name = statistic_name\n",
      "        self.value = None\n",
      "\n",
      "    @property\n",
      "    def name(self) -> StatisticName:\n",
      "        return self.statistic_name\n",
      "\n",
      "    def micro_batch_update(self, **kwargs) -> None:\n",
      "        self.value = kwargs.get(self.statistic_name)\n",
      "\n",
      "    def batch_commit(self, **_kwargs) -> StatisticValue:\n",
      "        batch_statistic = self.value\n",
      "        self.value = None\n",
      "        return batch_statistic\n",
      "<file_sep># ../pipeline/outputs/metrics/metric_base.py\n",
      "from pipeline.outputs.metrics.statistic_base import StatisticName, StatisticBase\n",
      "\n",
      "from abc import ABC, abstractmethod\n",
      "from enum import Enum\n",
      "\n",
      "import torch\n",
      "\n",
      "\n",
      "class OptimizationMode(str, Enum):\n",
      "    MIN = 'minimization'\n",
      "    MAX = 'maximization'\n",
      "\n",
      "\n",
      "class MetricBase(StatisticBase, ABC):\n",
      "    @property\n",
      "    @abstractmethod\n",
      "    def mode(self) -> OptimizationMode:\n",
      "        raise NotImplementedError\n",
      "\n",
      "\n",
      "class MaskType(str, Enum):\n",
      "    ATTACHED = ''\n",
      "    DETACHED = 'detached'\n",
      "    COMPLETION = 'completion'\n",
      "    CONTEXT = 'context'\n",
      "    FULL = 'full'\n",
      "\n",
      "\n",
      "class MaskBasedMetric(MetricBase, ABC):\n",
      "    def __init__(self, mask_type: MaskType) -> None:\n",
      "        self.mask_type = mask_type\n",
      "\n",
      "    @property\n",
      "    def name(self) -> StatisticName:\n",
      "        prefix = '' if self.mask_type == MaskType.ATTACHED else f'{self.mask_type}_'\n",
      "        return prefix + super().name\n",
      "\n",
      "    def get_mask(self, **kwargs) -> torch.Tensor:\n",
      "        match self.mask_type:\n",
      "            case MaskType.ATTACHED:\n",
      "                return kwargs['loss_mask']\n",
      "            case MaskType.DETACHED:\n",
      "                return ~kwargs['loss_mask'] & kwargs['target_attn_mask']\n",
      "            case MaskType.COMPLETION:\n",
      "                return kwargs['completion_mask']\n",
      "            case MaskType.CONTEXT:\n",
      "                return ~kwargs['completion_mask'] & kwargs['target_attn_mask']\n",
      "            case MaskType.FULL:\n",
      "                return kwargs['target_attn_mask']\n",
      "            case _:\n",
      "                raise ValueError(f'Invalid mask type: {self.mask_type}.')\n",
      "<file_sep># ../pipeline/outputs/metrics/counters.py\n",
      "from pipeline.outputs.metrics.metric_base import OptimizationMode, MetricBase, MaskType, MaskBasedMetric\n",
      "from pipeline.outputs.metrics.statistic_base import StatisticValue, StatisticName\n",
      "\n",
      "from typing import TypeVar, Type\n",
      "\n",
      "import torch\n",
      "\n",
      "T = TypeVar('T')\n",
      "\n",
      "# avoiding cyclical imports\n",
      "UniversalTrainer = TypeVar('UniversalTrainer')\n",
      "\n",
      "\n",
      "class EpochCounter(MetricBase):\n",
      "    _instance = None  # singleton pattern\n",
      "    # it’s not a metric in the usual sense, but when used with main_metric in\n",
      "    # TopKCheckpointManager, it will result in saving only the last k checkpoints\n",
      "    mode = OptimizationMode.MAX\n",
      "\n",
      "    def __new__(cls: Type[T], *args, **kwargs) -> T:\n",
      "        if cls._instance is None:\n",
      "            cls._instance = super().__new__(cls)\n",
      "        return cls._instance\n",
      "\n",
      "    def __init__(self) -> None:\n",
      "        self.samples = 0\n",
      "        self.ds_length = 1\n",
      "\n",
      "    @property\n",
      "    def name(self) -> StatisticName:\n",
      "        return 'epoch'\n",
      "\n",
      "    def micro_batch_update(self, input_ids: torch.Tensor, trainer: UniversalTrainer, **_kwargs) -> None:\n",
      "        if trainer.model.training:  # ignores validation samples\n",
      "            self.samples += input_ids.shape[0]\n",
      "            self.ds_length = len(trainer.train_dl.dataset)\n",
      "\n",
      "    def batch_commit(self, **_kwargs) -> StatisticValue:\n",
      "        return self.samples / self.ds_length\n",
      "\n",
      "\n",
      "class TokenCounter(MaskBasedMetric):\n",
      "    mode = OptimizationMode.MAX\n",
      "\n",
      "    def __init__(self, *args, **kwargs) -> None:\n",
      "        super().__init__(*args, **kwargs)\n",
      "        self.num_tokens = 0\n",
      "\n",
      "    @property\n",
      "    def name(self) -> StatisticName:\n",
      "        mask_type = '' if self.mask_type == MaskType.ATTACHED else f'{self.mask_type}_'\n",
      "        return f'num_{mask_type}tokens'\n",
      "\n",
      "    @torch.inference_mode()\n",
      "    def micro_batch_update(self, **kwargs) -> None:\n",
      "        self.num_tokens += self.get_mask(**kwargs).sum().item()\n",
      "\n",
      "    def batch_commit(self, **_kwargs) -> StatisticValue:\n",
      "        return self.num_tokens\n",
      "<file_sep># ../pipeline/outputs/metrics/__init__.py\n",
      "from incontext.init_from_config import find_class\n",
      "from pipeline.outputs.metrics.counters import EpochCounter, TokenCounter\n",
      "from pipeline.outputs.metrics.cross_entropy import CrossEntropy\n",
      "from pipeline.outputs.metrics.exact_match import ExactMatch\n",
      "from pipeline.outputs.metrics.statistic_base import LazyStatistic, StatisticName, StatisticBase\n",
      "from pipeline.outputs.metrics.top_k_accuracy import TopKAccuracy\n",
      "\n",
      "import os\n",
      "from typing import Iterable\n",
      "\n",
      "import yaml\n",
      "from transformers import PreTrainedTokenizerBase\n",
      "\n",
      "\n",
      "def find_metric_class(metric_name: str) -> type:\n",
      "    return find_class(\n",
      "        name=metric_name,\n",
      "        module_name='pipeline.outputs.metrics',\n",
      "        normalization_func=lambda x: {\n",
      "            'epoch': 'EpochCounter',\n",
      "            'num_tokens': 'TokenCounter',\n",
      "        }.get(x, x.replace('_', '')),\n",
      "    )\n",
      "\n",
      "\n",
      "def init_metrics(loaded_config: Iterable[StatisticName],\n",
      "                 configs_dir: str,\n",
      "                 tokenizer: PreTrainedTokenizerBase,\n",
      "                 ) -> list[StatisticBase]:\n",
      "    # dictionary solves the problem of using the same metric names multiple times:\n",
      "    # only the last metric specified in the configuration will be used\n",
      "    metrics = dict()\n",
      "\n",
      "    for path in loaded_config:\n",
      "        full_path = os.path.join(configs_dir, 'metrics/metrics', path)\n",
      "        metric_name = os.path.basename(os.path.dirname(path))\n",
      "\n",
      "        with open(full_path) as stream:\n",
      "            metric_config = yaml.safe_load(stream)\n",
      "\n",
      "        if metric_config is None:\n",
      "            metric_config = dict()\n",
      "\n",
      "        metric_class = find_metric_class(metric_name)\n",
      "        if metric_class.requires_tokenizer:\n",
      "            metric_config['tokenizer'] = tokenizer\n",
      "\n",
      "        metric = metric_class(**metric_config)\n",
      "        metrics[metric.name] = metric\n",
      "\n",
      "    return list(metrics.values())\n",
      "\n",
      "\n",
      "__all__ = [\n",
      "    'find_metric_class',\n",
      "    'init_metrics',\n",
      "    'EpochCounter',\n",
      "    'TokenCounter',\n",
      "    'CrossEntropy',\n",
      "    'ExactMatch',\n",
      "    'LazyStatistic',\n",
      "    'TopKAccuracy',\n",
      "]\n",
      "<file_sep># ../pipeline/data/preprocessors/lm_preprocessor.py\n",
      "from pipeline.data.preprocessors.completion_loss_preprocessor import CompletionLossPreprocessor\n",
      "\n",
      "import torch\n",
      "from transformers import BatchEncoding\n",
      "\n",
      "\n",
      "class LMPreprocessor(CompletionLossPreprocessor):\n",
      "    def get_loss_mask(self,\n",
      "                      _tokenized_completions: BatchEncoding,\n",
      "                      target_attn_mask: torch.Tensor,\n",
      "                      **_kwargs,\n",
      "                      ) -> torch.Tensor:\n",
      "        position_ids = torch.arange(target_attn_mask.shape[-1])\n",
      "        num_informative_tokens = target_attn_mask.sum(dim=-1, keepdim=True)\n",
      "        num_loss_tokens = (self.loss_ratio * num_informative_tokens).ceil().long()\n",
      "        loss_mask = (num_informative_tokens - num_loss_tokens <= position_ids)\n",
      "        return loss_mask.logical_and(target_attn_mask)\n",
      "<file_sep># ../pipeline/data/preprocessors/completion_loss_preprocessor.py\n",
      "from incontext.data_structures import BatchComposedDatapoint\n",
      "from pipeline.data.preprocessors.preprocessor_base import PreprocessedBatch, AmortizedPreprocessorBase\n",
      "\n",
      "import re\n",
      "import warnings\n",
      "\n",
      "import torch\n",
      "from transformers import BatchEncoding, PreTrainedTokenizerBase\n",
      "\n",
      "\n",
      "class CompletionLossPreprocessor(AmortizedPreprocessorBase):\n",
      "    def __init__(self,\n",
      "                 tokenizer: PreTrainedTokenizerBase,\n",
      "                 max_seq_len: int,\n",
      "                 context_tokens: int,\n",
      "                 max_completion_len: int,\n",
      "                 loss_ratio: float,\n",
      "                 num_chars_per_token: int,\n",
      "                 use_sep_token: bool,  # appended to the context\n",
      "                 padding: bool,\n",
      "                 verbose: bool = True,\n",
      "                 ) -> None:\n",
      "        super().__init__(num_chars_per_token, verbose)\n",
      "\n",
      "        # not all models have BOS token (e.g. Qwen2.5-Coder)\n",
      "        max_seq_len += (tokenizer.bos_token_id is None)\n",
      "\n",
      "        if not 0 < loss_ratio <= 1:\n",
      "            raise ValueError('loss_ratio must be selected from the interval (0, 1]. '\n",
      "                             f'Got {loss_ratio} instead.')\n",
      "\n",
      "        if padding:\n",
      "            tokenizer.deprecation_warnings['Asking-to-pad-a-fast-tokenizer'] = True\n",
      "        tokenizer.deprecation_warnings['sequence-length-is-longer-than-the-specified-maximum'] = True\n",
      "\n",
      "        self.tokenizer = tokenizer\n",
      "        self.max_seq_len = max_seq_len\n",
      "        self.context_tokens = context_tokens\n",
      "        self.max_completion_len = max_completion_len\n",
      "        self.loss_ratio = loss_ratio\n",
      "        self.use_sep_token = use_sep_token\n",
      "        self.padding = padding\n",
      "\n",
      "    def tokenize_pre_context_prompt(self, prompts: list[str]) -> BatchEncoding:\n",
      "        char_trunc_upper_bound = self.num_chars_per_token * self.max_seq_len\n",
      "\n",
      "        tokenized_prompts = self.tokenizer(\n",
      "            text=[prompt[-char_trunc_upper_bound:] for prompt in prompts],\n",
      "            add_special_tokens=False,\n",
      "            return_attention_mask=False,\n",
      "        )\n",
      "\n",
      "        for tokenized_prompt, prompt in zip(tokenized_prompts.input_ids, prompts):\n",
      "            overflow_chars = len(prompt) > char_trunc_upper_bound\n",
      "            underflow_tokens = len(tokenized_prompt) < self.max_seq_len\n",
      "\n",
      "            if overflow_chars and underflow_tokens:\n",
      "                self._inc_num_chars_per_token()\n",
      "                return self.tokenize_pre_context_prompt(prompts)\n",
      "\n",
      "        return tokenized_prompts\n",
      "\n",
      "    def tokenize_composed_completion(self, completions: list[str]) -> BatchEncoding:\n",
      "        char_trunc_upper_bound = self.num_chars_per_token * self.max_seq_len\n",
      "        trunc_completions = [completion[:char_trunc_upper_bound] for completion in completions]\n",
      "\n",
      "        tokenized_completions = self.tokenizer(\n",
      "            text=trunc_completions,\n",
      "            add_special_tokens=False,\n",
      "            return_attention_mask=False,\n",
      "            return_offsets_mapping=self.tokenizer.is_fast,  # TODO: is it needed?\n",
      "            return_length=True,\n",
      "        )\n",
      "\n",
      "        tokenized_completions.length = torch.tensor(tokenized_completions.length)\n",
      "        overflow_chars = torch.tensor([len(completion) > char_trunc_upper_bound for completion in completions])\n",
      "        underflow_tokens = (tokenized_completions.length < self.max_seq_len)\n",
      "\n",
      "        if torch.any(overflow_chars & underflow_tokens):\n",
      "            self._inc_num_chars_per_token()\n",
      "            return self.tokenize_composed_completion(completions)\n",
      "\n",
      "        if not self.tokenizer.is_fast:\n",
      "            tokenized_completions['offset_mapping'] = list(map(\n",
      "                self.calc_offset_mapping, tokenized_completions.input_ids\n",
      "            ))\n",
      "\n",
      "        tokenized_completions['newline_positions'] = [\n",
      "            [match.start() for match in re.finditer('\\n', completion)]\n",
      "            for completion in trunc_completions\n",
      "        ]\n",
      "\n",
      "        return tokenized_completions\n",
      "\n",
      "    def tokenize_composed_context(self, contexts: list[str]) -> BatchEncoding:\n",
      "        char_trunc_upper_bound = self.num_chars_per_token * self.max_seq_len\n",
      "\n",
      "        tokenized_contexts = self.tokenizer(\n",
      "            text=[ctx[-char_trunc_upper_bound:] for ctx in contexts],\n",
      "            add_special_tokens=False,\n",
      "            return_attention_mask=False,\n",
      "        )\n",
      "\n",
      "        for tokenized_ctx, ctx in zip(tokenized_contexts.input_ids, contexts):\n",
      "            overflow_chars = len(ctx) > char_trunc_upper_bound\n",
      "            underflow_tokens = len(tokenized_ctx) < self.max_seq_len\n",
      "\n",
      "            if overflow_chars and underflow_tokens:\n",
      "                self._inc_num_chars_per_token()\n",
      "                return self.tokenize_composed_context(contexts)\n",
      "\n",
      "            if not overflow_chars and len(tokenized_ctx) < self.context_tokens:\n",
      "                if not self.padding:\n",
      "                    raise ValueError('Not enough data to satisfy context_tokens.')\n",
      "                elif self.verbose:\n",
      "                    warnings.warn('Not enough data to satisfy context_tokens.')\n",
      "\n",
      "        return tokenized_contexts\n",
      "\n",
      "    def calc_lens(self,\n",
      "                  prompt: list[int],\n",
      "                  context: list[int],\n",
      "                  completion: list[int],\n",
      "                  ) -> tuple[int, int, int]:\n",
      "        if len(context) >= self.context_tokens:\n",
      "            prompt_len = min(\n",
      "                len(prompt),\n",
      "                self.max_seq_len - self.context_tokens,\n",
      "            )\n",
      "            completion_len = min(\n",
      "                len(completion),\n",
      "                self.max_seq_len - self.context_tokens - prompt_len,\n",
      "                self.max_completion_len,\n",
      "            )\n",
      "            context_len = self.max_seq_len - prompt_len - completion_len\n",
      "        else:\n",
      "            context_len = len(context)\n",
      "            prompt_len = min(\n",
      "                len(prompt),\n",
      "                self.max_seq_len - context_len,\n",
      "            )\n",
      "            completion_len = min(\n",
      "                self.max_seq_len - prompt_len - context_len,\n",
      "                self.max_completion_len,\n",
      "            )\n",
      "\n",
      "        return prompt_len, context_len, completion_len\n",
      "\n",
      "    @staticmethod\n",
      "    def _get_partial_completion_mask(tokenized_completions: BatchEncoding,\n",
      "                                     target_attn_mask: torch.Tensor,\n",
      "                                     ratio: float,\n",
      "                                     ) -> torch.Tensor:\n",
      "        position_ids = torch.arange(target_attn_mask.shape[-1])\n",
      "        num_informative_tokens = target_attn_mask.sum(dim=-1, keepdim=True)\n",
      "        completions_len = tokenized_completions.length.unsqueeze(-1)\n",
      "        num_masked_tokens = (ratio * completions_len).ceil().long()\n",
      "        mask = (num_informative_tokens - num_masked_tokens <= position_ids)\n",
      "        return mask.logical_and(target_attn_mask)\n",
      "\n",
      "    def get_loss_mask(self, *args, **kwargs) -> torch.Tensor:\n",
      "        return self._get_partial_completion_mask(*args, **kwargs, ratio=self.loss_ratio)\n",
      "\n",
      "    def get_completion_mask(self, *args, **kwargs) -> torch.Tensor:\n",
      "        return self._get_partial_completion_mask(*args, **kwargs, ratio=1)\n",
      "\n",
      "    def __call__(self, batch: BatchComposedDatapoint) -> PreprocessedBatch:\n",
      "        tokenized_prompts = self.tokenize_pre_context_prompt(batch['pre_context_prompt'])\n",
      "        tokenized_completions = self.tokenize_composed_completion(batch['composed_completion'])\n",
      "        tokenized_contexts = self.tokenize_composed_context(batch['composed_context'])\n",
      "\n",
      "        tokenized_batch = list()\n",
      "        batch_size = len(tokenized_completions.length)\n",
      "\n",
      "        for sample_idx in range(batch_size):\n",
      "            prompt = tokenized_prompts.input_ids[sample_idx]\n",
      "            context = tokenized_contexts.input_ids[sample_idx]\n",
      "            completion = tokenized_completions.input_ids[sample_idx]\n",
      "\n",
      "            prompt_len, context_len, completion_len = self.calc_lens(prompt, context, completion)\n",
      "\n",
      "            prompt = prompt[-prompt_len:]\n",
      "            if self.tokenizer.bos_token_id is not None:\n",
      "                prompt = [self.tokenizer.bos_token_id] + prompt\n",
      "\n",
      "            context = context[-context_len:]\n",
      "            if self.use_sep_token and context:\n",
      "                context = context[1:] + [self.tokenizer.sep_token_id]\n",
      "\n",
      "            completion = completion[:completion_len]\n",
      "\n",
      "            tokenized_completions.offset_mapping[sample_idx] = \\\n",
      "                tokenized_completions.offset_mapping[sample_idx][:completion_len]\n",
      "            tokenized_completions.length[sample_idx] = len(completion)\n",
      "\n",
      "            tokenized_batch.append(prompt + context + completion)\n",
      "\n",
      "        padded_batch = self.tokenizer.pad(\n",
      "            encoded_inputs={'input_ids': tokenized_batch},\n",
      "            padding='longest',\n",
      "            return_attention_mask=True,\n",
      "            return_tensors='pt')\n",
      "        input_attn_mask = padded_batch.attention_mask[:, :-1]\n",
      "        target_attn_mask = padded_batch.attention_mask[:, 1:]\n",
      "\n",
      "        return PreprocessedBatch(\n",
      "            input_ids=padded_batch.input_ids[:, :-1],\n",
      "            target_ids=padded_batch.input_ids[:, 1:],\n",
      "            loss_mask=self.get_loss_mask(tokenized_completions, target_attn_mask),\n",
      "            completion_mask=self.get_completion_mask(tokenized_completions, target_attn_mask),\n",
      "            input_attn_mask=input_attn_mask,\n",
      "            target_attn_mask=target_attn_mask.bool(),\n",
      "        )\n",
      "<file_sep># ../pipeline/data/preprocessors/preprocessor_base.py\n",
      "from incontext.data_structures import BatchComposedDatapoint\n",
      "\n",
      "import math\n",
      "import warnings\n",
      "from abc import ABC, abstractmethod\n",
      "from typing import TypedDict\n",
      "\n",
      "import torch\n",
      "\n",
      "\n",
      "class PreprocessedBatch(TypedDict):\n",
      "    input_ids: torch.Tensor\n",
      "    target_ids: torch.Tensor\n",
      "\n",
      "    loss_mask: torch.Tensor\n",
      "    completion_mask: torch.Tensor\n",
      "\n",
      "    input_attn_mask: torch.Tensor\n",
      "    target_attn_mask: torch.Tensor\n",
      "\n",
      "\n",
      "class PreprocessorBase(ABC):\n",
      "    tokenizer = None\n",
      "\n",
      "    @abstractmethod\n",
      "    def get_loss_mask(self, *args, **kwargs) -> torch.Tensor:\n",
      "        \"\"\"\n",
      "        Important note: different number of masked tokens in different\n",
      "        micro-batches will break gradient accumulation, in which case\n",
      "        the training loop should include corresponding gradient scaling.\n",
      "        *or we just don't care :)\n",
      "        \"\"\"\n",
      "        raise NotImplementedError\n",
      "\n",
      "    def calc_offset_mapping(self, seq_ids: list[int]) -> list[tuple[int, int]]:\n",
      "        char_start = 0\n",
      "        offsets = list()\n",
      "\n",
      "        for token_len in map(len, self.tokenizer.batch_decode(seq_ids)):\n",
      "            char_end = char_start + token_len\n",
      "            offsets.append((char_start, char_end))\n",
      "            char_start = char_end\n",
      "\n",
      "        return offsets\n",
      "\n",
      "    @abstractmethod\n",
      "    def get_completion_mask(self, *args, **kwargs) -> torch.Tensor:\n",
      "        raise NotImplementedError\n",
      "\n",
      "    @abstractmethod\n",
      "    def __call__(self, batch: BatchComposedDatapoint) -> PreprocessedBatch:\n",
      "        raise NotImplementedError\n",
      "\n",
      "\n",
      "class AmortizedPreprocessorBase(PreprocessorBase, ABC):\n",
      "    def __init__(self, num_chars_per_token: int, verbose: bool) -> None:\n",
      "        self.num_chars_per_token = num_chars_per_token\n",
      "        self.verbose = verbose\n",
      "\n",
      "    def _inc_num_chars_per_token(self) -> None:\n",
      "        old_value = self.num_chars_per_token\n",
      "        self.num_chars_per_token = math.ceil(1.5 * self.num_chars_per_token)\n",
      "\n",
      "        if self.verbose:\n",
      "            warnings.warn(\n",
      "                f'num_chars_per_token has been increased from {old_value} to {self.num_chars_per_token} '\n",
      "                'due to an underestimation of the length of the truncated character sequence.')\n",
      "<file_sep># ../pipeline/data/preprocessors/__init__.py\n",
      "from pipeline.data.preprocessors.completion_loss_preprocessor import CompletionLossPreprocessor\n",
      "from pipeline.data.preprocessors.lm_preprocessor import LMPreprocessor\n",
      "<file_sep># ../pipeline/trainers/universal_trainer.py\n",
      "from pipeline.model.adapters.adapter_base import AdapterBase\n",
      "from pipeline.outputs.checkpointers.checkpoint import Checkpoint\n",
      "from pipeline.outputs.checkpointers.checkpointer import CheckpointManager\n",
      "from pipeline.outputs.loggers.logger_base import Log, LoggerBase\n",
      "from pipeline.outputs.metrics.statistic_base import StatisticName, StatisticValue, StatisticBase\n",
      "from pipeline.trainers.trainer_base import TrainerBase\n",
      "from pipeline.trainers.utils.fused_sampler import FusedSampler\n",
      "from pipeline.trainers.utils.schedulers import get_lr_from_cosine_scheduler_with_linear_warmup\n",
      "\n",
      "import warnings\n",
      "from functools import partial\n",
      "from typing import Literal\n",
      "\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "from datasets import Dataset\n",
      "from torch.utils.data import DataLoader\n",
      "from tqdm.auto import trange, tqdm\n",
      "from transformers import PreTrainedTokenizerBase\n",
      "\n",
      "\n",
      "class UniversalTrainer(TrainerBase):\n",
      "    def __init__(self,\n",
      "                 model: nn.Module,\n",
      "                 tokenizer: PreTrainedTokenizerBase,\n",
      "                 train_ds: Dataset,\n",
      "                 valid_ds: Dataset | None,\n",
      "                 add_valid_ds: Dataset | None,\n",
      "                 # auxiliary objects\n",
      "                 adapter: AdapterBase,\n",
      "                 checkpointer: CheckpointManager,\n",
      "                 logger: LoggerBase,\n",
      "                 # iteration parameters\n",
      "                 max_iters: int,\n",
      "                 valid_freq: int | None,\n",
      "                 checkpointing_freq: int | None,\n",
      "                 gradient_accumulation_steps: int,\n",
      "                 micro_batch_size: int,\n",
      "                 # optimizer\n",
      "                 learning_rate: float,\n",
      "                 beta_1: float,\n",
      "                 beta_2: float,\n",
      "                 weight_decay: float,\n",
      "                 max_grad_norm: float,\n",
      "                 # scheduler\n",
      "                 warmup_iters: int | None,\n",
      "                 lr_decay_iters: int | None,\n",
      "                 min_lr: float | None,\n",
      "                 # metrics\n",
      "                 train_metrics: list[StatisticBase],\n",
      "                 valid_metrics: list[StatisticBase],\n",
      "                 # DataLoader\n",
      "                 shuffle: bool,\n",
      "                 drop_last: bool,\n",
      "                 num_workers: int,\n",
      "                 prefetch_factor: int,\n",
      "                 random_seed: int | None,\n",
      "                 # Floating point\n",
      "                 fp32_matmul_precision: Literal['highest', 'high', 'medium'],\n",
      "                 ) -> None:\n",
      "        # main objects\n",
      "        self.model = model\n",
      "        self.tokenizer = tokenizer\n",
      "        self.adapter = adapter\n",
      "        self.checkpointer = checkpointer\n",
      "        self.logger = logger\n",
      "\n",
      "        # iterations\n",
      "        self.checkpointing_freq = checkpointing_freq\n",
      "\n",
      "        if checkpointing_freq is None:\n",
      "            self.checkpointing_freq = float('inf')\n",
      "            self.logger.message('Checkpointing is disabled.')\n",
      "        elif valid_freq is not None and valid_freq != checkpointing_freq:\n",
      "            warnings.warn('Validation and checkpointing are not synchronized (valid_freq != checkpointing_freq). '\n",
      "                          'Resulting checkpoints will not contain validation metrics.')\n",
      "\n",
      "        self.max_iters = max_iters\n",
      "        self.gradient_accumulation_steps = gradient_accumulation_steps\n",
      "        self.batch_size = gradient_accumulation_steps * micro_batch_size\n",
      "\n",
      "        # environment\n",
      "        self.is_on_cuda = (model.device.type == 'cuda')\n",
      "        if random_seed is not None:\n",
      "            torch.manual_seed(random_seed)\n",
      "        torch.set_float32_matmul_precision(fp32_matmul_precision)\n",
      "        logger.message(f\"Set the FP32 matrix multiplication precision to '{fp32_matmul_precision}'.\")\n",
      "\n",
      "        # validation\n",
      "        if valid_ds is None and add_valid_ds is not None:\n",
      "            raise ValueError('Do not use an additional validation slot unless you have filled the first one.')\n",
      "        if valid_ds is None and valid_freq is None and not valid_metrics:\n",
      "            self.valid_freq = float('inf')\n",
      "            self.valid_dl = None\n",
      "            self.logger.message('Validation is disabled.')\n",
      "        elif valid_ds is not None and valid_freq is not None and valid_metrics:\n",
      "            self.valid_freq = valid_freq\n",
      "\n",
      "            ds_to_dl = lambda x: DataLoader(\n",
      "                dataset=x,\n",
      "                batch_size=micro_batch_size,\n",
      "                shuffle=False,\n",
      "                num_workers=num_workers,\n",
      "                pin_memory=self.is_on_cuda,\n",
      "                drop_last=False,\n",
      "                prefetch_factor=prefetch_factor,\n",
      "                persistent_workers=(valid_freq > max_iters),\n",
      "                pin_memory_device=str(model.device),\n",
      "            )\n",
      "\n",
      "            self.valid_dl = ds_to_dl(valid_ds)\n",
      "            self.add_valid_dl = ds_to_dl(add_valid_ds) if add_valid_ds is not None else None\n",
      "        else:\n",
      "            raise ValueError('The valid_ds, valid_freq and valid_metrics arguments do not match each other.')\n",
      "\n",
      "        # training dataset\n",
      "        sampler = FusedSampler(\n",
      "            start_sample_idx=(self.batch_size * 0),  # was previously used to slice the dataset\n",
      "            end_sample_idx=(self.batch_size * max_iters),\n",
      "            dataset_length=len(train_ds),\n",
      "        ) if shuffle else None\n",
      "\n",
      "        self.train_dl = DataLoader(\n",
      "            dataset=train_ds,\n",
      "            batch_size=micro_batch_size,\n",
      "            sampler=sampler,\n",
      "            num_workers=num_workers,\n",
      "            pin_memory=self.is_on_cuda,\n",
      "            drop_last=drop_last,\n",
      "            prefetch_factor=prefetch_factor,\n",
      "            pin_memory_device=str(model.device),\n",
      "        )\n",
      "\n",
      "        # optimizer initialization\n",
      "        self.optimizer = self.adapter.init_optimizer(\n",
      "            self.model, lr=learning_rate,\n",
      "            betas=(beta_1, beta_2),\n",
      "            weight_decay=weight_decay,\n",
      "            fused=self.is_on_cuda,\n",
      "        )\n",
      "\n",
      "        # gradient utilities\n",
      "        self.grad_scaler = torch.cuda.amp.GradScaler(enabled=(model.dtype == torch.float16))\n",
      "        self.max_grad_norm = max_grad_norm\n",
      "\n",
      "        # scheduler initialization\n",
      "        if warmup_iters is None and lr_decay_iters is None and min_lr is None:\n",
      "            self.get_lr = lambda _: learning_rate\n",
      "        elif warmup_iters is not None and lr_decay_iters is not None and min_lr is not None:\n",
      "            self.get_lr = partial(\n",
      "                get_lr_from_cosine_scheduler_with_linear_warmup,\n",
      "                min_lr=min_lr,\n",
      "                max_lr=learning_rate,\n",
      "                warmup_iters=warmup_iters,\n",
      "                lr_decay_iters=lr_decay_iters,\n",
      "            )\n",
      "        else:\n",
      "            raise ValueError('The warmup_iters, lr_decay_iters and min_lr arguments do not match each other.')\n",
      "\n",
      "        # metrics\n",
      "        self.train_metrics = train_metrics\n",
      "        self.valid_metrics = valid_metrics\n",
      "\n",
      "    @torch.inference_mode()\n",
      "    def validate(self, valid_dl: DataLoader | None, verbose: bool = True) -> dict[StatisticName, StatisticValue]:\n",
      "        if valid_dl is None:\n",
      "            return {}\n",
      "\n",
      "        is_additional = valid_dl is self.add_valid_dl\n",
      "        training = self.model.training\n",
      "        self.model.eval()\n",
      "\n",
      "        valid_iter = tqdm(\n",
      "            iterable=valid_dl,\n",
      "            desc='Additional validation steps' if is_additional else 'Validation steps',\n",
      "            position=1,\n",
      "            leave=None,\n",
      "            disable=not verbose,\n",
      "        )\n",
      "\n",
      "        for micro_batch in valid_iter:\n",
      "            inputs = (\n",
      "                input_ids, target_ids,\n",
      "                loss_mask, completion_mask,\n",
      "                input_attn_mask, target_attn_mask,\n",
      "            ) = tuple(t.to(self.model.device) for t in micro_batch.values())\n",
      "            args, kwargs = self.adapter.get_args_kwargs(*inputs)\n",
      "\n",
      "            model_output = self.model(*args, **kwargs)\n",
      "            loss_per_token = F.cross_entropy(\n",
      "                input=model_output.logits.flatten(0, 1),\n",
      "                target=target_ids.flatten(0, 1),\n",
      "                reduction='none',\n",
      "            ).view_as(target_ids)\n",
      "\n",
      "            locals_copy = locals().copy()\n",
      "            locals_copy['trainer'] = locals_copy.pop('self')\n",
      "            [metric.micro_batch_update(**locals_copy) for metric in self.valid_metrics]\n",
      "            del locals_copy\n",
      "\n",
      "        locals_copy = locals().copy()\n",
      "        locals_copy['trainer'] = locals_copy.pop('self')\n",
      "        valid_log = {\n",
      "            f'{\"additional_\" if is_additional else \"\"}{metric.name}': metric.batch_commit(**locals_copy)\n",
      "            for metric in self.valid_metrics\n",
      "        }\n",
      "\n",
      "        self.model.train(training)\n",
      "        return valid_log\n",
      "\n",
      "    def train(self, verbose: bool = True) -> None:\n",
      "        self.model.train()\n",
      "\n",
      "        train_iter = iter(self.train_dl)\n",
      "        pbar_iter = trange(\n",
      "            0, self.max_iters,\n",
      "            desc='Optimization steps',\n",
      "            initial=0,\n",
      "            total=self.max_iters,\n",
      "            position=0,\n",
      "            disable=not verbose,\n",
      "        )\n",
      "        pbar_accumulation = trange(\n",
      "            self.gradient_accumulation_steps,\n",
      "            desc='Gradient accumulation steps',\n",
      "            position=1,\n",
      "            leave=None,\n",
      "            disable=not verbose,\n",
      "        )\n",
      "\n",
      "        # zero-step validation\n",
      "        if self.valid_dl is not None:\n",
      "            valid_log = self.validate(self.valid_dl, verbose)\n",
      "            valid_log |= self.validate(self.add_valid_dl, verbose)\n",
      "            log = Log(iteration_number=0, valid_metrics=valid_log)\n",
      "            self.logger.log(log)\n",
      "\n",
      "        for iter_num in pbar_iter:\n",
      "            pbar_accumulation.reset()\n",
      "\n",
      "            learning_rate = self.get_lr(iter_num)\n",
      "            for param_group in self.optimizer.param_groups:\n",
      "                param_group['lr'] = learning_rate\n",
      "\n",
      "            for _ in range(self.gradient_accumulation_steps):\n",
      "                inputs = (\n",
      "                    input_ids, target_ids,\n",
      "                    loss_mask, completion_mask,\n",
      "                    input_attn_mask, target_attn_mask,\n",
      "                ) = tuple(t.to(self.model.device) for t in next(train_iter).values())\n",
      "                args, kwargs = self.adapter.get_args_kwargs(*inputs)\n",
      "\n",
      "                model_output = self.model(*args, **kwargs)\n",
      "                loss_per_token = F.cross_entropy(\n",
      "                    input=model_output.logits.flatten(0, 1),\n",
      "                    target=target_ids.flatten(0, 1),\n",
      "                    reduction='none',\n",
      "                ).view_as(target_ids)\n",
      "                # not accurate if drop_last=False and micro_batch_size != 1\n",
      "                # see also PreprocessorBase.get_loss_mask comment in pipeline/data/preprocessors/preprocessor_base.py\n",
      "                loss = loss_per_token[loss_mask].mean() / self.gradient_accumulation_steps\n",
      "\n",
      "                self.grad_scaler.scale(loss).backward()\n",
      "\n",
      "                locals_copy = locals().copy()\n",
      "                locals_copy['trainer'] = locals_copy.pop('self')\n",
      "                [metric.micro_batch_update(**locals_copy) for metric in self.train_metrics]\n",
      "                del locals_copy\n",
      "\n",
      "                pbar_accumulation.update()\n",
      "\n",
      "            if self.max_grad_norm != 0:\n",
      "                self.grad_scaler.unscale_(self.optimizer)\n",
      "                grad_norm = torch.nn.utils.clip_grad_norm_(\n",
      "                    parameters=self.adapter.get_trainable_parameters(self.model),\n",
      "                    max_norm=self.max_grad_norm,\n",
      "                )\n",
      "\n",
      "            self.grad_scaler.step(self.optimizer)\n",
      "            self.grad_scaler.update()\n",
      "            self.optimizer.zero_grad(set_to_none=True)\n",
      "\n",
      "            locals_copy = locals().copy()\n",
      "            locals_copy['trainer'] = locals_copy.pop('self')\n",
      "            log = Log(iteration_number=iter_num + 1, train_metrics={\n",
      "                metric.name: metric.batch_commit(**locals_copy) for metric in self.train_metrics\n",
      "            })\n",
      "            del locals_copy\n",
      "\n",
      "            if (iter_num + 1) % self.valid_freq == 0:\n",
      "                valid_log = self.validate(self.valid_dl, verbose)\n",
      "                valid_log |= self.validate(self.add_valid_dl, verbose)\n",
      "                log['valid_metrics'] = valid_log\n",
      "            self.logger.log(log)\n",
      "\n",
      "            if (iter_num + 1) % self.checkpointing_freq == 0:\n",
      "                self.checkpointer.save_checkpoint(Checkpoint(\n",
      "                    metrics=log,\n",
      "                    model=self.model,\n",
      "                    optimizer_state=self.optimizer.state_dict(),\n",
      "                ))\n",
      "<file_sep># ../pipeline/trainers/trainer_base.py\n",
      "from pipeline.outputs.metrics.statistic_base import StatisticName, StatisticValue\n",
      "\n",
      "from abc import ABC, abstractmethod\n",
      "\n",
      "import torch\n",
      "\n",
      "\n",
      "class TrainerBase(ABC):\n",
      "    @abstractmethod\n",
      "    @torch.inference_mode()\n",
      "    def validate(self, *args, **kwargs) -> dict[StatisticName, StatisticValue]:\n",
      "        raise NotImplementedError\n",
      "\n",
      "    @abstractmethod\n",
      "    def train(self, *args, **kwargs) -> None:\n",
      "        raise NotImplementedError\n",
      "<file_sep># ../pipeline/trainers/__init__.py\n",
      "from pipeline.trainers.universal_trainer import UniversalTrainer\n",
      "<file_sep># ../pipeline/model/__init__.py\n",
      "from pipeline.environment.hardware import get_free_device, get_optimal_dtype\n",
      "\n",
      "from enum import Enum\n",
      "from typing import Any\n",
      "\n",
      "import torch\n",
      "from omegaconf import OmegaConf\n",
      "from transformers.models.auto import MODEL_FOR_CAUSAL_LM_MAPPING\n",
      "from transformers.utils import is_flash_attn_2_available, is_torch_sdpa_available\n",
      "from transformers import (\n",
      "    AutoTokenizer,\n",
      "    AutoModelForCausalLM,\n",
      "    AutoConfig,\n",
      "    PreTrainedModel,\n",
      "    PreTrainedTokenizerBase,\n",
      ")\n",
      "\n",
      "\n",
      "class AttentionImplementation(str, Enum):\n",
      "    # nondeterministic\n",
      "    FA2 = 'flash_attention_2'\n",
      "    SDPA = 'sdpa'\n",
      "    # deterministic\n",
      "    EAGER = 'eager'\n",
      "\n",
      "\n",
      "def init_tokenizer(tokenizer_name: str, trust_remote_code: bool, **_kwargs) -> PreTrainedTokenizerBase:\n",
      "    tokenizer = AutoTokenizer.from_pretrained(\n",
      "        pretrained_model_name_or_path=tokenizer_name,\n",
      "        trust_remote_code=trust_remote_code,\n",
      "    )\n",
      "\n",
      "    tokenizer.padding_side = 'right'\n",
      "    if tokenizer.sep_token is None:\n",
      "        tokenizer.add_special_tokens({'sep_token': '<|SEP|>'})\n",
      "\n",
      "    return tokenizer\n",
      "\n",
      "\n",
      "def get_optimal_attn(model_name: str, device: torch.device, dtype: torch.dtype) -> AttentionImplementation:\n",
      "    hf_model_config = AutoConfig.from_pretrained(model_name)\n",
      "    model_class = MODEL_FOR_CAUSAL_LM_MAPPING[type(hf_model_config)]\n",
      "\n",
      "    fa2_supported = (\n",
      "            is_flash_attn_2_available() and\n",
      "            model_class._supports_flash_attn_2 and  # noqa: HF doesn't have an API for this case\n",
      "            device.type == 'cuda' and\n",
      "            dtype in (torch.float16, torch.bfloat16)\n",
      "    )\n",
      "\n",
      "    if fa2_supported:\n",
      "        return AttentionImplementation.FA2\n",
      "    elif is_torch_sdpa_available() and model_class._supports_sdpa:  # noqa: same\n",
      "        return AttentionImplementation.SDPA\n",
      "    else:\n",
      "        return AttentionImplementation.EAGER\n",
      "\n",
      "\n",
      "def init_model(model_name: str,\n",
      "               trust_remote_code: bool,\n",
      "               use_cache: bool = False,\n",
      "               device: str | None = None,\n",
      "               dtype: str | None = None,\n",
      "               attn_implementation: AttentionImplementation | None = None,\n",
      "               compile: bool = True,\n",
      "               config: dict[str, Any] | None = None,\n",
      "               **_kwargs,\n",
      "               ) -> PreTrainedModel:\n",
      "    device = get_free_device() if device is None else torch.device(device)\n",
      "    dtype = get_optimal_dtype() if dtype is None else getattr(torch, dtype)\n",
      "\n",
      "    if attn_implementation is None:\n",
      "        attn_implementation = get_optimal_attn(model_name, device, dtype)\n",
      "    else:\n",
      "        attn_implementation = AttentionImplementation(attn_implementation)\n",
      "\n",
      "    if config is None:\n",
      "        config = dict()\n",
      "\n",
      "    kwargs_config = config\n",
      "    if not isinstance(kwargs_config, dict):\n",
      "        kwargs_config = OmegaConf.to_container(kwargs_config)\n",
      "\n",
      "    model = AutoModelForCausalLM.from_pretrained(\n",
      "        pretrained_model_name_or_path=model_name,\n",
      "        trust_remote_code=trust_remote_code,\n",
      "        device_map=device,\n",
      "        torch_dtype=dtype,\n",
      "        attn_implementation=attn_implementation,\n",
      "        use_cache=use_cache,\n",
      "        **kwargs_config,\n",
      "    )\n",
      "\n",
      "    if compile:\n",
      "        return torch.compile(model)\n",
      "    else:\n",
      "        return model\n",
      "\n",
      "\n",
      "__all__ = [\n",
      "    'init_tokenizer',\n",
      "    'init_model',\n",
      "]\n",
      "<file_sep># ../pipeline/environment/hardware.py\n",
      "import subprocess\n",
      "import warnings\n",
      "\n",
      "import torch\n",
      "\n",
      "\n",
      "def get_free_device(used_memory_upper_bound: float = 0.001) -> torch.device:\n",
      "    if hasattr(get_free_device, 'allocated'):\n",
      "        return get_free_device.allocated\n",
      "\n",
      "    for gpu_index in range(torch.cuda.device_count()):\n",
      "        gpu_pid_stats = subprocess.check_output([\n",
      "            'nvidia-smi', f'-i={gpu_index}', '--query-compute-apps=pid', '--format=csv,noheader',\n",
      "        ], encoding='utf-8')\n",
      "        gpu_mem_stats = subprocess.check_output([\n",
      "            'nvidia-smi', f'-i={gpu_index}', '--query-gpu=memory.used,memory.total', '--format=csv,noheader',\n",
      "        ], encoding='utf-8')\n",
      "\n",
      "        mem_used, mem_total = map(int, gpu_mem_stats.replace('MiB', '').split(', '))\n",
      "\n",
      "        if not gpu_pid_stats and mem_used / mem_total <= used_memory_upper_bound:\n",
      "            get_free_device.allocated = torch.device(f'cuda:{gpu_index}')\n",
      "            return get_free_device.allocated\n",
      "\n",
      "    warnings.warn('No CUDA devices were found. CPU will be used.')\n",
      "    return torch.device('cpu')\n",
      "\n",
      "\n",
      "def get_optimal_dtype() -> torch.dtype:\n",
      "    if torch.cuda.is_available() and torch.cuda.is_bf16_supported():\n",
      "        return torch.bfloat16\n",
      "    else:\n",
      "        warnings.warn('torch.bfloat16 is not supported. torch.float16 '\n",
      "                      'with gradient scaling will be used instead.')\n",
      "        return torch.float16\n",
      "<file_sep># ../pipeline/data/dataset.py\n",
      "import random\n",
      "from collections import defaultdict\n",
      "\n",
      "import pandas as pd\n",
      "from datasets import Dataset\n",
      "\n",
      "\n",
      "def train_test_split(df: pd.DataFrame,\n",
      "                     test_size: int,\n",
      "                     upper_bound_per_repo: int,\n",
      "                     random_seed: int | None = None,\n",
      "                     ) -> tuple[list[int], list[int] | None]:\n",
      "    if test_size == 0:\n",
      "        return list(range(len(df))), None\n",
      "\n",
      "    generator = random.Random(random_seed)\n",
      "    queue = defaultdict(list)\n",
      "    repos_enum = list(enumerate(df.pre_context_prompt))\n",
      "    generator.shuffle(repos_enum)\n",
      "\n",
      "    for idx, repo in repos_enum:\n",
      "        queue[repo].append(idx)\n",
      "\n",
      "    queue = list(queue.items())\n",
      "    generator.shuffle(queue)\n",
      "\n",
      "    train_repos_ids = set(range(len(df)))\n",
      "    test_repos_ids = set()\n",
      "    cur_test_size = 0\n",
      "\n",
      "    while cur_test_size != test_size:\n",
      "        if queue:\n",
      "            repo, ids = queue.pop()\n",
      "        else:\n",
      "            raise ValueError(\n",
      "                'There are not enough data points in the original dataset to satisfy both the '\n",
      "                'test_size and upper_bound_per_repo arguments. Try either decreasing the test_size '\n",
      "                'or increasing the upper_bound_per_repo.')\n",
      "\n",
      "        num_new_samples = min(upper_bound_per_repo, test_size - cur_test_size, len(ids))\n",
      "\n",
      "        train_repos_ids.difference_update(ids)\n",
      "        test_repos_ids.update(ids[:num_new_samples])\n",
      "        cur_test_size += num_new_samples\n",
      "\n",
      "    return list(train_repos_ids), list(test_repos_ids)\n",
      "\n",
      "\n",
      "def irrelevant_context(string: str) -> str:\n",
      "    # Experiments with irrelevant context are only done with OpenCoder, so this function is sufficient\n",
      "    # Note that it has a different effect than the ReversedContextPostprocessor in incontext/blocks/context_postprocessing.py\n",
      "    return '<file_sep>'.join(string.split('<file_sep>')[:-1][::-1] + [''])\n",
      "\n",
      "\n",
      "def load_dataset(main_dataset_path: str,\n",
      "                 add_dataset_path: str | None,\n",
      "                 irrelevant_context: bool,\n",
      "                 file_level: bool,\n",
      "                 **split_kwargs,\n",
      "                 ) -> tuple[Dataset, Dataset, Dataset | None]:\n",
      "    dataset = pd.read_parquet(main_dataset_path)\n",
      "    train_ids, test_ids = train_test_split(dataset, **split_kwargs)\n",
      "\n",
      "    if irrelevant_context:\n",
      "        dataset['composed_context'] = dataset.composed_context.apply(irrelevant_context)\n",
      "    if file_level:\n",
      "        dataset['composed_context'] = ''\n",
      "\n",
      "    train_ds = Dataset.from_pandas(dataset.iloc[train_ids])\n",
      "    valid_ds = Dataset.from_pandas(dataset.iloc[test_ids])\n",
      "\n",
      "    if add_dataset_path is None:\n",
      "        return train_ds, valid_ds, None\n",
      "\n",
      "    add_dataset = pd.read_parquet(add_dataset_path)\n",
      "    assert list(dataset.pre_context_prompt) == list(add_dataset.pre_context_prompt)\n",
      "    add_valid_ds = Dataset.from_pandas(add_dataset.iloc[test_ids])\n",
      "\n",
      "    return train_ds, valid_ds, add_valid_ds\n",
      "<file_sep># ../evaluation/__main__.py\n",
      "from evaluation.dataset import LongCodeArenaDataset, DataCollator\n",
      "from evaluation.data_structures import ExactMatchCounter\n",
      "from incontext import init_from_config as init_composer\n",
      "from pipeline.model import init_tokenizer, init_model\n",
      "\n",
      "import json\n",
      "import os\n",
      "import sys\n",
      "\n",
      "import hydra\n",
      "import torch\n",
      "from datasets import load_dataset\n",
      "from omegaconf import DictConfig, OmegaConf\n",
      "from tqdm import tqdm\n",
      "from torch.utils.data import DataLoader\n",
      "\n",
      "\n",
      "PROJECT_DIR = os.path.dirname(os.path.dirname(__file__))\n",
      "CONFIGS_DIR = os.path.join(PROJECT_DIR, 'configs')\n",
      "\n",
      "\n",
      "@torch.inference_mode()\n",
      "@hydra.main(config_path=CONFIGS_DIR, config_name='evaluation', version_base=None)\n",
      "def main(config: DictConfig) -> None:\n",
      "    output_file = os.path.join(PROJECT_DIR, f'evaluation/outputs/individual/{config.eval_name}.json')\n",
      "    if os.path.exists(output_file):\n",
      "        print(f'{config.eval_name} has already been processed. Skipping this evaluation...')\n",
      "        return\n",
      "\n",
      "    argv_sh = ' \\\\\\n'.join(['python3 -m evaluation'] + sys.argv[1:])\n",
      "\n",
      "    if config.path_to_checkpoint is not None:\n",
      "        config.model.model_name = config.path_to_checkpoint\n",
      "\n",
      "    composer = init_composer(os.path.join(CONFIGS_DIR, config.path_to_composer_config))\n",
      "\n",
      "    tokenizer = init_tokenizer(**config.model)\n",
      "    tokenizer.truncation_side = 'left'\n",
      "\n",
      "    model = init_model(**config.model)\n",
      "    model = model.eval().requires_grad_(False)\n",
      "\n",
      "    crumpled_dataset = load_dataset(\n",
      "        path='JetBrains-Research/lca-project-level-code-completion',\n",
      "        name=f'{config.dataset_type}_context',\n",
      "        split='test',\n",
      "    )\n",
      "    dataset = LongCodeArenaDataset(\n",
      "        crumpled_dataset=crumpled_dataset,\n",
      "        context_size=config.context_size,\n",
      "        composer=composer,\n",
      "        allow_leak=config.allow_leak,\n",
      "    )\n",
      "\n",
      "    dataloader = DataLoader(\n",
      "        dataset=dataset,\n",
      "        batch_size=config.batch_size,\n",
      "        shuffle=False,\n",
      "        num_workers=config.num_workers,\n",
      "        pin_memory=(model.device.type == 'cuda'),\n",
      "        drop_last=False,\n",
      "        prefetch_factor=config.prefetch_factor,\n",
      "        pin_memory_device=str(model.device),\n",
      "        collate_fn=DataCollator(\n",
      "            tokenizer=tokenizer,\n",
      "            context_size=config.context_size,\n",
      "        ),\n",
      "    )\n",
      "\n",
      "    inproject_em = ExactMatchCounter()\n",
      "    infile_em = ExactMatchCounter()\n",
      "    ref_dict = {'inproject': inproject_em, 'infile': infile_em}\n",
      "    pbar_iter = tqdm(dataloader, desc='Evaluation steps')\n",
      "\n",
      "    for line_types, input_ids, attn_mask, ground_truths in pbar_iter:\n",
      "        input_ids = input_ids.to(model.device)\n",
      "        attn_mask = attn_mask.to(model.device)\n",
      "\n",
      "        model_output = model(input_ids=input_ids, attention_mask=attn_mask)\n",
      "        completions = tokenizer.batch_decode(model_output.logits.argmax(-1))\n",
      "\n",
      "        for line_type, completion, ground_truth in zip(line_types, completions, ground_truths):\n",
      "            ref_dict[line_type].num_matches += completion.rstrip('\\n').endswith(ground_truth.rstrip('\\n'))\n",
      "            ref_dict[line_type].num_lines += 1\n",
      "\n",
      "        pbar_iter.set_description(\n",
      "            f'Evaluation steps; inproject={inproject_em.value * 100:.1f}, infile={infile_em.value * 100:.1f}'\n",
      "        )\n",
      "\n",
      "    result = OmegaConf.to_container(config)\n",
      "    result.pop('eval_name')\n",
      "    result['composer'] = repr(composer)\n",
      "    result['sh'] = argv_sh\n",
      "    result['exact_match'] = {\n",
      "        'inproject': {\n",
      "            'num_matches': inproject_em.num_matches,\n",
      "            'num_lines': inproject_em.num_lines,\n",
      "            'value': inproject_em.value,\n",
      "        },\n",
      "        'infile': {\n",
      "            'num_matches': infile_em.num_matches,\n",
      "            'num_lines': infile_em.num_lines,\n",
      "            'value': infile_em.value,\n",
      "        },\n",
      "    }\n",
      "\n",
      "    with open(output_file, 'w') as stream:\n",
      "        json.dump(result, stream, indent=4)\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    main()\n",
      "<file_sep># ../evaluation/dataset.py\n",
      "from evaluation.data_structures import LongCodeArenaDatapoint\n",
      "from incontext import ChainedComposer\n",
      "from incontext.data_structures import Datapoint\n",
      "\n",
      "import math\n",
      "from dataclasses import asdict\n",
      "from typing import Literal\n",
      "\n",
      "import torch\n",
      "from datasets import Dataset as HuggingFaceDataset\n",
      "from torch.utils.data import Dataset\n",
      "from transformers import PreTrainedTokenizerBase\n",
      "\n",
      "\n",
      "LineType = Literal['inproject', 'infile']\n",
      "EvalSample = tuple[LineType, str, str, str]\n",
      "EvalBatch = tuple[list[LineType], torch.Tensor, torch.Tensor, list[str]]\n",
      "\n",
      "\n",
      "class LongCodeArenaDataset(Dataset):\n",
      "    def __init__(self,\n",
      "                 crumpled_dataset: HuggingFaceDataset,\n",
      "                 context_size: int,\n",
      "                 composer: ChainedComposer,\n",
      "                 allow_leak: bool,\n",
      "                 ) -> None:\n",
      "        self.crumpled_dataset = crumpled_dataset\n",
      "        self.context_size = context_size\n",
      "        self.composer = composer\n",
      "        self.allow_leak = allow_leak\n",
      "\n",
      "        self.indices = list()\n",
      "        for datapoint_idx, datapoint in enumerate(crumpled_dataset):\n",
      "            for line_type in ('inproject', 'infile'):\n",
      "                for line_idx in datapoint['completion_lines'][line_type]:\n",
      "                    self.indices.append((datapoint_idx, line_type, line_idx))\n",
      "\n",
      "    def __len__(self) -> int:\n",
      "        return len(self.indices)\n",
      "\n",
      "    def __getitem__(self, idx: int) -> EvalSample:\n",
      "        datapoint_idx, line_type, line_idx = self.indices[idx]\n",
      "        datapoint = LongCodeArenaDatapoint(**self.crumpled_dataset[datapoint_idx])\n",
      "\n",
      "        completion_lines = datapoint.completion_file['content'].split('\\n')\n",
      "        incontext_datapoint = Datapoint(\n",
      "            repo=datapoint.repo,\n",
      "            completion_file=datapoint.completion_file,\n",
      "            repo_snapshot=datapoint.repo_snapshot,\n",
      "        )\n",
      "\n",
      "        if self.allow_leak:\n",
      "            composed_datapoint = self.composer.compose(asdict(incontext_datapoint))\n",
      "            incontext_datapoint.completion_file['content'] = '\\n'.join(completion_lines[:line_idx])\n",
      "        else:\n",
      "            incontext_datapoint.completion_file['content'] = '\\n'.join(completion_lines[:line_idx])\n",
      "            composed_datapoint = self.composer.compose(asdict(incontext_datapoint))\n",
      "        \n",
      "        composed_datapoint['composed_completion'] = self.composer.compose_completion(incontext_datapoint)\n",
      "        ground_truth = completion_lines[line_idx]\n",
      "\n",
      "        return (\n",
      "            line_type,\n",
      "            composed_datapoint['composed_context'] + ('\\n', '')[composed_datapoint['composed_context'].endswith('\\n')],\n",
      "            composed_datapoint['composed_completion'] + ('\\n', '')[composed_datapoint['composed_completion'].endswith('\\n')],\n",
      "            ground_truth + ('\\n', '')[ground_truth.endswith('\\n')],\n",
      "        )\n",
      "\n",
      "\n",
      "class DataCollator:\n",
      "    def __init__(self,\n",
      "                 tokenizer: PreTrainedTokenizerBase,\n",
      "                 context_size: int,\n",
      "                 ) -> None:\n",
      "        self.tokenizer = tokenizer\n",
      "        self.context_size = context_size\n",
      "\n",
      "    def _tokenize(self, \n",
      "                  text: str,\n",
      "                  max_seq_len: int,\n",
      "                  num_chars_per_token: int = 6,\n",
      "                  ) -> list[int]:\n",
      "        if max_seq_len == 0:\n",
      "            return []\n",
      "\n",
      "        num_chars = max_seq_len * num_chars_per_token\n",
      "        trunc_text = text[-num_chars:]\n",
      "\n",
      "        tokenized_text = self.tokenizer(\n",
      "            text=trunc_text,\n",
      "            add_special_tokens=False,\n",
      "            return_attention_mask=False,\n",
      "        )\n",
      "\n",
      "        if len(text) > len(trunc_text) and len(tokenized_text.input_ids) < max_seq_len:\n",
      "            return self._tokenize(text, max_seq_len, math.ceil(1.5 * num_chars_per_token))\n",
      "        else:\n",
      "            return tokenized_text.input_ids[-max_seq_len:]\n",
      "\n",
      "    def __call__(self, batch: list[EvalSample]) -> EvalBatch:\n",
      "        line_types = list()\n",
      "        input_ids = list()\n",
      "        ground_truths = list()\n",
      "\n",
      "        for line_type, repo_context, file_prefix, ground_truth in batch:\n",
      "            tokenized_completion = self._tokenize(\n",
      "                text=file_prefix + ground_truth,\n",
      "                max_seq_len=self.context_size + 1)\n",
      "            tokenized_repo_context = self._tokenize(\n",
      "                text=repo_context,\n",
      "                max_seq_len=self.context_size - len(tokenized_completion) + 1,\n",
      "            )\n",
      "\n",
      "            line_types.append(line_type)\n",
      "            input_ids.append((tokenized_repo_context + tokenized_completion)[:-1])\n",
      "            ground_truths.append(ground_truth)\n",
      "\n",
      "        padded_batch = self.tokenizer.pad(\n",
      "            encoded_inputs={'input_ids': input_ids},\n",
      "            padding='longest',\n",
      "            return_attention_mask=True,\n",
      "            return_tensors='pt')\n",
      "        assert padded_batch.input_ids.shape[-1] <= self.context_size, padded_batch.input_ids.shape\n",
      "\n",
      "        return line_types, padded_batch.input_ids, padded_batch.attention_mask, ground_truths\n",
      "<file_sep># ../evaluation/data_structures.py\n",
      "from incontext.data_structures import CompletionFile, RepoSnapshot\n",
      "\n",
      "from dataclasses import dataclass\n",
      "from typing import TypedDict\n",
      "\n",
      "\n",
      "class CompletionLines(TypedDict, total=False):\n",
      "    commited: list[int]\n",
      "    common: list[int]\n",
      "    infile: list[int]\n",
      "    inproject: list[int]\n",
      "    non_informative: list[int]\n",
      "    random: list[int]\n",
      "    other: list[int]\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class LongCodeArenaDatapoint:\n",
      "    repo: str\n",
      "    commit_hash: str\n",
      "    completion_file: CompletionFile\n",
      "    completion_lines: CompletionLines\n",
      "    repo_snapshot: RepoSnapshot\n",
      "    completion_lines_raw: CompletionLines | None = None\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class ExactMatchCounter:\n",
      "    num_matches: int = 0\n",
      "    num_lines: int = 0\n",
      "\n",
      "    @property\n",
      "    def value(self) -> float:\n",
      "        if self.num_lines > 0:\n",
      "            return self.num_matches / self.num_lines\n",
      "        else:\n",
      "            return 0\n",
      "<file_sep># ../pipeline/__main__.py\n",
      "from incontext.init_from_config import find_class\n",
      "from pipeline.data.dataset import load_dataset\n",
      "from pipeline.model import init_tokenizer, init_model\n",
      "from pipeline.outputs.metrics import init_metrics\n",
      "\n",
      "import os\n",
      "import sys\n",
      "\n",
      "import hydra\n",
      "from hydra.core.hydra_config import HydraConfig\n",
      "from omegaconf import DictConfig, OmegaConf\n",
      "\n",
      "\n",
      "PROJECT_DIR = os.path.dirname(os.path.dirname(__file__))\n",
      "CONFIGS_DIR = os.path.join(PROJECT_DIR, 'configs')\n",
      "\n",
      "\n",
      "@hydra.main(config_path=CONFIGS_DIR, config_name='pipeline', version_base=None)\n",
      "def main(config: DictConfig) -> None:\n",
      "    argv_sh = ' \\\\\\n'.join(['python3 -m pipeline'] + sys.argv[1:])\n",
      "\n",
      "    run_dir = os.path.join(PROJECT_DIR, 'runs', config.run_name)\n",
      "    argv_sh_file = os.path.join(run_dir, config.argv_sh_file)\n",
      "    checkpoints_dir = os.path.join(run_dir, config.checkpoints_dir)\n",
      "    logs_dir = os.path.join(run_dir, config.logs_dir)\n",
      "\n",
      "    if os.path.exists(run_dir):\n",
      "        with open(argv_sh_file) as stream:\n",
      "            old_argv_sh = stream.read()\n",
      "\n",
      "        if argv_sh != old_argv_sh:\n",
      "            input(f'Mismatch of script arguments with an older instance of the same run ({argv_sh_file}).\\n'\n",
      "                   'Press ENTER to continue with the new ones.')\n",
      "    else:\n",
      "        os.mkdir(run_dir)\n",
      "        os.mkdir(checkpoints_dir)\n",
      "        os.mkdir(logs_dir)\n",
      "\n",
      "        os.mknod(os.path.join(checkpoints_dir, '.gitkeep'))\n",
      "        os.mknod(os.path.join(logs_dir, '.gitkeep'))\n",
      "\n",
      "    with open(argv_sh_file, 'w') as stream:\n",
      "        stream.write(argv_sh)\n",
      "\n",
      "    config_choices = HydraConfig.get().runtime.choices\n",
      "    adapter_name, checkpointer_name, logger_name, preprocessor_name, trainer_name = [\n",
      "        os.path.dirname(config_choices.get(cfg_group))\n",
      "        for cfg_group in ('adapter', 'checkpointer', 'logger', 'preprocessor', 'trainer')\n",
      "    ]\n",
      "\n",
      "    adapter_class = find_class(name=adapter_name, module_name='pipeline.model.adapters')\n",
      "    checkpointer_class = find_class(\n",
      "        name=checkpointer_name,\n",
      "        module_name='pipeline.outputs.checkpointers',\n",
      "        normalization_func={\n",
      "            'top_k_checkpointer': 'TopKCheckpointManager',\n",
      "            'checkpointer': 'CheckpointManager',\n",
      "        }.__getitem__,\n",
      "    )\n",
      "    logger_class = find_class(name=logger_name, module_name='pipeline.outputs.loggers')\n",
      "    preprocessor_class = find_class(name=preprocessor_name, module_name='pipeline.data.preprocessors')\n",
      "    trainer_class = find_class(name=trainer_name, module_name='pipeline.trainers')\n",
      "\n",
      "    checkpointer = checkpointer_class(**config.checkpointer, directory=checkpoints_dir)\n",
      "\n",
      "    tokenizer = init_tokenizer(**config.model)\n",
      "    model = init_model(**config.model)\n",
      "\n",
      "    adapter = adapter_class(**config.adapter, model_name=config.model.model_name)\n",
      "\n",
      "    model = adapter.adapt(model)\n",
      "\n",
      "    preprocessor = preprocessor_class(**config.preprocessor, tokenizer=tokenizer)\n",
      "\n",
      "    logger = logger_class(\n",
      "        **config.logger,\n",
      "        directory=logs_dir,\n",
      "        name=config.run_name,\n",
      "        config=dict(config) | {'config_choices': config_choices},\n",
      "    )\n",
      "\n",
      "    train_ds, valid_ds, add_valid_ds = load_dataset(**config.dataset, **config.split)\n",
      "\n",
      "    train_ds.set_transform(preprocessor)\n",
      "    valid_ds.set_transform(preprocessor)\n",
      "\n",
      "    if add_valid_ds is not None:\n",
      "        add_preprocessor_class = find_class(\n",
      "            name=os.path.dirname(config.additional_preprocessor),\n",
      "            module_name='pipeline.data.preprocessors',\n",
      "        )\n",
      "        add_preprocessor_config = OmegaConf.load(\n",
      "            os.path.join(CONFIGS_DIR, f'preprocessor/{config.additional_preprocessor}.yaml'),\n",
      "        )\n",
      "        add_preprocessor = add_preprocessor_class(**add_preprocessor_config, tokenizer=tokenizer)\n",
      "        add_valid_ds.set_transform(add_preprocessor)\n",
      "\n",
      "    train_metrics = init_metrics(\n",
      "        loaded_config=config.metrics.train_metrics,\n",
      "        configs_dir=CONFIGS_DIR,\n",
      "        tokenizer=tokenizer)\n",
      "    valid_metrics = init_metrics(\n",
      "        loaded_config=config.metrics.valid_metrics,\n",
      "        configs_dir=CONFIGS_DIR,\n",
      "        tokenizer=tokenizer,\n",
      "    )\n",
      "\n",
      "    trainer = trainer_class(\n",
      "        **config.trainer,\n",
      "        model=model,\n",
      "        tokenizer=tokenizer,\n",
      "        train_ds=train_ds,\n",
      "        valid_ds=valid_ds,\n",
      "        add_valid_ds=add_valid_ds,\n",
      "        adapter=adapter,\n",
      "        checkpointer=checkpointer,\n",
      "        logger=logger,\n",
      "        train_metrics=train_metrics,\n",
      "        valid_metrics=valid_metrics)\n",
      "    trainer.train(verbose=True)\n",
      "\n",
      "    logger.message('Run successfully completed.')\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    main()\n",
      "<file_sep># ../incontext/blocks/block.py\n",
      "from incontext.data_structures import Chunk, Datapoint, File\n",
      "from incontext.repr_mixin import ReprMixin\n",
      "\n",
      "from abc import ABC, abstractmethod\n",
      "from typing import Sequence\n",
      "\n",
      "BlockArgs = Sequence[File] | Sequence[Chunk]\n",
      "\n",
      "\n",
      "class ComposerBlock(ABC, ReprMixin):\n",
      "    first_block_permit: bool = False\n",
      "    last_block_permit: bool = False\n",
      "\n",
      "    @property\n",
      "    @abstractmethod\n",
      "    def next_blocks(self) -> tuple[type, ...]:\n",
      "        raise NotImplementedError\n",
      "\n",
      "    def check_next_block(self, block) -> None:\n",
      "        if not isinstance(block, self.next_blocks):\n",
      "            raise ValueError(f'{type(block).__name__} cannot be used after {type(self).__name__}.')\n",
      "\n",
      "    @abstractmethod\n",
      "    def __call__(self, args: BlockArgs, datapoint: Datapoint) -> BlockArgs | str:\n",
      "        raise NotImplementedError\n",
      "<file_sep># ../incontext/composer/composer_base.py\n",
      "from incontext.blocks.file_preprocessing import NewlinePreprocessor\n",
      "from incontext.data_structures import (\n",
      "    BatchComposedDatapoint,\n",
      "    BatchDatapoint,\n",
      "    ComposedDatapoint,\n",
      "    Datapoint,\n",
      ")\n",
      "\n",
      "from abc import ABC, abstractmethod\n",
      "from typing import Any\n",
      "\n",
      "\n",
      "class ComposerBase(ABC):\n",
      "    def __init__(self,\n",
      "                 pre_context_prompt: str,\n",
      "                 post_context_prompt: str,\n",
      "                 path_comment_template: str,\n",
      "                 ) -> None:\n",
      "        self.pre_context_prompt = pre_context_prompt\n",
      "        self.post_context_prompt = post_context_prompt\n",
      "        self.path_comment_template = path_comment_template\n",
      "\n",
      "    def get_pre_context_prompt(self, datapoint: Datapoint) -> str:\n",
      "        return self.pre_context_prompt.format(datapoint.repo)\n",
      "\n",
      "    def get_post_context_prompt(self, _datapoint: Datapoint) -> str:\n",
      "        return self.post_context_prompt\n",
      "\n",
      "    @abstractmethod\n",
      "    def compose_context(self, datapoint: Datapoint) -> str:\n",
      "        raise NotImplementedError\n",
      "\n",
      "    def compose_completion(self, datapoint: Datapoint) -> str:\n",
      "        return self.path_comment_template.format(\n",
      "            filename=datapoint.completion_file['filename'],\n",
      "            content=NewlinePreprocessor.unify_newlines(datapoint.completion_file['content']),\n",
      "        )\n",
      "\n",
      "    def compose(self, datapoint: dict[str, Any]) -> ComposedDatapoint:\n",
      "        datapoint = Datapoint(\n",
      "            repo=datapoint['repo'],\n",
      "            completion_file=datapoint['completion_file'],\n",
      "            repo_snapshot=datapoint['repo_snapshot'],\n",
      "        )\n",
      "\n",
      "        return ComposedDatapoint(\n",
      "            pre_context_prompt=self.get_pre_context_prompt(datapoint),\n",
      "            composed_context=self.compose_context(datapoint) + self.get_post_context_prompt(datapoint),\n",
      "            composed_completion=self.compose_completion(datapoint),\n",
      "        )\n",
      "\n",
      "    def compose_batch(self, batch: BatchDatapoint) -> BatchComposedDatapoint:\n",
      "        batch_keys = batch.keys()\n",
      "        composed_batch_keys = BatchComposedDatapoint.__required_keys__\n",
      "        # transpose and compose\n",
      "        batch = [self.compose(dict(zip(batch_keys, data))) for data in zip(*batch.values())]\n",
      "        # transpose back\n",
      "        batch = {key: list(map(lambda x: x.get(key), batch)) for key in composed_batch_keys}\n",
      "        return batch\n",
      "<file_sep># ../incontext/blocks/context_postprocessing.py\n",
      "from incontext.blocks.block import ComposerBlock\n",
      "from incontext.data_structures import Datapoint\n",
      "\n",
      "import random\n",
      "from abc import ABC\n",
      "from typing import Type\n",
      "\n",
      "from transformers import AutoTokenizer\n",
      "\n",
      "\n",
      "class ContextPostprocessor(ComposerBlock, ABC):\n",
      "    last_block_permit = True\n",
      "\n",
      "    @property\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "        return ContextPostprocessor,\n",
      "\n",
      "\n",
      "class PartialMemoryPostprocessor(ContextPostprocessor):\n",
      "    def __init__(self, dropout: float, random_seed: int | None) -> None:\n",
      "        if not 0 <= dropout <= 1:\n",
      "            raise ValueError('dropout must be selected from the interval [0, 1]. '\n",
      "                             f'Got {dropout} instead.')\n",
      "        self.dropout = dropout\n",
      "        self.generator = random.Random(random_seed)\n",
      "\n",
      "    def __call__(self, context: str, _datapoint: Datapoint) -> str:\n",
      "        # dropping of path comments can occasionally happen\n",
      "        return '\\n'.join(line for line in context.split('\\n') if self.generator.random() >= self.dropout)\n",
      "\n",
      "\n",
      "class LineLengthPostprocessor(ContextPostprocessor):\n",
      "    def __init__(self, min_len: int, max_len: int) -> None:\n",
      "        self.min_len = min_len\n",
      "        self.max_len = max_len\n",
      "\n",
      "    def __call__(self, context: str, _datapoint: Datapoint) -> str:\n",
      "        return '\\n'.join(line for line in context.split('\\n') if self.min_len <= len(line) <= self.max_len)\n",
      "\n",
      "\n",
      "class LineStripPostprocessor(ContextPostprocessor):\n",
      "    def __call__(self, context: str, _datapoint: Datapoint) -> str:\n",
      "        return '\\n'.join(line.strip() for line in context.split('\\n'))\n",
      "\n",
      "\n",
      "class CompletionLeakPostprocessor(ContextPostprocessor):\n",
      "    def __init__(self, \n",
      "                 chars_lower_bound: int,\n",
      "                 context_size: int,\n",
      "                 num_segments: int,\n",
      "                 tokenizer_name: str,\n",
      "                 trust_remote_code: bool,\n",
      "                 random_seed: int | None,\n",
      "                 ) -> None:\n",
      "        self.chars_lower_bound = chars_lower_bound\n",
      "        self.context_size = context_size\n",
      "        self.num_segments = num_segments\n",
      "\n",
      "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
      "            pretrained_model_name_or_path=tokenizer_name,\n",
      "            trust_remote_code=trust_remote_code,\n",
      "        )\n",
      "        self.generator = random.Random(random_seed)\n",
      "\n",
      "    def _select_random_subsequences(self, segment_lens: list[int], num_context_lines: int) -> list[tuple[int, int]]:\n",
      "        available = [True] * num_context_lines\n",
      "        subsequences = list()\n",
      "\n",
      "        for length in segment_lens:\n",
      "            valid_starts = [\n",
      "                i for i in range(num_context_lines - length + 1)\n",
      "                if all(available[i:i + length])]\n",
      "\n",
      "            if not valid_starts:\n",
      "                subsequences.append((0, 0))\n",
      "                continue\n",
      "\n",
      "            start = self.generator.choice(valid_starts)\n",
      "            end = start + length\n",
      "\n",
      "            for i in range(start, end):\n",
      "                available[i] = False\n",
      "\n",
      "            subsequences.append((start, end))\n",
      "\n",
      "        return subsequences\n",
      "\n",
      "    def _leak_completion(self, context: str, completion: str) -> str:\n",
      "        completion_lines = [line + '\\n' for line in completion.rstrip().split('\\n')]\n",
      "\n",
      "        num_segments = min(len(completion_lines), self.num_segments)\n",
      "        breaks = sorted(self.generator.sample(range(len(completion_lines)), k=(num_segments - 1)))\n",
      "\n",
      "        segments = list()\n",
      "        for start_idx, end_idx in zip([0] + breaks, breaks + [len(completion_lines)]):\n",
      "            segments.append((start_idx, end_idx))\n",
      "        self.generator.shuffle(segments)\n",
      "\n",
      "        segment_lens = [end_idx - start_idx for start_idx, end_idx in segments]\n",
      "\n",
      "        context_lines = [line + '\\n' for line in context.rstrip().split('\\n')]\n",
      "\n",
      "        while len(context_lines) < sum(segment_lens):\n",
      "            segments.pop()\n",
      "            segment_lens.pop()\n",
      "        assert len(context_lines) >= sum(segment_lens)\n",
      "\n",
      "        replace_positions = self._select_random_subsequences(segment_lens, len(context_lines))\n",
      "\n",
      "        for (cmp_start, cmp_end), (ctx_start, ctx_end) in zip(segments, replace_positions):\n",
      "            if ctx_start >= ctx_end:\n",
      "                continue\n",
      "\n",
      "            for offset in range(cmp_end - cmp_start):\n",
      "                context_lines[ctx_start + offset] = completion_lines[cmp_start + offset]\n",
      "\n",
      "        return ''.join(context_lines)\n",
      "\n",
      "    def __call__(self, context: str, datapoint: Datapoint) -> str:\n",
      "        tokenized_context = self.tokenizer(\n",
      "            context[-self.chars_lower_bound:],\n",
      "            return_attention_mask=False,\n",
      "        ).input_ids[-self.context_size:]\n",
      "        num_required_chars = len(self.tokenizer.decode(tokenized_context))\n",
      "\n",
      "        visible_context = context[-num_required_chars:]\n",
      "        completion = datapoint.completion_file['content']\n",
      "        contaminated_context = self._leak_completion(visible_context, completion)\n",
      "\n",
      "        return contaminated_context\n",
      "\n",
      "\n",
      "# Hardcode to make init_from_config clearer\n",
      "class DseekCompletionLeakPostprocessor(CompletionLeakPostprocessor):\n",
      "    def __init__(self, *args, **kwargs) -> None:\n",
      "        super().__init__(*args, **kwargs,\n",
      "                         tokenizer_name='deepseek-ai/deepseek-coder-1.3b-base',\n",
      "                         trust_remote_code=True)\n",
      "\n",
      "\n",
      "# Hardcode to make init_from_config clearer\n",
      "class OCoderCompletionLeakPostprocessor(CompletionLeakPostprocessor):\n",
      "    def __init__(self, *args, **kwargs) -> None:\n",
      "        super().__init__(*args, **kwargs,\n",
      "                         tokenizer_name='infly/OpenCoder-1.5B-Base',\n",
      "                         trust_remote_code=True)\n",
      "\n",
      "\n",
      "class ReversedContextPostprocessor(ContextPostprocessor):\n",
      "    def __init__(self,\n",
      "                 chars_lower_bound: int,\n",
      "                 context_size: int,\n",
      "                 chunks_sep: str,\n",
      "                 tokenizer_name: str,\n",
      "                 trust_remote_code: bool,\n",
      "                 ) -> None:\n",
      "        self.chars_lower_bound = chars_lower_bound\n",
      "        self.context_size = context_size\n",
      "        self.chunks_sep = chunks_sep\n",
      "\n",
      "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
      "            pretrained_model_name_or_path=tokenizer_name,\n",
      "            trust_remote_code=trust_remote_code,\n",
      "        )\n",
      "\n",
      "    def __call__(self, context: str, datapoint: Datapoint) -> str:\n",
      "        completion = datapoint.completion_file['content']\n",
      "\n",
      "        tokenized_context = self.tokenizer(\n",
      "            (context + completion)[-self.chars_lower_bound:],\n",
      "            return_attention_mask=False,\n",
      "        ).input_ids[-self.context_size:]\n",
      "        num_required_chars = len(self.tokenizer.decode(tokenized_context)) - len(completion)\n",
      "\n",
      "        visible_context = context[-num_required_chars:]\n",
      "        reversed_context = self.chunks_sep.join(visible_context.split(self.chunks_sep)[::-1])\n",
      "\n",
      "        return reversed_context\n",
      "\n",
      "\n",
      "# Hardcode to make init_from_config clearer\n",
      "class OCoderReversedContextPostprocessor(ReversedContextPostprocessor):\n",
      "    def __init__(self, *args, **kwargs) -> None:\n",
      "        super().__init__(*args, **kwargs,\n",
      "                         tokenizer_name='infly/OpenCoder-1.5B-Base',\n",
      "                         trust_remote_code=True)\n",
      "\n",
      "\n",
      "class RandomTokensPostprocessor(ContextPostprocessor):\n",
      "    def __init__(self,\n",
      "                 context_size: int,\n",
      "                 tokenizer_name: str,\n",
      "                 trust_remote_code: bool,\n",
      "                 random_seed: int | None,\n",
      "                 ) -> None:\n",
      "        self.context_size = context_size\n",
      "\n",
      "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
      "            pretrained_model_name_or_path=tokenizer_name,\n",
      "            trust_remote_code=trust_remote_code,\n",
      "        )\n",
      "        self.generator = random.Random(random_seed)\n",
      "\n",
      "        special_token_ids = set(list(self.tokenizer.get_added_vocab().values()) + self.tokenizer.all_special_ids)\n",
      "        self.allowed_token_ids = list(set(range(len(self.tokenizer))).difference(special_token_ids))\n",
      "\n",
      "    def __call__(self, _context: str, _datapoint: Datapoint) -> str:\n",
      "        return self.tokenizer.decode(self.generator.choices(self.allowed_token_ids, k=self.context_size))\n",
      "\n",
      "\n",
      "# Hardcode to make init_from_config clearer\n",
      "class DseekRandomTokensPostprocessor(RandomTokensPostprocessor):\n",
      "    def __init__(self, *args, **kwargs) -> None:\n",
      "        super().__init__(*args, **kwargs,\n",
      "                         tokenizer_name='deepseek-ai/deepseek-coder-1.3b-base',\n",
      "                         trust_remote_code=True)\n",
      "\n",
      "\n",
      "# Hardcode to make init_from_config clearer\n",
      "class OCoderRandomTokensPostprocessor(RandomTokensPostprocessor):\n",
      "    def __init__(self, *args, **kwargs) -> None:\n",
      "        super().__init__(*args, **kwargs,\n",
      "                         tokenizer_name='infly/OpenCoder-1.5B-Base',\n",
      "                         trust_remote_code=True)\n",
      "<file_sep># ../incontext/blocks/file_chunking.py\n",
      "from incontext.blocks.block import ComposerBlock\n",
      "from incontext.blocks.file_preprocessing import NewlinePreprocessor\n",
      "from incontext.data_structures import Chunk, Datapoint, File\n",
      "\n",
      "import math\n",
      "from abc import ABC\n",
      "from enum import Enum\n",
      "from string import whitespace\n",
      "from typing import Callable, NamedTuple, Sequence, TypeVar, Type\n",
      "\n",
      "import tree_sitter\n",
      "import tree_sitter_python\n",
      "\n",
      "T = TypeVar('T')\n",
      "\n",
      "\n",
      "class FileChunker(ComposerBlock, ABC):\n",
      "    first_block_permit = True\n",
      "\n",
      "    @property\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "        from incontext.blocks.chunk_assembling import ChunkAssembler\n",
      "        from incontext.blocks.chunk_ranking import ChunkRanker\n",
      "        return ChunkRanker, ChunkAssembler\n",
      "\n",
      "\n",
      "class FileGrainedChunker(FileChunker):  # identity chunker\n",
      "    def __call__(self, files: Sequence[File], datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        chunks = list()\n",
      "        for file in files:\n",
      "            assert file.metadata['filename'] != datapoint.completion_file['filename']\n",
      "            chunks.append(Chunk(\n",
      "                content=file.content,\n",
      "                metadata=file.metadata,\n",
      "                file_ref=file,\n",
      "            ))\n",
      "\n",
      "        return chunks\n",
      "\n",
      "\n",
      "class CodeSegment(str, Enum):\n",
      "    COMMENT = 'comment_segment'\n",
      "    DOCSTRING = 'docstring_segment'\n",
      "    IMPORT = 'import_segment'\n",
      "    CODE = 'code_segment'\n",
      "    UNDEFINED = 'undefined_segment'\n",
      "\n",
      "    @classmethod\n",
      "    def from_node(cls: Type[T], node: tree_sitter.Node) -> T:\n",
      "        if 'comment' in node.type.lower():\n",
      "            return cls.COMMENT\n",
      "        elif node.type == 'string' and node.text.startswith(CodeSegmentGrainedChunker.DOCSTRING_PREFIX):\n",
      "            return cls.DOCSTRING\n",
      "        elif 'import' in node.type.lower():\n",
      "            return cls.IMPORT\n",
      "        elif node.child_count == 0:\n",
      "            return cls.CODE\n",
      "        else:\n",
      "            return cls.UNDEFINED\n",
      "\n",
      "\n",
      "class Segment(NamedTuple):\n",
      "    start_byte: int\n",
      "    type: CodeSegment\n",
      "\n",
      "\n",
      "class CodeSegmentGrainedChunker(FileChunker):\n",
      "    ENCODING = 'utf8'\n",
      "    DOCSTRING_PREFIX = (bytes(\"'''\", ENCODING), bytes('\"\"\"', ENCODING))\n",
      "\n",
      "    def __init__(self) -> None:\n",
      "        py_language = tree_sitter.Language(tree_sitter_python.language())\n",
      "        self.parser = tree_sitter.Parser(py_language)\n",
      "\n",
      "    @staticmethod\n",
      "    def dfs_segmentation(root_node: tree_sitter.Node) -> list[Segment]:\n",
      "        segments = list()\n",
      "        queue = [root_node]\n",
      "\n",
      "        while queue:\n",
      "            node = queue.pop()\n",
      "            segment_type = CodeSegment.from_node(node)\n",
      "\n",
      "            if segment_type != CodeSegment.UNDEFINED:\n",
      "                if len(segments) == 0 or segment_type != segments[-1].type:\n",
      "                    segments.append(Segment(node.start_byte, segment_type))\n",
      "            else:\n",
      "                queue.extend(reversed(node.children))\n",
      "\n",
      "        return segments\n",
      "\n",
      "    @staticmethod\n",
      "    def strip_lines(string: str, strip_func: Callable[[str], str]) -> str:\n",
      "        return '\\n'.join(map(strip_func, string.split('\\n')))\n",
      "\n",
      "    def __call__(self, files: Sequence[File], datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        chunks = list()\n",
      "\n",
      "        for file in files:\n",
      "            if not file.metadata['filename'].endswith('.py'):\n",
      "                chunks.append(Chunk(\n",
      "                    content=file.content,\n",
      "                    metadata=file.metadata | {'segment_type': CodeSegment.UNDEFINED},\n",
      "                    file_ref=file,\n",
      "                ))\n",
      "                continue\n",
      "\n",
      "            assert file.metadata['filename'] != datapoint.completion_file['filename']\n",
      "\n",
      "            bytecode = bytes(file.content, self.ENCODING)\n",
      "            tree = self.parser.parse(bytecode)\n",
      "            segments = self.dfs_segmentation(tree.root_node)\n",
      "\n",
      "            dummy_segment = Segment(len(bytecode), CodeSegment.UNDEFINED)\n",
      "            segments.append(dummy_segment)\n",
      "\n",
      "            comments_chunk = Chunk(\n",
      "                content='', metadata=file.metadata | {'segment_type': CodeSegment.COMMENT}, file_ref=file)\n",
      "            docstrings_chunk = Chunk(\n",
      "                content='', metadata=file.metadata | {'segment_type': CodeSegment.DOCSTRING}, file_ref=file)\n",
      "            imports_chunk = Chunk(\n",
      "                content='', metadata=file.metadata | {'segment_type': CodeSegment.IMPORT}, file_ref=file)\n",
      "            code_chunk = Chunk(\n",
      "                content='', metadata=file.metadata | {'segment_type': CodeSegment.CODE}, file_ref=file)\n",
      "            prev_edited_chunk = None\n",
      "\n",
      "            for i in range(len(segments) - 1):\n",
      "                start = segments[i].start_byte\n",
      "                end = segments[i + 1].start_byte\n",
      "                segment_str = bytecode[start:end].decode(self.ENCODING)\n",
      "                segment_type = segments[i].type\n",
      "\n",
      "                match segment_type:\n",
      "                    case CodeSegment.COMMENT:\n",
      "                        # inline comment newline fix\n",
      "                        if prev_edited_chunk is not None and not prev_edited_chunk.content.rstrip(\n",
      "                                whitespace.replace('\\n', '')).endswith('\\n'):\n",
      "                            prev_edited_chunk.content += '\\n' + segment_str.split('\\n')[-1]\n",
      "\n",
      "                        if segment_str.count('\\n') >= 2:\n",
      "                            comments_chunk.content += self.strip_lines(segment_str, str.strip)\n",
      "                            prev_edited_chunk = comments_chunk\n",
      "\n",
      "                    case CodeSegment.DOCSTRING:\n",
      "                        docstrings_chunk.content += self.strip_lines(segment_str, str.strip)\n",
      "                        prev_edited_chunk = docstrings_chunk\n",
      "\n",
      "                    case CodeSegment.IMPORT:\n",
      "                        imports_chunk.content += segment_str\n",
      "                        prev_edited_chunk = imports_chunk\n",
      "\n",
      "                    case CodeSegment.CODE:\n",
      "                        code_chunk.content += segment_str\n",
      "                        prev_edited_chunk = code_chunk\n",
      "\n",
      "                    case _:\n",
      "                        raise RuntimeError\n",
      "\n",
      "            for chunk in (comments_chunk, docstrings_chunk, imports_chunk, code_chunk):\n",
      "                if chunk.content.strip():\n",
      "                    chunk.content = self.strip_lines(chunk.content.rstrip(), str.rstrip)\n",
      "                    chunks.append(chunk)\n",
      "\n",
      "        return chunks\n",
      "\n",
      "\n",
      "class DocstringAndCommentOnlyChunker(CodeSegmentGrainedChunker):\n",
      "    def __call__(self, *args, **kwargs) -> Sequence[Chunk]:\n",
      "        return [chunk for chunk in super().__call__(*args, **kwargs) if\n",
      "                chunk.metadata['segment_type'] == CodeSegment.DOCSTRING or\n",
      "                chunk.metadata['segment_type'] == CodeSegment.COMMENT]\n",
      "\n",
      "\n",
      "class CodeOnlyChunker(CodeSegmentGrainedChunker):\n",
      "    def __call__(self, *args, **kwargs) -> Sequence[Chunk]:\n",
      "        return [chunk for chunk in super().__call__(*args, **kwargs)\n",
      "                if chunk.metadata['segment_type'] == CodeSegment.CODE]\n",
      "\n",
      "\n",
      "class FixedLineChunker(FileChunker):\n",
      "    def __init__(self, chunk_lines_size: int, overlap_lines_size: int) -> None:\n",
      "        if chunk_lines_size <= overlap_lines_size:\n",
      "            raise ValueError('chunk_lines_size must be greater than overlap_lines_size.')\n",
      "\n",
      "        self.chunk_lines_size = chunk_lines_size\n",
      "        self.overlap_lines_size = overlap_lines_size\n",
      "\n",
      "    def __call__(self, files: Sequence[File], datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        chunks = list()\n",
      "\n",
      "        for file in files:\n",
      "            assert file.metadata['filename'] != datapoint.completion_file['filename']\n",
      "\n",
      "            lines = file.content.split('\\n')\n",
      "            total_lines = len(lines)\n",
      "\n",
      "            stride = self.chunk_lines_size - self.overlap_lines_size\n",
      "            for i in range(total_lines, self.chunk_lines_size - 1, -stride):\n",
      "                start_idx = max(0, i - self.chunk_lines_size)\n",
      "                chunks.append(Chunk(\n",
      "                    content='\\n'.join(lines[start_idx:i]),\n",
      "                    metadata=file.metadata,\n",
      "                    file_ref=file\n",
      "                ))\n",
      "\n",
      "            if total_lines % stride != 0:\n",
      "                chunks.append(Chunk(\n",
      "                    content='\\n'.join(lines[:self.chunk_lines_size]),\n",
      "                    metadata=file.metadata,\n",
      "                    file_ref=file\n",
      "                ))\n",
      "\n",
      "        return chunks\n",
      "\n",
      "\n",
      "class CompletionDuplicationChunker(FileChunker):\n",
      "    def __init__(self, chars_lower_bound: int) -> None:\n",
      "        self.chars_lower_bound = chars_lower_bound\n",
      "\n",
      "    def __call__(self, _files: Sequence[File], datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        filename = datapoint.completion_file['filename']\n",
      "        content = NewlinePreprocessor.unify_newlines(datapoint.completion_file['content'])\n",
      "        num_repeats = math.ceil(self.chars_lower_bound / len(content))\n",
      "        \n",
      "        return [Chunk(\n",
      "                    content=content,\n",
      "                    metadata=dict(filename=filename),\n",
      "                    file_ref=File(\n",
      "                        content=content,\n",
      "                        metadata=dict(filename=filename),\n",
      "                    ))\n",
      "                for _ in range(num_repeats)]\n",
      "<file_sep># ../incontext/blocks/chunk_ranking.py\n",
      "from incontext.blocks.block import ComposerBlock\n",
      "from incontext.data_structures import Chunk, Datapoint\n",
      "\n",
      "import os\n",
      "import random\n",
      "import warnings\n",
      "from abc import ABC\n",
      "from typing import Sequence, Type\n",
      "\n",
      "import tree_sitter\n",
      "import tree_sitter_python\n",
      "\n",
      "\n",
      "class ChunkRanker(ComposerBlock, ABC):\n",
      "    @property\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "        from incontext.blocks.chunk_sorting import ChunkSorter\n",
      "        return ChunkRanker, ChunkSorter\n",
      "\n",
      "\n",
      "class NegativePathDistanceRanker(ChunkRanker):\n",
      "    @staticmethod\n",
      "    def _path_distance(path_from: str, path_to: str) -> int:\n",
      "        path_from = os.path.normpath(path_from)\n",
      "        path_to = os.path.normpath(path_to)\n",
      "\n",
      "        if path_from == path_to:\n",
      "            warnings.warn(f'Data leakage: the {path_from} completion file is contained in the repo snapshot.')\n",
      "\n",
      "        divided_path_from = path_from.split(os.path.sep)\n",
      "        divided_path_to = path_to.split(os.path.sep)\n",
      "\n",
      "        common_len = 0\n",
      "        for segment_from, segment_to in zip(divided_path_from, divided_path_to):\n",
      "            if segment_from == segment_to:\n",
      "                common_len += 1\n",
      "            else:\n",
      "                break\n",
      "\n",
      "        num_residuals_from = len(divided_path_from) - common_len - 1\n",
      "        num_residuals_to = len(divided_path_to) - common_len - 1\n",
      "\n",
      "        return num_residuals_from + num_residuals_to\n",
      "\n",
      "    def __call__(self, chunks: Sequence[Chunk], datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        path_to = datapoint.completion_file['filename']\n",
      "        for chunk in chunks:\n",
      "            dist = self._path_distance(chunk.file_ref.metadata['filename'], path_to)\n",
      "            chunk.rank.append(-dist)\n",
      "        return chunks\n",
      "\n",
      "\n",
      "class FileExtensionRanker(ChunkRanker):\n",
      "    def __init__(self, ordered_groups: list[list[str]]) -> None:\n",
      "        self.group_weights = {\n",
      "            extension: weight\n",
      "            for weight, group in enumerate(ordered_groups)\n",
      "            for extension in group\n",
      "        }\n",
      "\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        for chunk in chunks:\n",
      "            extension = '.' + chunk.file_ref.metadata['filename'].split('.')[-1]\n",
      "            chunk.rank.append(self.group_weights.get(extension, -1))\n",
      "        return chunks\n",
      "\n",
      "\n",
      "class FunctionCallRanker(ChunkRanker):\n",
      "    ENCODING = 'utf8'\n",
      "\n",
      "    def __init__(self, is_relative: bool) -> None:\n",
      "        self.is_relative = is_relative\n",
      "\n",
      "        py_language = tree_sitter.Language(tree_sitter_python.language())\n",
      "        self.parser = tree_sitter.Parser(py_language)\n",
      "\n",
      "    def dfs_count(self, node: tree_sitter.Node) -> int:\n",
      "        return (node.type == 'call') + sum(self.dfs_count(child) for child in node.children)\n",
      "\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        for chunk in chunks:\n",
      "            if chunk.file_ref.metadata['filename'].endswith('.py'):\n",
      "                bytecode = bytes(chunk.content, self.ENCODING)\n",
      "                tree = self.parser.parse(bytecode)\n",
      "                num_calls = self.dfs_count(tree.root_node)\n",
      "            else:\n",
      "                num_calls = 0\n",
      "\n",
      "            if self.is_relative:\n",
      "                num_calls /= len(chunk.content)\n",
      "\n",
      "            chunk.rank.append(num_calls)\n",
      "        return chunks\n",
      "\n",
      "\n",
      "class RandomRanker(ChunkRanker):\n",
      "    def __init__(self, random_seed: int | None) -> None:\n",
      "        self.generator = random.Random(random_seed)\n",
      "\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        ranks = list(range(len(chunks)))\n",
      "        self.generator.shuffle(ranks)\n",
      "        for rank, chunk in zip(ranks, chunks):\n",
      "            chunk.rank.append(rank)\n",
      "        return chunks\n",
      "\n",
      "\n",
      "class IoURanker(ChunkRanker):\n",
      "    def __init__(self, min_len: int) -> None:\n",
      "        self.min_len = min_len\n",
      "\n",
      "    def _get_lines(self, content: str) -> set[str]:\n",
      "        return {line for line in map(str.strip, content.split('\\n')) if len(line) >= self.min_len}\n",
      "\n",
      "    def __call__(self, chunks: Sequence[Chunk], datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        target_lines = self._get_lines(datapoint.completion_file['content'])\n",
      "        for chunk in chunks:\n",
      "            chunk_lines = self._get_lines(chunk.content)\n",
      "            iou_score = len(target_lines & chunk_lines) / len(target_lines | chunk_lines)\n",
      "            chunk.rank.append(iou_score)\n",
      "        return chunks\n",
      "<file_sep># ../incontext/composer/chained_composer.py\n",
      "from incontext.blocks.block import ComposerBlock\n",
      "from incontext.composer.composer_base import ComposerBase\n",
      "from incontext.data_structures import Datapoint, File\n",
      "from incontext.repr_mixin import ReprMixin\n",
      "\n",
      "from typing import Any, Sequence\n",
      "\n",
      "\n",
      "class UnsafeComposerChain:\n",
      "    def __init__(self, *blocks: ComposerBlock) -> None:\n",
      "        self.blocks = blocks\n",
      "\n",
      "    def __call__(self, datapoint: Datapoint) -> Any:\n",
      "        x = [\n",
      "            File(content=cnt, metadata={'filename': fn})\n",
      "            for fn, cnt in zip(*datapoint.repo_snapshot.values())\n",
      "        ]\n",
      "        for block in self.blocks:\n",
      "            x = block(x, datapoint)\n",
      "        return x\n",
      "\n",
      "\n",
      "class ComposerChain(UnsafeComposerChain):\n",
      "    def __init__(self, *blocks: ComposerBlock) -> None:\n",
      "        if not blocks:\n",
      "            raise ValueError('ComposerChain instance must contain at least one element.')\n",
      "        elif not blocks[0].first_block_permit:\n",
      "            raise ValueError(f'{type(blocks[0]).__name__} cannot start a chain of blocks.')\n",
      "        elif not blocks[-1].last_block_permit:\n",
      "            raise ValueError(f'{type(blocks[-1]).__name__} cannot end a chain of blocks.')\n",
      "\n",
      "        for block, next_block in zip(blocks[:-1], blocks[1:]):\n",
      "            block.check_next_block(next_block)\n",
      "\n",
      "        super().__init__(*blocks)\n",
      "\n",
      "\n",
      "class ChainedComposer(ComposerBase, ComposerChain, ReprMixin):\n",
      "    def __init__(self, blocks: Sequence[ComposerBlock], *args, **kwargs) -> None:\n",
      "        ComposerBase.__init__(self, *args, **kwargs)\n",
      "        ComposerChain.__init__(self, *blocks)\n",
      "\n",
      "    def compose_context(self, datapoint: Datapoint) -> str:\n",
      "        return self.__call__(datapoint)\n",
      "<file_sep># ../incontext/blocks/chunk_sorting.py\n",
      "from incontext.blocks.block import ComposerBlock\n",
      "from incontext.data_structures import Chunk, Datapoint\n",
      "\n",
      "from abc import ABC\n",
      "from typing import Sequence, Type\n",
      "\n",
      "\n",
      "class ChunkSorter(ComposerBlock, ABC):\n",
      "    @property\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "        from incontext.blocks.chunk_assembling import ChunkAssembler\n",
      "        return ChunkSorter, ChunkAssembler\n",
      "\n",
      "\n",
      "class LexicographicSorter(ChunkSorter):\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        return sorted(chunks, key=lambda c: c.rank)\n",
      "\n",
      "\n",
      "class ReverseLexicographicSorter(ChunkSorter):\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        return sorted(chunks, key=lambda c: c.rank, reverse=True)\n",
      "\n",
      "\n",
      "class MixedSorter(ChunkSorter):\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]:\n",
      "        sorted_chunks = list()\n",
      "        num_rankers = len(next(iter(chunks)).rank)\n",
      "        i = 0\n",
      "\n",
      "        for _ in range(len(chunks)):\n",
      "            chunk = max(chunks, key=lambda x: x.rank[i])\n",
      "            sorted_chunks.append(chunk)\n",
      "            for j in range(num_rankers):\n",
      "                chunk.rank[j] = -float('inf')\n",
      "            i = (i + 1) % num_rankers\n",
      "\n",
      "        return sorted_chunks[::-1]\n",
      "<file_sep># ../incontext/blocks/chunk_assembling.py\n",
      "from incontext.blocks.block import ComposerBlock\n",
      "from incontext.data_structures import Chunk, Datapoint\n",
      "\n",
      "from abc import ABC\n",
      "from typing import Sequence, Type\n",
      "\n",
      "\n",
      "class ChunkAssembler(ComposerBlock, ABC):\n",
      "    last_block_permit = True\n",
      "\n",
      "    @property\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "        from incontext.blocks.context_postprocessing import ContextPostprocessor\n",
      "        return ContextPostprocessor,\n",
      "\n",
      "\n",
      "class JoiningAssembler(ChunkAssembler):\n",
      "    def __init__(self, chunks_sep: str) -> None:\n",
      "        self.chunks_sep = chunks_sep\n",
      "\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> str:\n",
      "        return self.chunks_sep.join(chunk.content for chunk in chunks)\n",
      "\n",
      "\n",
      "class PathCommentAssembler(JoiningAssembler):\n",
      "    def __init__(self, chunks_sep: str, path_comment_template: str) -> None:\n",
      "        super().__init__(chunks_sep)\n",
      "        self.path_comment_template = path_comment_template\n",
      "\n",
      "    def __call__(self, chunks: Sequence[Chunk], datapoint: Datapoint) -> str:\n",
      "        for chunk in chunks:\n",
      "            chunk.content = self.path_comment_template.format(\n",
      "                filename=chunk.file_ref.metadata['filename'], content=chunk.content)\n",
      "        return super().__call__(chunks, datapoint)\n",
      "<file_sep># ../incontext/blocks/file_preprocessing.py\n",
      "from incontext.blocks.block import ComposerBlock\n",
      "from incontext.data_structures import Datapoint, File\n",
      "\n",
      "from abc import ABC\n",
      "from typing import Sequence, Type\n",
      "\n",
      "import tree_sitter\n",
      "import tree_sitter_python\n",
      "import warnings\n",
      "\n",
      "\n",
      "class FilePreprocessor(ComposerBlock, ABC):\n",
      "    first_block_permit = True\n",
      "\n",
      "    @property\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "        from incontext.blocks.file_chunking import FileChunker\n",
      "        from incontext.blocks.file_filtering import FileFilter\n",
      "        return FileFilter, FilePreprocessor, FileChunker\n",
      "\n",
      "\n",
      "class EmptyLinesRemovalPreprocessor(FilePreprocessor):\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "        for file in files:\n",
      "            file.content = '\\n'.join(line for line in file.content.split('\\n') if line.strip())\n",
      "        return files\n",
      "\n",
      "\n",
      "class NewlinePreprocessor(FilePreprocessor):\n",
      "    @staticmethod\n",
      "    def unify_newlines(string: str) -> str:\n",
      "        return '\\n'.join(string.rstrip().splitlines()) + '\\n'\n",
      "\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "        for file in files:\n",
      "            file.content = self.unify_newlines(file.content)\n",
      "        return files\n",
      "\n",
      "\n",
      "class DeclarationOnlyPreprocessor(FilePreprocessor):\n",
      "    ENCODING = 'utf8'\n",
      "\n",
      "    def __init__(self) -> None:\n",
      "        py_language = tree_sitter.Language(tree_sitter_python.language())\n",
      "        self.parser = tree_sitter.Parser(py_language)\n",
      "\n",
      "    def __call__(self, files: Sequence[File], datapoint: Datapoint) -> Sequence[File]:\n",
      "        for file in files:\n",
      "            if not file.metadata['filename'].endswith('.py'):\n",
      "                continue\n",
      "\n",
      "            bytecode = bytes(file.content, self.ENCODING)\n",
      "            queue = [self.parser.parse(bytecode).root_node]\n",
      "            declarations = list()\n",
      "\n",
      "            while queue:\n",
      "                node = queue.pop()\n",
      "                queue.extend(reversed(node.children))\n",
      "\n",
      "                if node.type not in ('function_definition', 'class_definition'):\n",
      "                    continue\n",
      "\n",
      "                start = bytecode[:node.start_byte].rfind(b'\\n') + 1\n",
      "                for child in node.children:\n",
      "                    if child.type == ':':\n",
      "                        end = child.end_byte\n",
      "                        break\n",
      "                else:\n",
      "                    warnings.warn(f'A corrupted {file.metadata[\"filename\"]} file structure '\n",
      "                                  f'has been detected in the {datapoint.repo} repository.')\n",
      "                    end = node.end_byte\n",
      "\n",
      "                declaration = bytecode[start:end]\n",
      "                declaration = declaration.decode('utf8') + ' ...'\n",
      "                declarations.append(declaration)\n",
      "\n",
      "            file.content = '\\n'.join(declarations)\n",
      "        return files\n",
      "<file_sep># ../incontext/blocks/file_filtering.py\n",
      "from incontext.blocks.block import ComposerBlock\n",
      "from incontext.data_structures import Datapoint, File\n",
      "\n",
      "from abc import ABC\n",
      "from typing import Sequence, Type\n",
      "\n",
      "\n",
      "class FileFilter(ComposerBlock, ABC):\n",
      "    first_block_permit = True\n",
      "\n",
      "    @property\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]:\n",
      "        from incontext.blocks.file_chunking import FileChunker\n",
      "        from incontext.blocks.file_preprocessing import FilePreprocessor\n",
      "        return FileFilter, FilePreprocessor, FileChunker\n",
      "\n",
      "\n",
      "class NullFileFilter(FileFilter):\n",
      "    def __call__(self, *_args, **_kwargs) -> Sequence[File]:\n",
      "        return []\n",
      "\n",
      "\n",
      "class InclusiveFileExtensionFilter(FileFilter):\n",
      "    def __init__(self, whitelist: list[str]) -> None:\n",
      "        self.whitelist = tuple(whitelist)\n",
      "\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "        return [file for file in files if file.metadata['filename'].endswith(self.whitelist)]\n",
      "\n",
      "\n",
      "class ExclusiveFileExtensionFilter(FileFilter):\n",
      "    def __init__(self, blacklist: list[str]) -> None:\n",
      "        self.blacklist = tuple(blacklist)\n",
      "\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "        return [file for file in files if not file.metadata['filename'].endswith(self.blacklist)]\n",
      "\n",
      "\n",
      "class EmptyFileFilter(FileFilter):\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "        return [file for file in files if file.content.strip()]\n",
      "\n",
      "\n",
      "class FileLengthFilter(FileFilter):\n",
      "    def __init__(self, min_len: int, max_len: int) -> None:\n",
      "        self.min_len = min_len\n",
      "        self.max_len = max_len\n",
      "\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]:\n",
      "        return [file for file in files if self.min_len <= len(file.content) <= self.max_len]\n",
      "<file_sep># ../incontext/repr_mixin.py\n",
      "class ReprMixin:\n",
      "    _init_args = None\n",
      "    _init_kwargs = None\n",
      "\n",
      "    def __init_subclass__(cls, **kwargs) -> None:\n",
      "        super().__init_subclass__(**kwargs)\n",
      "        original_init = cls.__init__\n",
      "\n",
      "        def wrapped_init(self, *init_args, **init_kwargs) -> None:\n",
      "            if cls == type(self):\n",
      "                self._init_args = init_args\n",
      "                self._init_kwargs = init_kwargs\n",
      "            original_init(self, *init_args, **init_kwargs)\n",
      "\n",
      "        cls.__init__ = wrapped_init\n",
      "\n",
      "    def __repr__(self) -> str:\n",
      "        args_str = ', '.join(\n",
      "            [\n",
      "                f\"'{arg}'\" if isinstance(arg, str) else repr(arg)\n",
      "                for arg in self._init_args\n",
      "            ] + [\n",
      "                f\"{key}='{value}'\" if isinstance(value, str) else f'{key}={value!r}'\n",
      "                for key, value in self._init_kwargs.items()\n",
      "            ])\n",
      "        return f'{type(self).__name__}({args_str})'\n",
      "<file_sep># ../incontext/data_structures.py\n",
      "from dataclasses import dataclass, field\n",
      "from typing import Any, TypedDict\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class File:\n",
      "    content: str\n",
      "    metadata: dict[str, Any]\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class Chunk:\n",
      "    content: str\n",
      "    metadata: dict[str, Any]\n",
      "    file_ref: File\n",
      "    rank: list = field(default_factory=list)  # of comparable elements\n",
      "\n",
      "\n",
      "class CompletionFile(TypedDict):\n",
      "    filename: str\n",
      "    content: str\n",
      "\n",
      "\n",
      "class RepoSnapshot(TypedDict):\n",
      "    filename: list[str]\n",
      "    content: list[str]\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class Datapoint:\n",
      "    repo: str\n",
      "    completion_file: CompletionFile\n",
      "    repo_snapshot: RepoSnapshot\n",
      "\n",
      "\n",
      "class BatchDatapoint(TypedDict):\n",
      "    repo: list[str]\n",
      "    completion_file: list[CompletionFile]\n",
      "    repo_snapshot: list[RepoSnapshot]\n",
      "\n",
      "\n",
      "class ComposedDatapoint(TypedDict):\n",
      "    pre_context_prompt: str\n",
      "    composed_context: str\n",
      "    composed_completion: str\n",
      "\n",
      "\n",
      "class BatchComposedDatapoint(TypedDict):\n",
      "    pre_context_prompt: list[str]\n",
      "    composed_context: list[str]\n",
      "    composed_completion: list[str]\n",
      "<file_sep># ../incontext/init_from_config.py\n",
      "from incontext.composer.chained_composer import ChainedComposer\n",
      "\n",
      "import os\n",
      "from typing import Callable\n",
      "\n",
      "import yaml\n",
      "from omegaconf import OmegaConf\n",
      "\n",
      "\n",
      "def find_class(name: str, module_name: str, normalization_func: Callable[[str], str] | None = None) -> type:\n",
      "    module = __import__(module_name, fromlist=['*'])\n",
      "    if normalization_func is None:\n",
      "        normalized_name = name.replace('_', '')\n",
      "    else:\n",
      "        normalized_name = normalization_func(name)\n",
      "\n",
      "    for attr_name in dir(module):\n",
      "        if attr_name.lower() == normalized_name.lower():\n",
      "            return getattr(module, attr_name)\n",
      "\n",
      "    raise ValueError('Could not find class matching.')\n",
      "\n",
      "\n",
      "def init_from_config(path_to_config: str) -> ChainedComposer:\n",
      "    config_dir = os.path.dirname(path_to_config)\n",
      "    blocks_dir = os.path.join(config_dir, 'blocks')\n",
      "\n",
      "    config = OmegaConf.load(path_to_config)\n",
      "    formatted_config = dict(\n",
      "        pre_context_prompt=config.pre_context_prompt,\n",
      "        post_context_prompt=config.post_context_prompt,\n",
      "        path_comment_template=config.path_comment_template,\n",
      "        blocks=list(),\n",
      "    )\n",
      "\n",
      "    for path in config.block_configs:\n",
      "        full_path = os.path.join(blocks_dir, path)\n",
      "        block_name = os.path.basename(os.path.dirname(path))\n",
      "\n",
      "        with open(full_path) as stream:\n",
      "            block_config = yaml.safe_load(stream) or dict()\n",
      "\n",
      "        block = find_class(block_name, 'incontext')(**block_config)\n",
      "        formatted_config['blocks'].append(block)\n",
      "\n",
      "    composer = ChainedComposer(**formatted_config)\n",
      "    return composer\n",
      "<file_sep># ../incontext/__main__.py\n",
      "from incontext.init_from_config import init_from_config\n",
      "\n",
      "\n",
      "def main() -> None:\n",
      "    pass  # TODO: script for dataset composition\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    main()\n",
      "<file_sep>\n"
     ]
    }
   ],
   "source": [
    "composed_sample = composer.compose(toy_sample)\n",
    "print(composed_sample['composed_context'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47e7e39-4175-4098-b891-33753c784f13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Declaration `.py` Composer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4d3b12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ChainedComposer(pre_context_prompt='<repo_name>{}\\n<file_sep>', post_context_prompt='<file_sep>', path_comment_template='# {filename}\\n{content}', blocks=[EmptyFileFilter(), InclusiveFileExtensionFilter(whitelist=['.py']), NewlinePreprocessor(), DeclarationOnlyPreprocessor(), FileGrainedChunker(), NegativePathDistanceRanker(), IoURanker(min_len=5), LexicographicSorter(), PathCommentAssembler(chunks_sep='<file_sep>', path_comment_template='# {filename}\\n{content}')])\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize from config file\n",
    "composer = init_from_config('../configs/composer/declarations.yaml')\n",
    "repr(composer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d423e1e3-650f-4ca8-aad1-96b1171722a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ../pipeline/trainers/utils/schedulers.py\n",
      "def get_lr_from_cosine_scheduler_with_linear_warmup(iter_num: int,\n",
      "                                                    min_lr: float,\n",
      "                                                    max_lr: float,\n",
      "                                                    warmup_iters: int,\n",
      "                                                    lr_decay_iters: int,\n",
      "                                                    ) -> float: ...<file_sep># ../pipeline/trainers/utils/fused_sampler.py\n",
      "class FusedSampler(Sampler[int]): ...\n",
      "    def __init__(self,\n",
      "                 start_sample_idx: int,\n",
      "                 end_sample_idx: int,\n",
      "                 dataset_length: int,\n",
      "                 generator: torch.Generator | None = None,\n",
      "                 ) -> None: ...\n",
      "    def __iter__(self) -> Iterator[int]: ...\n",
      "    def __len__(self) -> int: ...<file_sep># ../pipeline/model/adapters/adapter_base.py\n",
      "class AdapterBase(ABC): ...\n",
      "    def __init__(self, model_name: str, params_pattern: str | None) -> None: ...\n",
      "    def get_trainable_parameters(self, model: nn.Module) -> Iterable[torch.Tensor]: ...\n",
      "    def init_optimizer(self, model: nn.Module, **optim_kwargs) -> torch.optim.AdamW: ...\n",
      "    def get_args_kwargs(self,\n",
      "                        input_ids: torch.Tensor,\n",
      "                        target_ids: torch.Tensor,\n",
      "                        loss_mask: torch.Tensor,\n",
      "                        completion_mask: torch.Tensor,\n",
      "                        input_attn_mask: torch.Tensor,\n",
      "                        target_attn_mask: torch.Tensor,\n",
      "                        ) -> tuple[tuple[Any], dict[str, Any]]: ...\n",
      "    def adapt(self, model: nn.Module) -> nn.Module: ...<file_sep># ../pipeline/model/adapters/identity_adapter.py\n",
      "class IdentityAdapter(AdapterBase): ...\n",
      "    def get_args_kwargs(self,\n",
      "                        input_ids: torch.Tensor,\n",
      "                        _target_ids: torch.Tensor,\n",
      "                        _loss_mask: torch.Tensor,\n",
      "                        _completion_mask: torch.Tensor,\n",
      "                        input_attn_mask: torch.Tensor,\n",
      "                        _target_attn_mask: torch.Tensor,\n",
      "                        ) -> tuple[tuple[Any], dict[str, Any]]: ...\n",
      "    def adapt(self, model: nn.Module) -> nn.Module: ...<file_sep># ../pipeline/model/adapters/__init__.py\n",
      "<file_sep># ../pipeline/outputs/loggers/local_logger.py\n",
      "class JsonFormatter(logging.Formatter): ...\n",
      "    def format(self, record: logging.LogRecord) -> str: ...\n",
      "class JsonHandler(logging.FileHandler): ...\n",
      "    def emit(self, record: logging.LogRecord) -> None: ...\n",
      "    def close(self) -> None: ...\n",
      "class LocalLogger(LoggerBase): ...\n",
      "    def __init__(self,\n",
      "                 train_csv: str,\n",
      "                 valid_csv: str,\n",
      "                 stdout_file: str,\n",
      "                 stderr_file: str,\n",
      "                 directory: str,\n",
      "                 **_kwargs,\n",
      "                 ) -> None: ...\n",
      "    def write_metrics_to_csv(metrics: dict[StatisticName, StatisticValue], path: str) -> None: ...\n",
      "    def log(self, metrics: Log) -> Log: ...\n",
      "    def message(self, message: Message) -> Message: ...\n",
      "    def warning_handler(self, message: Warning, category: type, path: str, lineno: int, *_kwargs) -> None: ...\n",
      "    def exception_handler(self, exc_type: type, exc_value: Exception, exc_traceback: TracebackType) -> NoReturn: ...<file_sep># ../pipeline/outputs/loggers/logger_base.py\n",
      "class Log(TypedDict): ...\n",
      "class LoggerBase(ABC): ...\n",
      "    def __new__(cls: Type[T], *args, **kwargs) -> T: ...\n",
      "    def log(self, metrics: Log) -> Log: ...\n",
      "    def message(self, message: Message) -> Message: ...<file_sep># ../pipeline/outputs/loggers/wandb_logger.py\n",
      "class WandbLogger(LocalLogger): ...\n",
      "    def __init__(self,\n",
      "                 train_csv: str,\n",
      "                 valid_csv: str,\n",
      "                 stdout_file: str,\n",
      "                 stderr_file: str,\n",
      "                 directory: str,\n",
      "                 **wandb_init_kwargs,\n",
      "                 ) -> None: ...\n",
      "    def log(self, metrics: Log) -> Log: ...<file_sep># ../pipeline/outputs/loggers/dummy_logger.py\n",
      "class DummyLogger(LoggerBase): ...\n",
      "    def __init__(self, *_args, **_kwargs) -> None: ...\n",
      "    def log(self, metrics: Log) -> Log: ...\n",
      "    def message(self, message: Message) -> Message: ...<file_sep># ../pipeline/outputs/loggers/__init__.py\n",
      "<file_sep># ../pipeline/outputs/checkpointers/top_k_checkpointer.py\n",
      "class TopKCheckpointManager(CheckpointManager): ...\n",
      "    def __init__(self, max_checkpoints_num: int, *args, **kwargs) -> None: ...\n",
      "    def save_checkpoint(self, checkpoint: Checkpoint) -> None: ...<file_sep># ../pipeline/outputs/checkpointers/checkpointer.py\n",
      "class CheckpointManager: ...\n",
      "    def __init__(self,\n",
      "                 main_metric: StatisticName,\n",
      "                 directory: str,\n",
      "                 checkpoint_directory_template: str = '{iteration_number:04d}',\n",
      "                 model_subdirectory: str = 'model',\n",
      "                 optim_state_filename: str = 'optim.pt',\n",
      "                 metrics_filename: str = 'metrics.json',  # should be .json\n",
      "                 ) -> None: ...\n",
      "    def load_metrics(self, checkpoint_dir: str) -> Log: ...\n",
      "    def get_checkpoint_score(self, checkpoint_dir: str) -> StatisticValue: ...\n",
      "    def save_checkpoint(self, checkpoint: Checkpoint) -> None: ...<file_sep># ../pipeline/outputs/checkpointers/checkpoint.py\n",
      "class Checkpoint: ...<file_sep># ../pipeline/outputs/checkpointers/__init__.py\n",
      "<file_sep># ../pipeline/outputs/metrics/top_k_accuracy.py\n",
      "class TopKAccuracy(MaskBasedMetric): ...\n",
      "    def __init__(self, k: int, *args, **kwargs) -> None: ...\n",
      "    def name(self) -> StatisticName: ...\n",
      "    def micro_batch_update(self,\n",
      "                           model_output: CausalLMOutputWithPast,\n",
      "                           target_ids: torch.Tensor,\n",
      "                           **kwargs,\n",
      "                           ) -> None: ...\n",
      "    def batch_commit(self, **_kwargs) -> StatisticValue: ...<file_sep># ../pipeline/outputs/metrics/exact_match.py\n",
      "class ExactMatch(MaskBasedMetric): ...\n",
      "    def __init__(self, tokenizer: PreTrainedTokenizerBase, min_tokens: int, *args, **kwargs) -> None: ...\n",
      "    def micro_batch_update(self,\n",
      "                           model_output: CausalLMOutputWithPast,\n",
      "                           target_ids: torch.Tensor,\n",
      "                           **kwargs,\n",
      "                           ) -> None: ...\n",
      "    def batch_commit(self, **_kwargs) -> StatisticValue: ...<file_sep># ../pipeline/outputs/metrics/cross_entropy.py\n",
      "class CrossEntropy(MaskBasedMetric): ...\n",
      "    def __init__(self, *args, **kwargs) -> None: ...\n",
      "    def micro_batch_update(self, loss_per_token: torch.Tensor, **kwargs) -> None: ...\n",
      "    def batch_commit(self, **_kwargs) -> StatisticValue: ...<file_sep># ../pipeline/outputs/metrics/statistic_base.py\n",
      "class StatisticBase(ABC): ...\n",
      "    def name(self) -> StatisticName: ...\n",
      "    def __repr__(self) -> str: ...\n",
      "    def micro_batch_update(self, **kwargs) -> None: ...\n",
      "    def batch_commit(self, **kwargs) -> StatisticValue: ...\n",
      "class LazyStatistic(StatisticBase): ...\n",
      "    def __init__(self, statistic_name: StatisticName) -> None: ...\n",
      "    def name(self) -> StatisticName: ...\n",
      "    def micro_batch_update(self, **kwargs) -> None: ...\n",
      "    def batch_commit(self, **_kwargs) -> StatisticValue: ...<file_sep># ../pipeline/outputs/metrics/metric_base.py\n",
      "class OptimizationMode(str, Enum): ...\n",
      "class MetricBase(StatisticBase, ABC): ...\n",
      "    def mode(self) -> OptimizationMode: ...\n",
      "class MaskType(str, Enum): ...\n",
      "class MaskBasedMetric(MetricBase, ABC): ...\n",
      "    def __init__(self, mask_type: MaskType) -> None: ...\n",
      "    def name(self) -> StatisticName: ...\n",
      "    def get_mask(self, **kwargs) -> torch.Tensor: ...<file_sep># ../pipeline/outputs/metrics/counters.py\n",
      "class EpochCounter(MetricBase): ...\n",
      "    def __new__(cls: Type[T], *args, **kwargs) -> T: ...\n",
      "    def __init__(self) -> None: ...\n",
      "    def name(self) -> StatisticName: ...\n",
      "    def micro_batch_update(self, input_ids: torch.Tensor, trainer: UniversalTrainer, **_kwargs) -> None: ...\n",
      "    def batch_commit(self, **_kwargs) -> StatisticValue: ...\n",
      "class TokenCounter(MaskBasedMetric): ...\n",
      "    def __init__(self, *args, **kwargs) -> None: ...\n",
      "    def name(self) -> StatisticName: ...\n",
      "    def micro_batch_update(self, **kwargs) -> None: ...\n",
      "    def batch_commit(self, **_kwargs) -> StatisticValue: ...<file_sep># ../pipeline/outputs/metrics/__init__.py\n",
      "def find_metric_class(metric_name: str) -> type: ...\n",
      "def init_metrics(loaded_config: Iterable[StatisticName],\n",
      "                 configs_dir: str,\n",
      "                 tokenizer: PreTrainedTokenizerBase,\n",
      "                 ) -> list[StatisticBase]: ...<file_sep># ../pipeline/data/preprocessors/lm_preprocessor.py\n",
      "class LMPreprocessor(CompletionLossPreprocessor): ...\n",
      "    def get_loss_mask(self,\n",
      "                      _tokenized_completions: BatchEncoding,\n",
      "                      target_attn_mask: torch.Tensor,\n",
      "                      **_kwargs,\n",
      "                      ) -> torch.Tensor: ...<file_sep># ../pipeline/data/preprocessors/completion_loss_preprocessor.py\n",
      "class CompletionLossPreprocessor(AmortizedPreprocessorBase): ...\n",
      "    def __init__(self,\n",
      "                 tokenizer: PreTrainedTokenizerBase,\n",
      "                 max_seq_len: int,\n",
      "                 context_tokens: int,\n",
      "                 max_completion_len: int,\n",
      "                 loss_ratio: float,\n",
      "                 num_chars_per_token: int,\n",
      "                 use_sep_token: bool,  # appended to the context\n",
      "                 padding: bool,\n",
      "                 verbose: bool = True,\n",
      "                 ) -> None: ...\n",
      "    def tokenize_pre_context_prompt(self, prompts: list[str]) -> BatchEncoding: ...\n",
      "    def tokenize_composed_completion(self, completions: list[str]) -> BatchEncoding: ...\n",
      "    def tokenize_composed_context(self, contexts: list[str]) -> BatchEncoding: ...\n",
      "    def calc_lens(self,\n",
      "                  prompt: list[int],\n",
      "                  context: list[int],\n",
      "                  completion: list[int],\n",
      "                  ) -> tuple[int, int, int]: ...\n",
      "    def _get_partial_completion_mask(tokenized_completions: BatchEncoding,\n",
      "                                     target_attn_mask: torch.Tensor,\n",
      "                                     ratio: float,\n",
      "                                     ) -> torch.Tensor: ...\n",
      "    def get_loss_mask(self, *args, **kwargs) -> torch.Tensor: ...\n",
      "    def get_completion_mask(self, *args, **kwargs) -> torch.Tensor: ...\n",
      "    def __call__(self, batch: BatchComposedDatapoint) -> PreprocessedBatch: ...<file_sep># ../pipeline/data/preprocessors/preprocessor_base.py\n",
      "class PreprocessedBatch(TypedDict): ...\n",
      "class PreprocessorBase(ABC): ...\n",
      "    def get_loss_mask(self, *args, **kwargs) -> torch.Tensor: ...\n",
      "    def calc_offset_mapping(self, seq_ids: list[int]) -> list[tuple[int, int]]: ...\n",
      "    def get_completion_mask(self, *args, **kwargs) -> torch.Tensor: ...\n",
      "    def __call__(self, batch: BatchComposedDatapoint) -> PreprocessedBatch: ...\n",
      "class AmortizedPreprocessorBase(PreprocessorBase, ABC): ...\n",
      "    def __init__(self, num_chars_per_token: int, verbose: bool) -> None: ...\n",
      "    def _inc_num_chars_per_token(self) -> None: ...<file_sep># ../pipeline/data/preprocessors/__init__.py\n",
      "<file_sep># ../pipeline/trainers/universal_trainer.py\n",
      "class UniversalTrainer(TrainerBase): ...\n",
      "    def __init__(self,\n",
      "                 model: nn.Module,\n",
      "                 tokenizer: PreTrainedTokenizerBase,\n",
      "                 train_ds: Dataset,\n",
      "                 valid_ds: Dataset | None,\n",
      "                 add_valid_ds: Dataset | None,\n",
      "                 # auxiliary objects\n",
      "                 adapter: AdapterBase,\n",
      "                 checkpointer: CheckpointManager,\n",
      "                 logger: LoggerBase,\n",
      "                 # iteration parameters\n",
      "                 max_iters: int,\n",
      "                 valid_freq: int | None,\n",
      "                 checkpointing_freq: int | None,\n",
      "                 gradient_accumulation_steps: int,\n",
      "                 micro_batch_size: int,\n",
      "                 # optimizer\n",
      "                 learning_rate: float,\n",
      "                 beta_1: float,\n",
      "                 beta_2: float,\n",
      "                 weight_decay: float,\n",
      "                 max_grad_norm: float,\n",
      "                 # scheduler\n",
      "                 warmup_iters: int | None,\n",
      "                 lr_decay_iters: int | None,\n",
      "                 min_lr: float | None,\n",
      "                 # metrics\n",
      "                 train_metrics: list[StatisticBase],\n",
      "                 valid_metrics: list[StatisticBase],\n",
      "                 # DataLoader\n",
      "                 shuffle: bool,\n",
      "                 drop_last: bool,\n",
      "                 num_workers: int,\n",
      "                 prefetch_factor: int,\n",
      "                 random_seed: int | None,\n",
      "                 # Floating point\n",
      "                 fp32_matmul_precision: Literal['highest', 'high', 'medium'],\n",
      "                 ) -> None: ...\n",
      "    def validate(self, valid_dl: DataLoader | None, verbose: bool = True) -> dict[StatisticName, StatisticValue]: ...\n",
      "    def train(self, verbose: bool = True) -> None: ...<file_sep># ../pipeline/trainers/trainer_base.py\n",
      "class TrainerBase(ABC): ...\n",
      "    def validate(self, *args, **kwargs) -> dict[StatisticName, StatisticValue]: ...\n",
      "    def train(self, *args, **kwargs) -> None: ...<file_sep># ../pipeline/trainers/__init__.py\n",
      "<file_sep># ../pipeline/model/__init__.py\n",
      "class AttentionImplementation(str, Enum): ...\n",
      "def init_tokenizer(tokenizer_name: str, trust_remote_code: bool, **_kwargs) -> PreTrainedTokenizerBase: ...\n",
      "def get_optimal_attn(model_name: str, device: torch.device, dtype: torch.dtype) -> AttentionImplementation: ...\n",
      "def init_model(model_name: str,\n",
      "               trust_remote_code: bool,\n",
      "               use_cache: bool = False,\n",
      "               device: str | None = None,\n",
      "               dtype: str | None = None,\n",
      "               attn_implementation: AttentionImplementation | None = None,\n",
      "               compile: bool = True,\n",
      "               config: dict[str, Any] | None = None,\n",
      "               **_kwargs,\n",
      "               ) -> PreTrainedModel: ...<file_sep># ../pipeline/environment/hardware.py\n",
      "def get_free_device(used_memory_upper_bound: float = 0.001) -> torch.device: ...\n",
      "def get_optimal_dtype() -> torch.dtype: ...<file_sep># ../pipeline/data/dataset.py\n",
      "def train_test_split(df: pd.DataFrame,\n",
      "                     test_size: int,\n",
      "                     upper_bound_per_repo: int,\n",
      "                     random_seed: int | None = None,\n",
      "                     ) -> tuple[list[int], list[int] | None]: ...\n",
      "def irrelevant_context(string: str) -> str: ...\n",
      "def load_dataset(main_dataset_path: str,\n",
      "                 add_dataset_path: str | None,\n",
      "                 irrelevant_context: bool,\n",
      "                 file_level: bool,\n",
      "                 **split_kwargs,\n",
      "                 ) -> tuple[Dataset, Dataset, Dataset | None]: ...<file_sep># ../evaluation/__main__.py\n",
      "def main(config: DictConfig) -> None: ...<file_sep># ../evaluation/dataset.py\n",
      "class LongCodeArenaDataset(Dataset): ...\n",
      "    def __init__(self,\n",
      "                 crumpled_dataset: HuggingFaceDataset,\n",
      "                 context_size: int,\n",
      "                 composer: ChainedComposer,\n",
      "                 allow_leak: bool,\n",
      "                 ) -> None: ...\n",
      "    def __len__(self) -> int: ...\n",
      "    def __getitem__(self, idx: int) -> EvalSample: ...\n",
      "class DataCollator: ...\n",
      "    def __init__(self,\n",
      "                 tokenizer: PreTrainedTokenizerBase,\n",
      "                 context_size: int,\n",
      "                 ) -> None: ...\n",
      "    def _tokenize(self, \n",
      "                  text: str,\n",
      "                  max_seq_len: int,\n",
      "                  num_chars_per_token: int = 6,\n",
      "                  ) -> list[int]: ...\n",
      "    def __call__(self, batch: list[EvalSample]) -> EvalBatch: ...<file_sep># ../evaluation/data_structures.py\n",
      "class CompletionLines(TypedDict, total=False): ...\n",
      "class LongCodeArenaDatapoint: ...\n",
      "class ExactMatchCounter: ...\n",
      "    def value(self) -> float: ...<file_sep># ../pipeline/__main__.py\n",
      "def main(config: DictConfig) -> None: ...<file_sep># ../incontext/blocks/chunk_assembling.py\n",
      "class ChunkAssembler(ComposerBlock, ABC): ...\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]: ...\n",
      "class JoiningAssembler(ChunkAssembler): ...\n",
      "    def __init__(self, chunks_sep: str) -> None: ...\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> str: ...\n",
      "class PathCommentAssembler(JoiningAssembler): ...\n",
      "    def __init__(self, chunks_sep: str, path_comment_template: str) -> None: ...\n",
      "    def __call__(self, chunks: Sequence[Chunk], datapoint: Datapoint) -> str: ...<file_sep># ../incontext/blocks/block.py\n",
      "class ComposerBlock(ABC, ReprMixin): ...\n",
      "    def next_blocks(self) -> tuple[type, ...]: ...\n",
      "    def check_next_block(self, block) -> None: ...\n",
      "    def __call__(self, args: BlockArgs, datapoint: Datapoint) -> BlockArgs | str: ...<file_sep># ../incontext/blocks/chunk_ranking.py\n",
      "class ChunkRanker(ComposerBlock, ABC): ...\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]: ...\n",
      "class NegativePathDistanceRanker(ChunkRanker): ...\n",
      "    def _path_distance(path_from: str, path_to: str) -> int: ...\n",
      "    def __call__(self, chunks: Sequence[Chunk], datapoint: Datapoint) -> Sequence[Chunk]: ...\n",
      "class FileExtensionRanker(ChunkRanker): ...\n",
      "    def __init__(self, ordered_groups: list[list[str]]) -> None: ...\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]: ...\n",
      "class FunctionCallRanker(ChunkRanker): ...\n",
      "    def __init__(self, is_relative: bool) -> None: ...\n",
      "    def dfs_count(self, node: tree_sitter.Node) -> int: ...\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]: ...\n",
      "class RandomRanker(ChunkRanker): ...\n",
      "    def __init__(self, random_seed: int | None) -> None: ...\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]: ...\n",
      "class IoURanker(ChunkRanker): ...\n",
      "    def __init__(self, min_len: int) -> None: ...\n",
      "    def _get_lines(self, content: str) -> set[str]: ...\n",
      "    def __call__(self, chunks: Sequence[Chunk], datapoint: Datapoint) -> Sequence[Chunk]: ...<file_sep># ../incontext/blocks/context_postprocessing.py\n",
      "class ContextPostprocessor(ComposerBlock, ABC): ...\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]: ...\n",
      "class PartialMemoryPostprocessor(ContextPostprocessor): ...\n",
      "    def __init__(self, dropout: float, random_seed: int | None) -> None: ...\n",
      "    def __call__(self, context: str, _datapoint: Datapoint) -> str: ...\n",
      "class LineLengthPostprocessor(ContextPostprocessor): ...\n",
      "    def __init__(self, min_len: int, max_len: int) -> None: ...\n",
      "    def __call__(self, context: str, _datapoint: Datapoint) -> str: ...\n",
      "class LineStripPostprocessor(ContextPostprocessor): ...\n",
      "    def __call__(self, context: str, _datapoint: Datapoint) -> str: ...\n",
      "class CompletionLeakPostprocessor(ContextPostprocessor): ...\n",
      "    def __init__(self, \n",
      "                 chars_lower_bound: int,\n",
      "                 context_size: int,\n",
      "                 num_segments: int,\n",
      "                 tokenizer_name: str,\n",
      "                 trust_remote_code: bool,\n",
      "                 random_seed: int | None,\n",
      "                 ) -> None: ...\n",
      "    def _select_random_subsequences(self, segment_lens: list[int], num_context_lines: int) -> list[tuple[int, int]]: ...\n",
      "    def _leak_completion(self, context: str, completion: str) -> str: ...\n",
      "    def __call__(self, context: str, datapoint: Datapoint) -> str: ...\n",
      "class DseekCompletionLeakPostprocessor(CompletionLeakPostprocessor): ...\n",
      "    def __init__(self, *args, **kwargs) -> None: ...\n",
      "class OCoderCompletionLeakPostprocessor(CompletionLeakPostprocessor): ...\n",
      "    def __init__(self, *args, **kwargs) -> None: ...\n",
      "class ReversedContextPostprocessor(ContextPostprocessor): ...\n",
      "    def __init__(self,\n",
      "                 chars_lower_bound: int,\n",
      "                 context_size: int,\n",
      "                 chunks_sep: str,\n",
      "                 tokenizer_name: str,\n",
      "                 trust_remote_code: bool,\n",
      "                 ) -> None: ...\n",
      "    def __call__(self, context: str, datapoint: Datapoint) -> str: ...\n",
      "class OCoderReversedContextPostprocessor(ReversedContextPostprocessor): ...\n",
      "    def __init__(self, *args, **kwargs) -> None: ...\n",
      "class RandomTokensPostprocessor(ContextPostprocessor): ...\n",
      "    def __init__(self,\n",
      "                 context_size: int,\n",
      "                 tokenizer_name: str,\n",
      "                 trust_remote_code: bool,\n",
      "                 random_seed: int | None,\n",
      "                 ) -> None: ...\n",
      "    def __call__(self, _context: str, _datapoint: Datapoint) -> str: ...\n",
      "class DseekRandomTokensPostprocessor(RandomTokensPostprocessor): ...\n",
      "    def __init__(self, *args, **kwargs) -> None: ...\n",
      "class OCoderRandomTokensPostprocessor(RandomTokensPostprocessor): ...\n",
      "    def __init__(self, *args, **kwargs) -> None: ...<file_sep># ../incontext/blocks/chunk_sorting.py\n",
      "class ChunkSorter(ComposerBlock, ABC): ...\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]: ...\n",
      "class LexicographicSorter(ChunkSorter): ...\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]: ...\n",
      "class ReverseLexicographicSorter(ChunkSorter): ...\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]: ...\n",
      "class MixedSorter(ChunkSorter): ...\n",
      "    def __call__(self, chunks: Sequence[Chunk], _datapoint: Datapoint) -> Sequence[Chunk]: ...<file_sep># ../incontext/blocks/file_chunking.py\n",
      "class FileChunker(ComposerBlock, ABC): ...\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]: ...\n",
      "class FileGrainedChunker(FileChunker): ...\n",
      "    def __call__(self, files: Sequence[File], datapoint: Datapoint) -> Sequence[Chunk]: ...\n",
      "class CodeSegment(str, Enum): ...\n",
      "    def from_node(cls: Type[T], node: tree_sitter.Node) -> T: ...\n",
      "class Segment(NamedTuple): ...\n",
      "class CodeSegmentGrainedChunker(FileChunker): ...\n",
      "    def __init__(self) -> None: ...\n",
      "    def dfs_segmentation(root_node: tree_sitter.Node) -> list[Segment]: ...\n",
      "    def strip_lines(string: str, strip_func: Callable[[str], str]) -> str: ...\n",
      "    def __call__(self, files: Sequence[File], datapoint: Datapoint) -> Sequence[Chunk]: ...\n",
      "class DocstringAndCommentOnlyChunker(CodeSegmentGrainedChunker): ...\n",
      "    def __call__(self, *args, **kwargs) -> Sequence[Chunk]: ...\n",
      "class CodeOnlyChunker(CodeSegmentGrainedChunker): ...\n",
      "    def __call__(self, *args, **kwargs) -> Sequence[Chunk]: ...\n",
      "class FixedLineChunker(FileChunker): ...\n",
      "    def __init__(self, chunk_lines_size: int, overlap_lines_size: int) -> None: ...\n",
      "    def __call__(self, files: Sequence[File], datapoint: Datapoint) -> Sequence[Chunk]: ...\n",
      "class CompletionDuplicationChunker(FileChunker): ...\n",
      "    def __init__(self, chars_lower_bound: int) -> None: ...\n",
      "    def __call__(self, _files: Sequence[File], datapoint: Datapoint) -> Sequence[Chunk]: ...<file_sep># ../incontext/blocks/file_preprocessing.py\n",
      "class FilePreprocessor(ComposerBlock, ABC): ...\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]: ...\n",
      "class EmptyLinesRemovalPreprocessor(FilePreprocessor): ...\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]: ...\n",
      "class NewlinePreprocessor(FilePreprocessor): ...\n",
      "    def unify_newlines(string: str) -> str: ...\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]: ...\n",
      "class DeclarationOnlyPreprocessor(FilePreprocessor): ...\n",
      "    def __init__(self) -> None: ...\n",
      "    def __call__(self, files: Sequence[File], datapoint: Datapoint) -> Sequence[File]: ...<file_sep># ../incontext/blocks/file_filtering.py\n",
      "class FileFilter(ComposerBlock, ABC): ...\n",
      "    def next_blocks(self) -> tuple[Type[ComposerBlock], ...]: ...\n",
      "class NullFileFilter(FileFilter): ...\n",
      "    def __call__(self, *_args, **_kwargs) -> Sequence[File]: ...\n",
      "class InclusiveFileExtensionFilter(FileFilter): ...\n",
      "    def __init__(self, whitelist: list[str]) -> None: ...\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]: ...\n",
      "class ExclusiveFileExtensionFilter(FileFilter): ...\n",
      "    def __init__(self, blacklist: list[str]) -> None: ...\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]: ...\n",
      "class EmptyFileFilter(FileFilter): ...\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]: ...\n",
      "class FileLengthFilter(FileFilter): ...\n",
      "    def __init__(self, min_len: int, max_len: int) -> None: ...\n",
      "    def __call__(self, files: Sequence[File], _datapoint: Datapoint) -> Sequence[File]: ...<file_sep># ../incontext/composer/composer_base.py\n",
      "class ComposerBase(ABC): ...\n",
      "    def __init__(self,\n",
      "                 pre_context_prompt: str,\n",
      "                 post_context_prompt: str,\n",
      "                 path_comment_template: str,\n",
      "                 ) -> None: ...\n",
      "    def get_pre_context_prompt(self, datapoint: Datapoint) -> str: ...\n",
      "    def get_post_context_prompt(self, _datapoint: Datapoint) -> str: ...\n",
      "    def compose_context(self, datapoint: Datapoint) -> str: ...\n",
      "    def compose_completion(self, datapoint: Datapoint) -> str: ...\n",
      "    def compose(self, datapoint: dict[str, Any]) -> ComposedDatapoint: ...\n",
      "    def compose_batch(self, batch: BatchDatapoint) -> BatchComposedDatapoint: ...<file_sep># ../incontext/composer/chained_composer.py\n",
      "class UnsafeComposerChain: ...\n",
      "    def __init__(self, *blocks: ComposerBlock) -> None: ...\n",
      "    def __call__(self, datapoint: Datapoint) -> Any: ...\n",
      "class ComposerChain(UnsafeComposerChain): ...\n",
      "    def __init__(self, *blocks: ComposerBlock) -> None: ...\n",
      "class ChainedComposer(ComposerBase, ComposerChain, ReprMixin): ...\n",
      "    def __init__(self, blocks: Sequence[ComposerBlock], *args, **kwargs) -> None: ...\n",
      "    def compose_context(self, datapoint: Datapoint) -> str: ...<file_sep># ../incontext/repr_mixin.py\n",
      "class ReprMixin: ...\n",
      "    def __init_subclass__(cls, **kwargs) -> None: ...\n",
      "        def wrapped_init(self, *init_args, **init_kwargs) -> None: ...\n",
      "    def __repr__(self) -> str: ...<file_sep># ../incontext/init_from_config.py\n",
      "def find_class(name: str, module_name: str, normalization_func: Callable[[str], str] | None = None) -> type: ...\n",
      "def init_from_config(path_to_config: str) -> ChainedComposer: ...<file_sep># ../incontext/__main__.py\n",
      "def main() -> None: ...<file_sep># ../incontext/data_structures.py\n",
      "class File: ...\n",
      "class Chunk: ...\n",
      "class CompletionFile(TypedDict): ...\n",
      "class RepoSnapshot(TypedDict): ...\n",
      "class Datapoint: ...\n",
      "class BatchDatapoint(TypedDict): ...\n",
      "class ComposedDatapoint(TypedDict): ...\n",
      "class BatchComposedDatapoint(TypedDict): ...<file_sep>\n"
     ]
    }
   ],
   "source": [
    "composed_sample = composer.compose(toy_sample)\n",
    "print(composed_sample['composed_context'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9e95f6-6b97-490b-bc58-8b52829b063a",
   "metadata": {},
   "source": [
    "# Base Composer\n",
    "\n",
    "In general, a composer constructs a new _composed_ data point from the raw one. For this purpuse, it devides the data into four main parts:\n",
    "\n",
    "1. Leading prompt, `get_pre_context_prompt` method.\n",
    "2. Composed context, `compose_context` method.\n",
    "3. Prompt following context, `get_post_context_prompt` method.\n",
    "4. Composed completion, `compose_completion` method.\n",
    "\n",
    "In the simplest case, the leading prompt could be an empty string or the repository identifier, and the post-context prompt could be just a separator between the two main parts — context and completion. Now, let's focus on how we can compose context. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859b0459-5eb2-4816-b5dc-69829cfa4a1f",
   "metadata": {},
   "source": [
    "# Chained Composer\n",
    "\n",
    "A more general approach is to inherit from `ComposerBase` class and implement the corresponding method. It is a quick but not scalable solution in terms of efficient search space exploration. That's why we propose a more robust way of defining the composition pipeline — a chain of individual blocks.\n",
    "\n",
    "Types of such blocks:\n",
    "\n",
    "1. `FileFilter`, **file_filtering** module.\n",
    "2. `FilePreprocessor`, **file_preprocessing** module.\n",
    "3. `FileChunker`, **file_chunking** module.\n",
    "4. `ChunkRanker`, **chunk_ranking** module.\n",
    "5. `ChunkSorter`, **chunk_sorting** module.\n",
    "6. `ChunkAssembler`, **chunk_assembling** module.\n",
    "7. `ContextPostprocessor`, **context_postprocessing** module.\n",
    "\n",
    "See below for more details.\n",
    "\n",
    "The next directed graph illustrates:\n",
    "\n",
    "- The available order of blocks,\n",
    "- How optional their use is (the bold subgraph indicates optionality),\n",
    "- Data structure transitions: **Files -> Chunks -> Context** (grey frames)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b29a325aef36cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=2125x744>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "Image.open('composer-blocks.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e159fef0-ab5e-4982-b1f3-464ecf2f5c00",
   "metadata": {},
   "source": [
    "## file_filtering\n",
    "\n",
    "**Abstract class**: `FileFilter`. \\\n",
    "**Purpose**: Filter out unwanted files. \\\n",
    "**Currently implemented**:\n",
    "\n",
    "- `NullFileFilter` removes all context files,\n",
    "- `InclusiveFileExtensionFilter` selects files by their extensions,\n",
    "- `ExclusiveFileExtensionFilter` removes files by their extensions,\n",
    "- `EmptyFileFilter` removes empty files,\n",
    "- `FileLengthFilter` removes files that are too short or long (at the character level),\n",
    "\n",
    "## file_preprocessing\n",
    "\n",
    "**Abstract class**: `FilePreprocessor`. \\\n",
    "**Purpose**: File-level content modification. \\\n",
    "**Currently implemented**:\n",
    "\n",
    "- `EmptyLinesRemovalPreprocessor` removes empty lines,\n",
    "- `NewlinePreprocessor` normalizes newlines,\n",
    "- `DeclarationOnlyPreprocessor` extracts function and class declarations.\n",
    "\n",
    "## file_chunking\n",
    "\n",
    "**Abstract class**: `FileChunker`. \\\n",
    "**Purpose**: Convert a set of files into chunks, change granularity. \\\n",
    "**Currently implemented**:\n",
    "\n",
    "- `FileGrainedChunker` assigns a one-to-one relationship (can be understood as _no chunking_),\n",
    "- `CodeSegmentGrainedChunker` splits one Python file into four blocks: imports, docstrings, ≥3 lines comments, and code,\n",
    "- `DocstringAndCommentOnlyChunker` extracts docstring and comment chunks from the file,\n",
    "- `CodeOnlyChunker` extracts code snippets from the file,\n",
    "- `FixedLineChunker` splits the file into overlapping chunks,\n",
    "- `CompletionDuplicationChunker` replaces the repository context with the completion file.\n",
    "\n",
    "## chunk_ranking\n",
    "\n",
    "**Abstract class**: `ChunkRanker`. \\\n",
    "**Purpose**: Determine the importance of a chunk. \\\n",
    "**Currently implemented**:\n",
    "\n",
    "- `NegativePathDistanceRanker` based on the same idea as presented in the LCA paper,\n",
    "- `FileExtensionRanker` prioritizes some extensions over others,\n",
    "- `FunctionCallRanker` prioritizes chunks with a higher number of function calls,\n",
    "- `RandomRanker` shuffles chunks,\n",
    "- `IoURanker` prioritizes files with a larger number of shared lines with the completion file.\n",
    "\n",
    "## chunk_sorting\n",
    "\n",
    "**Abstract class**: `ChunkSorter`. \\\n",
    "**Purpose**: Sort a set of chunks based on their ranks. \\\n",
    "**Currently implemented**:\n",
    "\n",
    "- `LexicographicSorter` preserves rankers order,\n",
    "- `ReverseLexicographicSorter` creates irrelevant context,\n",
    "- `MixedSorter` interleaves rankers for ordering.\n",
    "\n",
    "## chunk_assembling\n",
    "\n",
    "**Abstract class**: `ChunkAssembler`. \\\n",
    "**Purpose**: Join sorted chunks. \\\n",
    "**Currently implemented**:\n",
    "\n",
    "- `JoiningAssembler` uses the provided string as a separator,\n",
    "- `PathCommentAssembler` adds information about the file's position in the project.\n",
    "\n",
    "## context_postprocessing\n",
    "\n",
    "**Abstract class**: `ContextPostprocessor`. \\\n",
    "**Purpose**: Context-level content modification. \\\n",
    "**Currently implemented**:\n",
    "\n",
    "- `PartialMemoryPostprocessor` drops some lines with a given probability,\n",
    "- `LineLengthPostprocessor` removes lines that are too short or long,\n",
    "- `LineStripPostprocessor` strips lines,\n",
    "- `CompletionLeakPostprocessor` leaks chunks of the completion file into the repository context,\n",
    "- `ReversedContextPostprocessor` applies the reversal of the context files that fall into the context window of the model,\n",
    "- `RandomTokensPostprocessor` replaces the context with a decoded sequence of random, non-special tokens."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
