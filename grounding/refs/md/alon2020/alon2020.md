# Structural Language Models of Code

Uri Alon <sup>1</sup> Roy Sadaka <sup>1</sup> Omer Levy 2 3 Eran Yahav <sup>1</sup>

### Abstract

We address the problem of *any-code completion* – generating a missing piece of source code in a given program without any restriction on the vocabulary or structure. We introduce a new approach to any-code completion that leverages the strict syntax of programming languages to model a code snippet as a tree – *structural language modeling* (SLM). SLM estimates the probability of the program's abstract syntax tree (AST) by decomposing it into a product of conditional probabilities over its nodes. We present a neural model that computes these conditional probabilities by considering all AST paths leading to a target node. Unlike previous techniques that have severely restricted the kinds of expressions that can be generated in this task, our approach can generate arbitrary code in any programming language. Our model significantly outperforms both seq2seq and a variety of structured approaches in generating Java and C# code. Our code, data, and trained models are available at [http://github.com/tech-srl/](http://github.com/tech-srl/slm-code-generation/) [slm-code-generation/](http://github.com/tech-srl/slm-code-generation/). An online demo is available at <http://AnyCodeGen.org>.

### 1. Introduction

Code completion is the problem of generating code given its surrounding code as context. In its most general form, this problem is extremely challenging as it requires reasoning over an unbounded number of syntactic structures and user-defined symbols. Previous approaches have avoided this issue by limiting the generation problem: program synthesis approaches are often tailored to domain-specific languages [\(Gulwani,](#page-31-0) [2011;](#page-31-0) [Polozov & Gulwani,](#page-31-0) [2015;](#page-31-0) [De](#page-30-0)[vlin et al.,](#page-30-0) [2017;](#page-30-0) [Ellis et al.,](#page-30-0) [2019\)](#page-30-0), while other recent approaches generate code in general languages like Java and C#, but severely restrict the syntax, vocabulary, domain, or nature of the generated programs [\(Murali et al.,](#page-31-0) [2018;](#page-31-0) [Brockschmidt et al.,](#page-30-0) [2019;](#page-30-0) [Young et al.,](#page-32-0) [2019\)](#page-32-0).

We introduce the task of *any-code completion* – generating code in a general-purpose programming language without any restriction on its vocabulary or structure. Specifically, we focus on generating code in context: given a program P and some part of the program p, the task is to predict p from the rest of the program P <sup>−</sup>=P\p. Any-code completion thus generalizes the restricted completion task of [Brockschmidt et al.](#page-30-0) [\(2019\)](#page-30-0), in which the target code contained only primitive types (e.g., int and string) and excluded user-defined functions. Figure [1](#page-1-0) shows two anycode completion examples.

In related tasks such as semantic parsing [\(Dong & Lapata,](#page-30-0) [2018;](#page-30-0) [Yu et al.,](#page-32-0) [2018;](#page-32-0) [Iyer et al.,](#page-31-0) [2019\)](#page-31-0), natural-languageto-code [\(Allamanis et al.,](#page-30-0) [2015;](#page-30-0) [Iyer et al.,](#page-31-0) [2018\)](#page-31-0), and editto-code [\(Yin et al.,](#page-32-0) [2019;](#page-32-0) [Zhao et al.,](#page-32-0) [2019\)](#page-32-0), models must use separate encoders and decoders because of the different modalities of the input (e.g. natural language text) and the output (code). In contrast, we leverage the fact that our input and output are of the *same modality* (code), and pursue better generalization by modeling them *jointly*.

We present a new approach that explicitly models the source and the target code as the same tree – *structural language modeling* (SLM). SLM estimates the probability of the program's abstract syntax tree (AST) by decomposing it into a product of conditional probabilities over its *nodes*. We present a neural model that computes these conditional probabilities by considering all AST paths leading to a target node, generalizing over traditional language models that consider sequences of words. While prior work uses AST paths to *read* programs [\(Alon et al.,](#page-30-0) [2019b\)](#page-30-0), we *generate* code by predicting the next node along the set of paths, generating the target AST node-by-node.

We evaluate SLMs on Java any-code completion, achieving a new state of the art: exact-match accuracy@1 of 18.04% and accuracy@5 of 24.83% (previous SOTA: 16.93% and 23.17%). SLMs also outperform existing models in the restricted completion task of [Brockschmidt et al.](#page-30-0) [\(2019\)](#page-30-0) in C# by a wide margin, 37.61% accuracy@1 compared to 26.42%. Our ablation study reveals the importance of *joint modeling* of the source and target code, rather than sep-

<sup>1</sup>Technion, Israel <sup>2</sup>Tel Aviv University 3 Facebook AI Research. Correspondence to: Uri Alon <urialon@cs.technion.ac.il>, Roy Sadaka <roysadaka@gmail.com>, Omer Levy <omerlevy@gmail.com>, Eran Yahav <yahave@cs.technion.ac.il>.

<span id="page-1-0"></span>

| public static Path[] stat2Paths(<br>FileStatus[] stats) {<br>if (stats == null) return null;<br>Path[] ret = new Path[stats.length];<br>for (int i = 0; i < stats.length; ++i){<br>ret[i] =<br>;<br>}<br>return ret;<br>} |                                                 |                                                                                                                  | public static string Camelize(<br>this string input)<br>{<br>var word = input.Pascalize();<br>return word.Length > 0 ?<br>.ToLower()<br>+ word.Substring(1)<br>: word;<br>} |                                                 |                                                                                                                |
|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------|------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------|----------------------------------------------------------------------------------------------------------------|
| stats[i].getPath()<br>True ref (Java):                                                                                                                                                                                    |                                                 | True ref (C#):                                                                                                   |                                                                                                                                                                             | word.Substring(0, 1)                            |                                                                                                                |
| SLM<br>top-5:                                                                                                                                                                                                             | (25.2%)<br>(3.3%)<br>(2.5%)<br>(1.7%)<br>(0.8%) | stats[i].getPath()<br>Path(stats[i])<br>new Path(stats[i], charset)<br>stat(stats[i], ret)<br>new Path(stats[i]) | SLM<br>top-5:                                                                                                                                                               | (14.1%)<br>(8.2%)<br>(5.8%)<br>(2.4%)<br>(1.9%) | word.Substring(0, 1)<br>word.trim()<br>word.Substring(1)<br>input.Substring(0, 1)<br>wordValue.Substring(0, 1) |
| (a)                                                                                                                                                                                                                       |                                                 |                                                                                                                  | (b)                                                                                                                                                                         |                                                 |                                                                                                                |

Figure 1. Examples from the Java (left) and C# (right) test sets. The highlighted expression in each example is the target p, which our models correctly generated from the rest of the snippet. Additional and larger examples can be found in Appendices [F](#page-11-0) and [G.](#page-11-0)

arating encoders from decoders. Finally, we discuss the theoretical advantages of SLMs, and show how they generalize many previous structural approaches for code generation. An interactive demo of our model is presented at <http://AnyCodeGen.org>.

## 2. Code Generation as Structural Language Modeling

We model the task of any-code completion by computing the probability of a program P r (P), similar to how a language model computes the probability of a natural language sentence. While language models typically assume a *sequence* as their input, our input is an abstract syntax *tree* A<sup>P</sup> . We thus introduce a *structural* language modeling approach (SLM).

The intuition behind this idea is that a language model could *generalize better* by modeling the *tree* rather than the sequential form of the program. Further, learning from the AST allows a model to save learning capacity, instead of having to re-learn known syntactic patterns from the text.

We first show a chain-rule decomposition of the tree's probability P r (A<sup>P</sup> ) into a product of conditional *node* probabilities, and then describe our path-based model for computing the individual conditional probabilities. We explain how to construct a tree from local node predictions, and finally discuss how our approach differs from previous work on production-based tree generation.

Representing Code as a Tree A program P is a sequence of tokens that can be unambiguously mapped to an abstract syntax tree (AST) A<sup>P</sup> , where every node represents an element in the language (e.g. conditions, loops, variable declarations) from a set T . Each AST leaf (terminal) has an associated user-defined value v ∈ V. Nonterminal nodes can have a varying number of children nodes.

Decomposing the Probability of a Tree Given a tree A<sup>P</sup> , we first traverse the tree, depth-first,<sup>1</sup> to induce an ordering over its nodes a0, . . . , a|A<sup>P</sup> <sup>|</sup> ∈ A<sup>P</sup> . We decompose the probability of a tree P r (A<sup>P</sup> ) using the chain rule, akin to the standard approach in language modeling:

$$\Pr\left(\mathcal{A}\_{\mathcal{P}}\right) = \prod\_{t} \Pr\left(a\_t | a\_{$$

where a<t are all the nodes that were traversed before at.

In any-code completion, part of the tree (AP<sup>−</sup> ) is already observed. Therefore, we order the nodes of AP<sup>−</sup> to be before the nodes of the target p, and compute only the conditional probabilities over the nodes in p, essentially conditioning on the observed tree AP<sup>−</sup> .

Representing Partial Trees via Paths How can we represent the partial tree composed of a<t when computing P r (at|a<t)? In standard language modeling, the structure is linear, and a<t is a sequence. One way to represent a partial tree is to linearize it according to the traversal order [\(Xiao et al.,](#page-32-0) [2016\)](#page-32-0); however, this creates artificially long distances between the current node a<sup>t</sup> and ancestor nodes (e.g., the root a0). Another option is to use only the path from the root node to a<sup>t</sup> [\(Rabinovich et al.,](#page-31-0) [2017\)](#page-31-0), but this ignores a lot of contextual information (e.g., sibling nodes).

We follow [Alon et al.](#page-30-0) [\(2018\)](#page-30-0) and use *the set of paths* from every leaf to a<sup>t</sup> together with the path from the root to

<sup>1</sup>Depth-first ordering is a common practice in tree generation [\(Maddison & Tarlow,](#page-31-0) [2014;](#page-31-0) [Raychev et al.,](#page-31-0) [2016\)](#page-31-0), but in principle our framework also allows for other orderings.

<span id="page-2-0"></span>![](_page_2_Figure_1.jpeg)

Figure 2. The subtree representing x > 1 is generated given its surrounding tree. At each step, the model generates the next node (denoted by ? ) of path1, path<sup>2</sup> and path<sup>3</sup> using the root path R. Dashed lines denote the AST structure; solid lines denote AST paths. Most AST paths are omitted from the figure, for clarity.

at. Intuitively, each path captures the effect of a different, possibly distant, program element on at, along with the syntactic relationship between them. For example, in Figure [1](#page-1-0) (left) the three paths originating from Path[] ret inform the model about the existence of ret which is an array of type Path. Thus, when completing ret[i] = ... – the completion should be a Path object. Other paths inform the model that the target is inside a For loop, iterated stats.length times. Considering the information flowing from all paths, our model correctly generates stats[i].getPath().

We denote the (candidate) node at time t as at, its (given) parent, which is currently expanded, by π (at), and the set of all paths as St:

$$\mathcal{S}\_t = \{ \ell \sim \pi \mid a\_t \mid \ell \in \text{leaves} \left( a\_{$$

where ` ; <sup>π</sup> (at) is the (only) path in the tree between a leaf ` and the current node to expand π (at). We denote the path from the root of the program as <sup>R</sup><sup>t</sup> <sup>=</sup> <sup>a</sup><sup>0</sup> ; <sup>π</sup> (at), which represents the current, relative position of π (at) in the program (marked as R in Figure 2). Whereas prior work used *whole* paths (between two leaf nodes) to encode ASTs [\(Alon et al.,](#page-30-0) [2019a;b\)](#page-30-0), our model observes *partial* paths (between a leaf and any other node) and learns to extend them by predicting their next node.

Figure 2 illustrates the traversal order of a subtree that represents the expression x > 1 and some of the paths used to compute the probability at each step. At each step, the probability of the next node is computed given the paths S<sup>t</sup> from the root and every given leaf up to the current node to expand. Figure 2(d) shows how after the terminal node with the value x is given, path<sup>3</sup> originating from this leaf is also used to compute the probability of the next nodes.

Our path-based approach generalizes previous approaches such as "parent feeding" and "previous action" encoding [\(Yin & Neubig,](#page-32-0) [2017\)](#page-32-0), context nodes [\(Bielik et al.,](#page-30-0) [2016\)](#page-30-0), and some of the graph-edges of [Brockschmidt et al.](#page-30-0) [\(2019\)](#page-30-0). See Section [8](#page-7-0) for further discussion.

Generating Trees In sequence generation, the length of the target sequence is controlled by generating an EOS token to stop. When generating trees, we require a more sophisticated mechanism to control arity and depth. We augment A<sup>P</sup> in two ways to allow node-by-node generation.

![](_page_2_Figure_11.jpeg)

Figure 3. Augmenting the AST with EOSnode and EOStok nodes.

First, we add a special EOSnode node to every nonterminal to control for *arity*. Generating this node indicates that the parent node has no more children nodes. Second, we end each subtoken sequence with a special EOStok node to control for *depth* during generation; we decompose each terminal node n<sup>v</sup> into a sequence of terminal nodes T<sup>v</sup> by splitting up the node's value v into *subtokens* based on <span id="page-3-0"></span>camel notation. For example, if v = toLowerCase, then T<sup>v</sup> = to → lower → case → EOStok. Figure [3](#page-2-0) shows an example of both EOSnode and EOStok in action.

Node Trees vs. Production Trees While we predict a single *node* at each step, previous work [\(Iyer et al.,](#page-31-0) [2018;](#page-31-0) [2019\)](#page-31-0) predicts a grammar production rule. This representation decomposes the code in a way that often forces the model to predict with partial information. For instance, consider generating the expression **str.Substring(3)**. The model of [Brockschmidt et al.](#page-30-0) [\(2019\)](#page-30-0) would first predict the rule **Expr**→**Expr.Substring(Expr)**, and only then expand **Expr**→**str** and **Expr**→**3**. That is, the model needs to predict the method name (Substring) *before* the invoking object (str). Further, the Substring method can get either one *or* two arguments, forcing the model to choose whether to use the one- or two-argument rule in advance. Node generation, however, allows us to predict the presence of a function call and only then to predict its object and method name, rather than predicting these a priori.

### 3. Model Architecture

In the previous section, we described how we can generate code given the probabilities P r (at|a<t), where a<t is represented by the set of partial AST paths St. Here, we present a neural model that estimates P r (at|St). We first encode each path in S<sup>t</sup> as a vector (Section 3.1); then, we contextualize and aggregate the entire set. Finally, we predict the target node a<sup>t</sup> by combining a subtoken vocabulary with a syntactic copy mechanism (Section 3.3).

#### 3.1. Encoding AST Paths

Given a partial AST path, i.e., a sequence of nodes n1, . . . , nk, our goal is to create a vector representation.

We first represent each node n<sup>i</sup> using embeddings. A subtoken node is represented by the index of its subtoken w in the embedding matrix Esubtoken; AST nodes are represented as a pair n<sup>i</sup> = (τ, κ) where τ is the node type, e.g. IfStatement, and κ is the node index among its sibling nodes. We represent node types using a learned embedding matrix Etype and the child indices using a learned matrix Eindex. The node's vector representation is the concatenation of the type and index vectors.

$$e\left(n\_i\right) = \begin{cases} E\_w^{\text{subtoken}} & n\_i \text{ is the subttoken } w\\ \left[E\_\tau^{\text{type}}; E\_\kappa^{\text{index}}\right] & n\_i \text{ is the AST node } (\tau, \kappa) \end{cases}$$

We encode the entire path using a uni-directional LSTM stack, and take the final states:<sup>2</sup>

$$\bar{f}\left(n\_1, \ldots, n\_k\right) = \text{LSTM}\left(e\left(n\_1\right), \ldots, e\left(n\_k\right)\right),$$

Given a set of partial paths S (omitting the iterator t for simplicity), we denote their encodings as H = { ; f (n1, . . . , nk) | (n1, . . . , nk) ∈ S}.

Efficient Computation When modeling a subtree, there are large overlaps between paths from different time steps. In particular, paths that originate from the same leaf share the same *prefix*. We therefore apply the LSTM on the prefix *once* and cache the intermediate state across suffixes, speeding up both training and inference significantly. An example is shown in Figure [7](#page-9-0) (supplementary material).

#### 3.2. Aggregating Multiple Paths

Given the set of paths S leading up to the parent π(a) of the target node a, our goal is to represent S in the context of predicting a. To do so, we introduce the aggregation function g (H, r, i). As its input, g takes the set of encoded paths H, the encoded root path r, and the child index i of the currently predicted child node a relative to its parent.

We first contextualize the path encodings H using a transformer encoder [\(Vaswani et al.,](#page-31-0) [2017\)](#page-31-0).<sup>3</sup> In parallel, we apply a non-linear transformation to the encoding of the root path r = ; f (R), in order to inform it that we wish to predict the i-th child of π(a):

$$Z = \text{Transformer}\left(H\right) \quad \tilde{r} = W\_r \cdot \text{ReLU}\left(C\_i \cdot r\right)$$

In this formulation, the parameter matrix C<sup>i</sup> is used when the child index is i, while the parameter matrix W<sup>r</sup> is used for every instance.

We then compute attention over the set of contextualized path encodings Z using the index-informed root-path encoding <sup>r</sup><sup>e</sup> as the query; we pass the weighted average <sup>z</sup><sup>e</sup> and the root-path encoding <sup>r</sup><sup>e</sup> through another fully-connected layer; we denote the resulting vector representation as <sup>e</sup>h:

$$\begin{aligned} \alpha &= \operatorname{softmax} \left( Z \cdot \widetilde{r} \right) & \widetilde{z} &= \sum\_{j} \alpha\_{j} \cdot Z\_{j} \\\\ \widetilde{h} &= g \left( H, r, i \right) = \operatorname{ReLU} \left( W\_{g} \left[ \widetilde{z}; \widetilde{r} \right] \right) \end{aligned}$$

where semicolons (;) denote vector concatenation.

#### 3.3. Predicting with a Syntactic Copy Mechanism

We can now predict <sup>a</sup> from the representation <sup>e</sup>h. If the target node's parent π(a) is a nonterminal AST node, then a must be an AST node; otherwise, a is a subtoken.

Predicting AST Nodes If a is an AST node, we predict a using a softmax over the node type embeddings Etype:

$$\Pr\left(a|\mathcal{S}\right) = \text{softmax}\left(E^{\text{type}} \cdot \tilde{h}\right) \quad \text{( $\pi(a)$  is a nonterminal)}$$

<sup>2</sup>Replacing the LSTMs with transformers yielded similar results in preliminary experiments.

<sup>3</sup> Since H is a set, we do not use positional embeddings.

<span id="page-4-0"></span>Predicting Subtokens Programs repeatedly refer to previously declared symbols, resulting in highly repetitive usage of identifiers. We therefore use a copy mechanism [\(Gu et al.,](#page-31-0) [2016\)](#page-31-0) to allow our model to predict either entire tokens or individual subtokens that exist in the context. As we show in Section [6,](#page-6-0) copying greatly improves our model's performance. For brevity, we describe how entire tokens are copied, and elaborate on the copy of *sub*tokens in Appendix [D.](#page-10-0) We score each leaf ` using a bilinear function (Wc) between its path's encoding <sup>H</sup>` and <sup>e</sup>h. At the same time, we score the token w, which is the token associated with `, from a limited vocabulary using the inner product between its representation in the subtoken embedding matrix <sup>E</sup>subtoken and <sup>e</sup>h.

$$s\_{\rm copy}(\ell) = H\_{\ell} \cdot W\_{c} \cdot \bar{h} \quad s\_{\rm gen}(w) = E\_{w}^{\rm subtoken} \cdot \bar{h}$$

The scores scopy and sgen are then summed over all occurrences that correspond to the same symbol and subsequently normalized via softmax. A key difference from most previous work [\(Ling et al.,](#page-31-0) [2016;](#page-31-0) [Yin & Neubig,](#page-32-0) [2017\)](#page-32-0) is that our copy mechanism uses the *syntactic* relation to the source (the path H`), rather than the sequential relation or the graph-node representation [\(Yin et al.,](#page-32-0) [2019\)](#page-32-0).

### 4. Experimental Setup

#### 4.1. Benchmarks

Any-Code Completion: Java We take the Java-small dataset of [Alon et al.](#page-30-0) [\(2019a\)](#page-30-0), which is a re-split of the dataset of [Allamanis et al.](#page-30-0) [\(2016\)](#page-30-0). It contains 11 GitHub projects, broken down into a single method per example, and split to train/dev/test by project to reduce code overlap. This dataset was found to contain the least code duplication by [Allamanis](#page-30-0) [\(2019\)](#page-30-0). We create any-code completion examples by selecting every expression larger than a single AST node as the target, using the remainder of the method as the context. We remove methods containing the word "test" in their body or file name, and omit 10% of the examples by filtering out methods longer than 20 lines to avoid configurations, initializations, and auto-generated code. To make the task even harder, we remove examples where the target appears as-is in the context. Ultimately, this dataset contains 1.3M/10k/20k train/dev/test examples.

Restricted Completion: C# To provide a fair comparison to [Brockschmidt et al.](#page-30-0) [\(2019\)](#page-30-0), we create an additional benchmark where the missing code is more limited. We use the code of [Brockschmidt et al.](#page-30-0) [\(2019\)](#page-30-0) which filters out examples where the targets contain non-primitive types or user-defined functions. We extract the exact same types of limited expressions. Since the dataset of [Brockschmidt](#page-30-0) [et al.](#page-30-0) [\(2019\)](#page-30-0) is not publicly available, we consulted with Brockschmidt et al. directly and extracted examples from the raw dataset of [Allamanis et al.](#page-30-0) [\(2018\)](#page-30-0) using their "unseen projects test" set. This dataset contains 30 GitHub projects broken down to one method per example. This dataset contains 16k/8k/3k train/dev/test examples.

Our datasets are available at: [http://github.com/](http://github.com/tech-srl/slm-code-generation/) [tech-srl/slm-code-generation/](http://github.com/tech-srl/slm-code-generation/). Detailed statistics are provided in Figure [6](#page-9-0) in Appendix [A.](#page-9-0)

Metrics Following [Brockschmidt et al.](#page-30-0) [\(2019\)](#page-30-0), we report exact match accuracy at 1 and 5. We also introduce a new *tree@k* metric which counts a prediction as correct if the entire tree structures, ignoring leaf values, are identical. For example, x > 1 and y > 2 would *not* count as identical in *exact match*, but *would* count as "tree-match identical" because both express that an identifier is greater than an integer (NAME > INT). The *tree@k* metric is interesting because it allows us to tease apart the model's syntactic errors from incorrect subtoken predictions.

#### 4.2. Baselines

We compare our model to a variety of original implementations and adaptations of existing models. We put significant effort to perform a fair comparison, including adding a copy mechanism to the NMT baselines and *sub*tokenization as in our model. We adapt strong baselines from the literature to our task, even if they were designed to different tasks such as NL→code and code→NL. We re-train all the following baselines on the same datasets as our models.

NMT We use standard autoregressive sequence-tosequence NMT baselines, in which we subtokenize the given code snippet, replace the target in the source with a special PRED symbol, and train the network to predict the target as a sequence of subtokens. *Transformerbase+copy* [\(Vaswani et al.,](#page-31-0) [2017\)](#page-31-0) uses the implementation of Open-NMT [\(Klein et al.,](#page-31-0) [2017\)](#page-31-0) with a copy mechanism [\(Gu et al.,](#page-31-0) [2016\)](#page-31-0). *Transformersmall+copy* uses dmodel=256, dff=1024, and 4 self attention heads per layer. *BiLSTM*→*LSTM+copy* is a 2-layer bidirectional LSTM encoder-decoder with d=512 and attention. *seq2tree+copy* follows [Aharoni &](#page-30-0) [Goldberg](#page-30-0) [\(2017\)](#page-30-0) and learns to generate the linearized, subtokenized target AST.

Java-specific Baselines We use the original implementation of [Iyer et al.](#page-31-0) [\(2018\)](#page-31-0), and also their *seq2prod* baseline which is a re-implementation of [Yin & Neubig](#page-32-0) [\(2017\)](#page-32-0); these are designed for NL→code tasks, in which we feed the code context as the NL input. The model of [Iyer et al.](#page-31-0) [\(2018\)](#page-31-0) is designed to get additional input of the available variables *and their types*, for which we do not feed types. While these models could also be applied to other languages, their implementation only supports Java.

C#-specific Baselines We compare our model to the graphbased GNN→NAG model using the implementation of [Brockschmidt et al.](#page-30-0) [\(2019\)](#page-30-0). [Bielik et al.](#page-30-0) [\(2016\)](#page-30-0) kindly

#### Structural Language Models of Code

<span id="page-5-0"></span>

| Model                                        | acc@1 | acc@5 | tree@1 | tree@5 |
|----------------------------------------------|-------|-------|--------|--------|
| code2seq (Alon et al., 2019a)                | 10.68 | 15.56 | 30.46  | 43.94  |
| Iyer et al. (2018)                           | 5.94  | 9.19  | 25.54  | 36.75  |
| seq2prod (Yin & Neubig, 2017)                | 8.05  | 11.82 | 30.77  | 41.73  |
| Transformersmall (Vaswani et al., 2017)+copy | 14.23 | 21.35 | 31.83  | 47.40  |
| Transformerbase (Vaswani et al., 2017)+copy  | 16.65 | 24.05 | 34.68  | 50.52  |
| BiLSTM→LSTM (Luong et al., 2015)+copy        | 16.93 | 23.17 | 34.29  | 49.72  |
| seq2tree (Aharoni & Goldberg, 2017)+copy     | 16.81 | 23.04 | 38.14  | 52.36  |
| SLM (this work)                              | 18.04 | 24.83 | 39.10  | 55.32  |

Table 1. Results on any-code completion in Java.

trained and tested their non-neural PHOG model on our C# dataset. We note that PHOG does not have an explicit copy mechanism, and considers only context to the left of the target code, while we consider also context to the right. Extending PHOG could potentially improve its results.

In both Java and C#, we compare to *code2seq* [\(Alon et al.,](#page-30-0) [2019a\)](#page-30-0), which is a strong code→NL model. We train it to generate the target code as a *sequence* of subtokens.

#### 4.3. Implementation and Hyperparameter Settings

Architecture We use embeddings of size 512, 2 layers of LSTMs with 256 units, and 4 transformer layers with 8 attention heads. We kept a small subtoken vocabulary of size 1000 to encourage the model to learn to copy; larger vocabularies did not show an improvement. These resulted in a very lightweight model of only 15M parameters, which is close to *Transformersmall* (11.8M parameters). In comparison, *Transformerbase* had more than 45M parameters (3× more parameters than our model).

Training We train the model end-to-end on a single V100 GPU, using cross entropy and the Adam optimizer [\(Kingma & Ba,](#page-31-0) [2015\)](#page-31-0), an initial learning rate of 10<sup>−</sup><sup>4</sup> multiplied by 0.95 every 20k steps. We bucket examples based on the number of predictions in the target subtree (nodes + subtokens + EOS), and vary the batch size such that each batch contains about 512 targets. We train the model to prefer copying entire tokens rather than copying subtokens, if possible, by optimizing for the entire token as the true label. We apply dropout of 0.25 in the Transformer layers, and a recurrent dropout of 0.5 in the LSTMs.

Inference We perform beam search with width of 5 and optimize for accuracy@1.

### 5. Results

Any-Code Completion: Java Table 1 shows that our SLM achieves over 1.1% and 0.78% better *acc@1* and *acc@5* (respectively) over the two strongest baselines. The improvement over *Transformersmall*, which is closer to our model in the number of parameters, is even higher: over

| Model           | acc@1 | acc@5 | tree@1 | tree@5 |
|-----------------|-------|-------|--------|--------|
| GNN→NAG         | 15.19 | 27.05 | 26.48  | 40.09  |
| code2seq        | 6.20  | 10.05 | 21.97  | 30.89  |
| seq2seq+copy    | 26.42 | 37.94 | 34.10  | 49.23  |
| seq2tree+copy   | 22.29 | 35.86 | 31.85  | 48.53  |
| PHOG            | 7.40  | 12.00 | –      | –      |
| SLM (this work) | 37.61 | 45.51 | 51.10  | 59.82  |

Table 2. Results on restricted completion in C#.

#### 3.8% and 3.4% in *acc@1* and *acc@5*.

The NMT baselines performed better than code-specific baselines. We hypothesize that the reason is that the NMT baselines are more generic, while the code-specific baselines are designed for different tasks: *seq2prod* is designed for tasks which involve generating code *given natural language input*; [Iyer et al.](#page-31-0) [\(2018\)](#page-31-0) additionally expects all member methods, fields, and their types as input; *code2seq* is designed to generate sequences rather than code, and does not have a copy mechanism. An approximation of *code2seq* with a copy mechanism is presented in Section [6.](#page-6-0)

Interestingly, the syntactically-informed *seq2tree* baseline achieved the highest *tree@k* among the baselines, while our model achieved higher *acc@k* and *tree@k*. This shows that leveraging the syntax can benefit NMT models as well.

Restricted Completion: C# Table 2 shows the results for the restricted completion task in C#, where *seq2seq+copy* is the *BiLSTM*→*LSTM+copy* model which performed the best among the Java baselines. We first observe that the *seq2seq+copy* and the *seq2tree+copy* baselines outperform the GNN→NAG of [Brockschmidt et al.](#page-30-0) [\(2019\)](#page-30-0), who introduced this task. Although [Brockschmidt et al.](#page-30-0) [\(2019\)](#page-30-0) did compare to a seq2seq baseline, their GNN→NAG model could copy symbols from the context, but their baseline did not. To conduct a fair comparison with our SLM model, we equipped the seq2seq and seq2tree baselines with a copy mechanism. Even though the *seq2seq+copy* and the *seq2tree+copy* baselines perform substantially better than the state of the art in this setting, our SLM model is able to go beyond, achieving significant gains over all models.

<span id="page-6-0"></span>

| Ablation       | acc@1 | acc@5 | tree@1 | tree@5 |
|----------------|-------|-------|--------|--------|
| Paths→Seq      | 12.95 | 18.52 | 33.44  | 43.43  |
| Seq→Path       | 12.12 | 17.12 | 28.68  | 43.99  |
| Paths→Paths    | 17.63 | 24.62 | 37.78  | 53.98  |
| No Root Att    | 14.43 | 18.48 | 28.20  | 35.65  |
| No Copy        | 10.72 | 15.70 | 30.61  | 44.35  |
| SLM (original) | 18.04 | 24.83 | 39.10  | 55.32  |

Table 3. Ablations on any-code completion in Java.

The superiority of our model over GNN→NAG may also be related to the GNN bottleneck [\(Alon & Yahav,](#page-30-0) [2020\)](#page-30-0), which hinders GNNs from propagating long-range messages. In contrast, propagating long-range messages using paths is natural for our model.

### 6. Ablation Study

To understand the importance of the various components and design decisions in our model, we conducted an extensive ablation study.

*Paths*→*Seq* follows *code2seq* [\(Alon et al.,](#page-30-0) [2019a\)](#page-30-0) and separates the model to an encoder and a decoder, where the decoder generates the target code as a sequence of subtokens. The main difference from *code2seq* is that *Paths*→*Seq* includes a copy mechanism, as in our model.

*Seq*→*Path* follows [Rabinovich et al.](#page-31-0) [\(2017\)](#page-31-0) and separates our model to an encoder and a decoder (including a copy mechanism), where the encoder encodes the context as a sequence of subtokens using a BiLSTM, and the decoder generates the missing subtree using the root path and the index of the generated child.

*Paths*→*Paths* is similar to our SLM model except that it uses separate encoder and decoder. These encoder and decoder have untied weights, unlike our SLM model which models the source and the target jointly.

*No Root Attention* uses max pooling instead of attention in aggregating multiple paths (see Section [3.2\)](#page-3-0). The indexinformed path from the root to the target's parent (R in Figure [2\)](#page-2-0) is concatenated with the result, instead of being used as attention query.

*No Copy* replaces copy mechanism with a much larger vocabulary (25k subtokens instead of 1k).

Results Table 3 shows the results of these alternatives. As our SLM model performs better than *Paths*→*Paths*, this ablation shows the importance of joint modeling of the context and the target subtree by parameter tying.

Each of *Paths*→*Paths* and the seq2seq baselines (Table [1\)](#page-5-0) performs better than *Paths*→*Seq* and *Seq*→*Path*; this shows the importance of *using the same type of encoder and decoder* for any-code completion, rather than combining "an optimal encoder" with "an optimal decoder". While this distinction between encoder and decoder types might be necessary for semantic parsing [\(Rabinovich et al.,](#page-31-0) [2017;](#page-31-0) [Dong & Lapata,](#page-30-0) [2018\)](#page-30-0), NL→code [\(Yin & Neubig,](#page-32-0) [2017\)](#page-32-0) and code→NL [\(Alon et al.,](#page-30-0) [2019a;](#page-30-0) [Fernandes et al.,](#page-30-0) [2019\)](#page-30-0) tasks because of the different modalities of the input and the output, this discrepancy may hurt generalization when the output is essentially a missing part of the input's AST.

*Paths*→*Paths* performs better than the seq2seq baselines (Table [1\)](#page-5-0), showing the advantage of using paths over textual sequences, even without parameter tying.

*No Root Attention* degrades *acc@1* and *acc@5* by 3.6% to 6.3%. This shows that dynamically attending to the context paths given the current root path is crucial.

*Not using a copying mechanism* results in a degradation of 7.3% to 9.1%. Programs use symbols and identifiers repetitively, thus the ability to copy symbols from the context is crucial for this task. For this reason, we included a copying mechanism in all NMT baselines in Section [4.](#page-4-0)

### 7. Qualitative Analysis

Our main results (Table [1](#page-5-0) and Table [2\)](#page-5-0) reveal a gap between *acc@k* and *tree@k*: when ignoring identifier values and comparing only the tree structure, accuracy is significantly higher across all models. While our SLM model performs better than all baselines in *acc@k*, our model also shows greater potential for improvement in its *tree@k* results, which are much higher than the baselines'. We thus focus on studying the cases where the tree was predicted correctly, but the model failed to generate the code exactly including names.

Figure [4\(a\)](#page-7-0) shows an example of this case: the ground truth has a structure of the form: NAME.NAME() > INT. Our model predicts value.length() > 0 (a tree-match) as its first candidate and value.length() > 55 (the ground truth) as its second. Null-checking a string is often followed by checking that it is also not empty, making the first candidate a reasonable prediction as well.

Figure [4\(b\)](#page-7-0)shows another example: in this case, the ground truth thisValue == thatValue ? 0 : 1 was predicted correctly only as the second candidate. Nevertheless, the top-3 candidates are tree-matches since all of them are of the form: NAME == NAME ? INT : INT. Interestingly, the fifth candidate (thisValue == thatValue) ? 0 : 1 is logically-equivalent to the ground truth.

In both examples, our model's top candidate differs from the ground truth by *a single identifier or literal*: in Figure [4\(a\)](#page-7-0) the model predicted 0 instead of 55; in Figure [4\(b\)](#page-7-0)

#### Structural Language Models of Code

<span id="page-7-0"></span>

| private static void log(String value) {<br>if (value != null<br>&&<br>)<br>value = value.substring(0, 55)+"";<br>LOG.info(value);<br>} |                                                                                                                                                                             | public int compareTo(LongWritable o) {<br>long thisValue = this.value;<br>long thatValue = o.value;<br>return (thisValue < thatValue ? -1 :<br>(<br>));<br>}                                                                                                 |  |  |  |  |
|----------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--|--|--|--|
| value.length() > 55<br>True ref:                                                                                                       |                                                                                                                                                                             | thisValue == thatValue ?<br>0 :<br>1                                                                                                                                                                                                                         |  |  |  |  |
| SLM<br>top-5:                                                                                                                          | value.length() > 0<br>(9.6%)<br>X<br>value.length() > 55<br>(7.3%)<br>value.startsWith("")<br>(1.8%)<br>!value.startsWith("")<br>(1.5%)<br>value.charAt(0) == '.'<br>(0.9%) | thisValue == thisValue ?<br>0 :<br>1<br>(16.3%)<br>X<br>thisValue == thatValue ?<br>0 :<br>1<br>(11.0%)<br>thisValue == value ?<br>0 :<br>1<br>(9.5%)<br>thisValue > thatValue ?<br>0 :<br>1<br>(6.6%)<br>(thisValue == thatValue) ? 0 :<br>1<br>↔<br>(6.1%) |  |  |  |  |
| (a)                                                                                                                                    |                                                                                                                                                                             | (b)                                                                                                                                                                                                                                                          |  |  |  |  |

Figure 4. Examples for cases where the top candidate is a "tree-match" (marked with ), but only the second candidate is an "exact match" (marked with X in bold). Predictions that are logically equivalent to the ground truth are marked with ↔. Additional (and larger) examples along with the predictions of the baselines are shown in Appendices [F](#page-11-0) and [G.](#page-11-0)

the model predicted thisValue instead of thatValue. Such single *sub*token errors are responsible for 30% of the cases where the model's top prediction is a tree-match but not an exact match. Single *token* (whole identifier or literal) mismatches are responsible for 74% of these cases. Thus, improving our model's ability to predict the right names has the potential to enhance our gains furthermore. Detailed results of allowing such mistakes in our model and in the baselines can be found in Appendix [C.](#page-9-0)

Additional possible post-filtering could filter out candidates that do not compile. In Figure [5,](#page-8-0) the first, third and fourth candidates do not compile, because the this.currentAttempt object does not have getCount, get, nor getTime methods. If the model's predictions would have been considered in the context of the entire project including its dependencies, these candidates could have been filtered out, and the (correct) fifth candidate would be ranked *second*. We leave compiler-guided code generation to future work.

Additional examples can be found in Appendices [F](#page-11-0) and [G,](#page-11-0) and in our interactive demo at <http://AnyCodeGen.org>.

### 8. Related Work

Generalizing Previous Approaches Our approach frames code generation as predicting the next node in all partial AST paths. This simple framing generalizes most previous work, without hand-crafted edges and special actions:

• Models that use information about ancestor nodes only [\(Rabinovich et al.,](#page-31-0) [2017\)](#page-31-0), as well as the "Parent Feeding" of [Yin & Neubig](#page-32-0) [\(2017\)](#page-32-0), are generalized by our model, since all paths that go into a node a<sup>t</sup> pass through its parent, and the path from the root is the attention query.

- The "previous action encoding" of [Yin & Neubig](#page-32-0) [\(2017\)](#page-32-0) is also a special case of our approach, because S<sup>t</sup> contains the paths starting from the *previously expanded* leaves of A<sup>p</sup> into the currently expanded node π (at), such as path<sup>3</sup> in Figure [2\(e\).](#page-2-0)
- The "context node" of PHOG [\(Bielik et al.,](#page-30-0) [2016\)](#page-30-0) is just one of the previously-traversed leaf nodes in a<t. Thus, not only that our model conditions on this context node as well, our model also takes into account the *syntactic relation*, i.e., the path, between the context and π (at). Moreover, while PHOG conditions on a single leaf, SLMs condition on *every* leaf in a<t.
- Finally, [Brockschmidt et al.](#page-30-0) [\(2019\)](#page-30-0) define special graph edges (e.g., "NextSib" and "Child") to capture relations on the AST. [Allamanis et al.](#page-30-0) [\(2018\)](#page-30-0) further defines data-flow and control-flow graph edges such as "ComputedFrom" and "GuardedByNegation". Most of these relations can be expressed as partial AST paths without manually designing them.

Program Generation Learning to generate programs is one of the oldest problems in machine learning [\(Waldinger](#page-32-0) [& Lee,](#page-32-0) [1969\)](#page-32-0) and has been considered by some as the "holy grail of computer science" [\(Pnueli & Rosner,](#page-31-0) [1989;](#page-31-0) [Gul](#page-31-0)[wani et al.,](#page-31-0) [2017\)](#page-31-0). Typically, the task is to generate a program given some form of input or context, such as complete formal specifications [\(Green,](#page-31-0) [1981;](#page-31-0) [Si et al.,](#page-31-0) [2019\)](#page-31-0) or input-output examples [\(Gulwani,](#page-31-0) [2011;](#page-31-0) [Devlin et al.,](#page-30-0) [2017;](#page-30-0) [Parisotto et al.,](#page-31-0) [2017;](#page-31-0) [Balog et al.,](#page-30-0) [2017;](#page-30-0) [Gaunt et al.,](#page-30-0) [2017\)](#page-30-0). While these approaches work well in some cases, they are often bounded to DSLs that prevent them from being applied to realistic, general-purpose code.

[Bielik et al.](#page-30-0) [\(2016\)](#page-30-0) learn a dynamic DSL expression that points to a *single* context that guides the generation of

<span id="page-8-0"></span>![](_page_8_Figure_1.jpeg)

Figure 5. An example from our test set in which a compiler-guided generation could filter out non-compiling candidates, and thus rank the ground truth *second* instead of *fifth*. Four out of the five candidates are "tree-match" (marked with ), the fifth candidate is an "exact match" (marked with X in bold), and only the second and the fifth candidate compile (marked with ).

a JavaScript program. [Maddison & Tarlow](#page-31-0) [\(2014\)](#page-31-0) and [Amodio et al.](#page-30-0) [\(2017\)](#page-30-0) generate general-purpose unconditional code, and do not deal with the challenge of fitting the code to a given context.

[Brockschmidt et al.](#page-30-0) [\(2019\)](#page-30-0) addressed a similar code completion task as ours using a graph encoder and a neural attribute grammar decoder. However, they limit their model to generate only primitive types or arrays of these; use a closed vocabulary; and omit user-defined functions. In this paper, we lift these constraints and allow any, generalpurpose, generation of code, of all types and containing any names. As we show in Section [5,](#page-5-0) our model performs significantly better.

[Murali et al.](#page-31-0) [\(2018\)](#page-31-0) generate code given a set of APIs in a "Java-like" language; they state that their approach is thus intrinsically limited to generate only API-heavy programs. [Yin et al.](#page-32-0) [\(2019\)](#page-32-0) generate general-purpose code by applying a given edit to a given code snippet. [Brody et al.](#page-30-0) [\(2020\)](#page-30-0) predict code edits directly given other edits that occurred in the context. [Yin & Neubig](#page-32-0) [\(2017\)](#page-32-0) and [Rabinovich](#page-31-0) [et al.](#page-31-0) [\(2017\)](#page-31-0) used a top-down syntactic approach for generating general-purpose code given a natural language description. Models that address APIs→code, edit→code, or NL→code tasks must model the input separately and differently from the output code. As we show in Section [6,](#page-6-0) modeling the source and the target differently perform poorly in our task, in which the input is code as well.

[Chen et al.](#page-30-0) [\(2018\)](#page-30-0) addressed JavaScript↔CoffeeScript translation with a tree-to-tree approach, which required a strong alignment between the source and target trees.

### 9. Conclusion

We presented a novel approach for any-code completion: joint modeling of an AST and its missing subtree using a structural language model. Our approach generalizes most previous work in this area while reaching state-of-the-art performance on challenging benchmarks. We demonstrate our approach in generating general-purpose code, in restricted and unrestricted settings, in two languages. Our model outperforms a variety of strong baselines, including programming language-oriented models and strong NMT models applied in our settings.

We believe that structural language modeling enables a wide range of future applications, similarly to how language modeling research has contributed to NLP in recent years. Our approach also has a variety of direct applications such as code completion, detecting and fixing unlikely existing code, and re-ranking solutions produced by another synthesizer or solver. To these ends, we make all our code, datasets, and trained models publicly available.

### Acknowledgments

We would like to thank Guy Waldman for developing the [AnyCodeGen.org](http://AnyCodeGen.org) website, Pavol Bielik and Martin Vechev for training their PHOG model on our dataset, Srinivasan Iyer for his useful advice, the guidance in training his model and adapting it to our task, Marc Brockschmidt for his useful implementation tips and guidance in training his model, and Miltiadis Allamanis for the guidance in reproducing his C# dataset.

### <span id="page-9-0"></span>Supplementary Material

|                                   | Java      | C#     |
|-----------------------------------|-----------|--------|
| #projects - training              | 9         | 25     |
| #projects - validation            | 1         | 2      |
| #projects - test                  | 1         | 3      |
| #examples - training              | 1,309,842 | 16,295 |
| #examples - validation            | 10,000    | 8,183  |
| #examples - test                  | 20,000    | 3,305  |
| Avg. number of paths              | 27.8      | 131.1  |
| Avg. source length - lines        | 10.4      | 57.5   |
| Avg. source length - tokens       | 77.7      | 264.3  |
| Avg. source length - subtokens    | 100.6     | 343.6  |
| Avg. target length - tokens       | 5.4       | 3.9    |
| Avg. target length - subtokens    | 7.8       | 5.0    |
| Avg. target length - tree nodes   | 3.8       | 3.9    |
| Avg. target length - tree targets | 10.8      | 10.8   |

Figure 6. Statistics of our datasets. When not mentioned otherwise, the statistic was measured on the training set.

![](_page_9_Figure_4.jpeg)

Figure 7. Efficient computation: partial paths for different time steps share the same prefix, allowing a shared computation. In this example, the prefix is the shared path from the leaf (not shown) to Greater, and is much longer than either of the suffixes.

### A. Data Statistics

Figure 6 shows some statistics of our used datasets. In Java: for the validation set, we randomly sampled 10, 000 examples from the raw validation set; for the test set, we randomly sampled 20, 000 examples from the raw test set.

We will release all datasets, raw and preprocessed, with the final version.

## B. Additional Evaluation Details

For both Java and C# models, we experimented with the following hyper-parameter values. We performed beam search on the validation set after every training iteration, and we selected the best configuration and checkpoint according to accuracy@1 on the validation set. After the best configuration was chosen, we ran a single evaluation run on the test set.

- ; f ∈ {LSTM, T ransformer} – how to encode each path.
- LSTM #layers ∈ {1, 2}
- dsubtoken ∈ {256, 512} embedding size.
- Transformer layers ∈ {0, 1, 2, 3, 4}
- lr ∈ {10<sup>−</sup><sup>3</sup> , 10<sup>−</sup><sup>4</sup> , 10<sup>−</sup><sup>5</sup>} – learning rate
- Learning rate decay every {10000, 20000, 40000} steps.

### C. Qualitative Analysis cont. - Correct Tree, Incorrect Names

In Section [7](#page-6-0) we discussed the gap between *acc@k* and *tree@k*. We found that 30% of the examples in the gap could have been *exact match* if a single subtoken prediction was fixed; 74% of the examples in the gap could have been *exact match* if a single identifier prediction was fixed. Table [4](#page-10-0) shows the accuracy of our model and the leading baselines if a single subtoken or a single token mismatches were counted as correct: *One SubToken Diff* and *One Token Diff* are similar to *exact match*, except that they allow a single subtoken or a single token mistake, respectively. As Table [4](#page-10-0) shows, not only that our model performs better than the baselines in *exact match*, it also shows a greater potential for improvement.

<span id="page-10-0"></span>

|                       | Exact-match (acc@k) |       | One SubToken Diff |       | One Token Diff |       | Tree@k |       |
|-----------------------|---------------------|-------|-------------------|-------|----------------|-------|--------|-------|
| Model                 | @1                  | @5    | @1                | @5    | @1             | @5    | @1     | @5    |
| Transformerbase +copy | 16.65               | 24.05 | 23.08             | 34.06 | 29.39          | 43.46 | 34.68  | 50.52 |
| BiLSTM→LSTM +copy     | 16.93               | 23.17 | 22.39             | 31.68 | 27.23          | 38.92 | 34.29  | 49.72 |
| seq2tree +copy        | 16.81               | 23.04 | 24.02             | 33.89 | 32.67          | 43.75 | 38.14  | 52.36 |
| SLM (this work)       | 18.04               | 24.83 | 24.40             | 35.19 | 33.68          | 46.57 | 39.10  | 55.32 |

Table 4. Examining the gap between *acc@k* and *tree@k*: the *acc@k* and *tree@k* results here are the same as in Table [1;](#page-5-0) *One SubToken Diff* allows a single *sub*token mismatch; *One Token Diff* allows a single token mismatch.

### D. Copying Single Subtokens

In addition to scoring the entire token to be copied, we also score each of the subtokens composing it according to their position. For each position i, we add a scoring function scopy<sup>i</sup> , such that scopy<sup>i</sup> (`) produces the copying score of the i'th subtoken of `, which we denote as `<sup>i</sup> :

$$s\_w = s\_{\text{gen}}(w) + \sum\_{\text{val}(\ell) = w} s\_{\text{copy\\_token}}(\ell) + \sum\_{i} \sum\_{\text{val}(\ell\_i) = w} s\_{\text{copy}\_i}(\ell)$$

P r (a|S) = softmax (s)

Where scopy token is the scoring function of copying the entire token, described in Section [3.3.](#page-3-0)

For example, a token of getX is scored entirely using scopy token; each of its subtokens, get and X, are scored using scopy<sup>1</sup> and scopy<sup>2</sup> respectively. That is, the model can either copy the entire token, or copy only some of its subtokens. This ability is especially useful in generating a name like setX, where getX appears in the context, and X is any unknown, user-defined, subtoken; the model learns to generate set from the vocabulary, and copy only the subtoken X.

```
protected void checkRpcAdminAccess() throws IOException, AccessControlException {
  UserGroupInformation ugi = UserGroupInformation.getCurrentUser();
  UserGroupInformation zkfcUgi = UserGroupInformation.getLoginUser();
  if (adminAcl.isUserAllowed(ugi)
    || ugi.getShortUserName().equals( zkfcUgi.getShortUserName() )) {
      LOG.info("Allowed RPC access from " + ugi
        + " at " + Server.getRemoteAddress());
      return;
    }
  String msg = "Disallowed RPC access from " + ugi
    + " at " + Server.getRemoteAddress() + ". Not listed in " + DFSConfigKeys.DFS_ADMIN;
  LOG.warn(msg);
  throw new AccessControlException(msg);
}
```

| True ref:             | zkfcUgi.getShortUserName() |         |               |
|-----------------------|----------------------------|---------|---------------|
|                       | zkfcUgi.getShortUserName() | (11.7%) | (exact match) |
| SLM top-5 candidates: | DFSConfigKeys.DFS          | (4.5%)  |               |
|                       | zkfcUgi.getUserName()      | (2.6%)  | (tree-match)  |
|                       | zkfcUgi.getUser()          | (1.7%)  | (tree-match)  |
|                       | zkfcUgi.getUserId()        | (0.6%)  | (tree-match)  |

*Entirely copied tokens* are marked in brown; unknown *copied subtokens* are marked in blue; *in-vocabulary* subtokens are marked in black; subtokens that are *both in-vocabulary and copied* from context are marked in purple.

Figure 8. A Java Any-Code Completion example from our test set along with the predictions of our model. The predictions of the baselines are shown in Figure [12](#page-15-0) below.

## <span id="page-11-0"></span>E. Example: Usefulness of Copy Mechanism

As shown in Section [6,](#page-6-0) the ability to copy is crucial for the any-code completion task, because of the repetitive use of identifiers and symbols in programs. Figure [8](#page-10-0) shows a representative example for the necessity of the copy mechanism: generating the ground truth zkfcUgi.getShortUserName() is feasible *only* thanks to the copy mechanism, since zkfc is obviously an UNK subtoken which was not observed in the training data.

In this case, since both zkfcUgi and getShortUserName appear in context, both were copied as *entire tokens*, rather than generated using subtokens. This example also shows how the ability to copy *entire tokens* ease the generation process by reducing the number of target symbols (our SLM model is able to copy and combine single subtokens as well).

# F. Java Examples

Figures [9](#page-12-0) to [18](#page-21-0) contain examples from our test set for the any-code completion task in Java, along with the prediction of our model and some of the baselines. The highlighted expressions are the true references that should be generated. Indentation and line breaks may have been altered for typesetting reasons.

# G. C# Examples

Figures [19](#page-22-0) to [26](#page-29-0) contain examples from our test set for the restricted completion task in C# along with the prediction of our model some of the baselines. The highlighted expressions are the true references that should be generated. Indentation and line breaks may have been altered for typesetting reasons.

```
private C findCounter(T key) {
    int i = key.ordinal();
    if (counters[i] == null) {
        counters[i] = newCounter(key);
    }
    return (C) counters[i] ;
}
```

| Model                 | Prediction                 |
|-----------------------|----------------------------|
| True ref:             | (C) counters[i]            |
|                       | (C) counters[i]<br>(71.6%) |
| SLM (this work)       | (C) this<br>(6.3%)         |
|                       | counters[i]<br>(4.8%)      |
|                       | (C) this                   |
| Transformerbase +copy | (C) counters[i]            |
|                       | (C) counters               |
|                       | (C) this                   |
| BiLSTM→LSTM +copy     | (C) counters[i]            |
|                       | counters[i]                |
|                       | (C) counters[i]            |
| Seq2tree +copy        | (C) counters[i].ordinal()  |
|                       | (C) counters.get(i)        |

```
private void handleTaskFinishedEvent(TaskFinishedEvent event) {
  TaskInfo taskInfo = info.tasksMap.get( event.getTaskId() );
  taskInfo.counters = event.getCounters();
  taskInfo.finishTime = event.getFinishTime();
  taskInfo.status = TaskStatus.State.SUCCEEDED.toString();
  taskInfo.successfulAttemptId = event.getSuccessfulTaskAttemptId();
}
```

| Model                 | Prediction             |                |
|-----------------------|------------------------|----------------|
| True ref:             | event.getTaskId()      |                |
|                       | event.getTaskName()    | (8.8%)         |
|                       | event.getId()          | (8.2%)         |
| SLM (this work)       | event.getTask()        | (3.4%)         |
|                       | event.getName()        | (3.3%)         |
|                       | event.getTaskId()      | (3.3%)         |
|                       | event.getTaskInfo()    |                |
| Transformerbase +copy | event.getTaskId()      |                |
|                       | event.getId()          |                |
|                       | event.getTask()        |                |
|                       | taskInfo.getTaskId()() |                |
|                       | event.name             |                |
| BiLSTM→LSTM +copy     | event.type             |                |
|                       | event.getId()          |                |
|                       | event.id               |                |
|                       | event.getKey()         |                |
|                       | event.getId()          |                |
| Seq2tree +copy        | event.getPath()        |                |
|                       | event.getDescription() |                |
|                       | event.getTaskName()    |                |
|                       | event.getTaskName(     | (Syntax error) |

Figure 9. Java examples from our test set along with the predictions of our model and the baselines.

```
private static void log(String value) {
    if (value!= null && value.length() > 55 )
        value = value.substring(0, 55) + "...";
    LOG.info(value);
}
```

| Model                 | Prediction             |                |
|-----------------------|------------------------|----------------|
| True ref:             | value.length() > 55    |                |
|                       | value.length() > 0     | (9.6%)         |
| SLM (this work)       | value.length() > 55    | (7.3%)         |
|                       | value.startsWith("")   | (1.8%)         |
|                       | value.length() > 55    |                |
| Transformerbase +copy | value.length() > 0)    |                |
|                       | value.length() > 1     |                |
|                       | value.length() > 55    |                |
| BiLSTM→LSTM +copy     | value.startsWith("")   |                |
|                       | value.startsWith("")   |                |
|                       | value.length() 55      | (Syntax error) |
| Seq2tree +copy        | value.endsWith("info") |                |
|                       | value.length() 55      | (Syntax error) |

```
private List<INode> initChildren() {
  if (children == null) {
    final ChildrenDiff combined = new ChildrenDiff();
    for (DirectoryDiff d = DirectoryDiff.this; d != null; d = d.getPosterior() ) {
      combined.combinePosterior(d.diff, null);
    }
    children = combined.apply2Current(ReadOnlyList.Util.asList(
        currentDir.getChildrenList(Snapshot.CURRENT_STATE_ID)));
  }
  return children;
}
```

| Model                 | Prediction                                                                                    |                                                                                        |
|-----------------------|-----------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------|
| True ref:             | d = d.getPosterior()                                                                          |                                                                                        |
| SLM (this work)       | d = d.getParent()<br>d = d.getChildrenList()<br>d = d<br>d = combined<br>d = d.getPosterior() | (18.8%)<br>(14.9%)<br>(4.5%)<br>(2.5%)<br>(1.8%)                                       |
| Transformerbase +copy | d = d<br>d = d.diff<br>d = d.getChildren()<br>d = d.currentDir<br>d = d.currentStateId        |                                                                                        |
| BiLSTM→LSTM +copy     | --d<br>d = d<br>d = d.getParent()<br>d = d.next<br>d = d.get()                                |                                                                                        |
| Seq2tree +copy        | d d.next<br>d d.parent<br>d d.getParent()<br>d d.getChildren()<br>d d.getRoot()               | (Syntax error)<br>(Syntax error)<br>(Syntax error)<br>(Syntax error)<br>(Syntax error) |

Figure 10. Java examples from our test set along with the predictions of our model and the baselines.

```
public float getProgress() {
    this.readLock.lock();
    try {
        if (this.currentAttempt != null) {
            return this.currentAttempt.getProgress() ;
        }
        return 0;
    } finally {
      this.readLock.unlock();
    }
}
```

| Model                 | Prediction                        |         |
|-----------------------|-----------------------------------|---------|
| True ref:             | this.currentAttempt.getProgress() |         |
|                       | this.currentAttempt.getCount()    | (31.3%) |
| SLM (this work)       | -1                                | (30.6%) |
|                       | this.currentAttempt.get()         | (1.5%)  |
|                       | this.currentAttempt.getTime()     | (1.2%)  |
|                       | this.currentAttempt.getProgress() | (0.9%)  |
|                       | this.currentAttempt.getProgress() |         |
| Transformerbase +copy | this.currentAttempt.floatValue()  |         |
|                       | this.currentAttempt.getFloat()    |         |
|                       | this.currentAttempt.get()         |         |
|                       | this.currentAttempt.getTime()     |         |
|                       | this.currentAttempt.getProgress() |         |
| BiLSTM→LSTM +copy     | this.currentAttempt.float()       |         |
|                       | this.currentAttempt.get()         |         |
|                       | this.currentAttempt.size()        |         |
|                       | this.currentAttempt.compute()     |         |
|                       | this.currentAttempt.getProgress() |         |
| Seq2tree +copy        | this.currentAttempt.floatValue()  |         |
|                       | this.currentAttempt.get()         |         |
|                       | this.currentAttempt.getValue()    |         |
|                       | (float)this.currentAttempt.size() |         |

```
public int compareTo(LongWritable o) {
    long thisValue = this.value;
    long thatValue = o.value;
    return (thisValue < thatValue ? -1 : ( thisValue == thatValue ? 0 : 1 ));
}
```

| Model                 | Prediction                           |                |
|-----------------------|--------------------------------------|----------------|
| True ref:             | thisValue == thatValue ?<br>0 :<br>1 |                |
|                       | thisValue == thisValue ?<br>0 :<br>1 | (16.3%)        |
|                       | thisValue == thatValue ?<br>0 :<br>1 | (11.0%)        |
| SLM (this work)       | thisValue == value ?<br>0 :<br>1     | (9.5%)         |
|                       | thatValue >> thatValue               |                |
| Transformerbase +copy | thatValue > thatValue ?<br>1 :<br>0  |                |
|                       | thatValue > thatValue                |                |
|                       | thisValue - thatValue                |                |
| BiLSTM→LSTM +copy     | thatValue & thatValue                |                |
|                       | thatValue ?<br>1 :<br>0              |                |
|                       | thisValue thatValue                  | (Syntax error) |
| Seq2tree +copy        | thisValue thatValue 0 1              | (Syntax error) |
|                       | thisValue thatValue 1 0              | (Syntax error) |

Figure 11. Java examples from our test set along with the predictions of our model and the baselines.

```
private static String getNameServiceId(
    Configuration conf, String addressKey) {
  String nameserviceId = conf.get(DFS_NAMESERVICE_ID);
  if (nameserviceId != null) {
    return nameserviceId;
  }
  Collection<String> nsIds = getNameServiceIds(conf);
  if (1 == nsIds.size() ) {
    return nsIds.toArray(new String[1])[0];
  }
  String nnId = conf.get(DFS_HA_NAMENODE_ID_KEY);
  return
    getSuffixIDs(conf, addressKey, null, nnId, LOCAL_ADDRESS_MATCHER)[0];
}
```

| Model                 | Predictions                                              |                             |
|-----------------------|----------------------------------------------------------|-----------------------------|
| True ref:             | nsIds.size()                                             |                             |
| SLM (this work)       | nsIds.size()<br>conf.size()<br>getSuffixIDs(conf).length | (83.7%)<br>(3.0%)<br>(2.5%) |
| Transformerbase +copy | -1<br>ns.size()<br>conf.size()                           |                             |
| BiLSTM→LSTM +copy     | -1<br>Integer.MAX VALUE<br>conf.size()                   |                             |
| Seq2tree +copy        | 1<br>nsIds.size()<br>stringPool.blank                    |                             |

```
protected void checkRpcAdminAccess() throws
    IOException, AccessControlException {
  UserGroupInformation ugi = UserGroupInformation.getCurrentUser();
  UserGroupInformation zkfcUgi = UserGroupInformation.getLoginUser();
  if (adminAcl.isUserAllowed(ugi) ||
    ugi.getShortUserName().equals( zkfcUgi.getShortUserName() )) {
      LOG.info("Allowed RPC access from " + ugi
        + " at " + Server.getRemoteAddress());
      return;
    }
  String msg = "Disallowed RPC access from " + ugi
    + " at " + Server.getRemoteAddress()
    + ". Not listed in " + DFSConfigKeys.DFS_ADMIN;
  LOG.warn(msg);
  throw new AccessControlException(msg);
}
```

| Model                 | Predictions                                                                          |                             |
|-----------------------|--------------------------------------------------------------------------------------|-----------------------------|
| True ref:             | zkfcUgi.getShortUserName()                                                           |                             |
| SLM (this work)       | zkfcUgi.getShortUserName()<br>DFSConfigKeys.DFS<br>zkfcUgi.getUserName()             | (11.7%)<br>(4.5%)<br>(2.6%) |
| Transformerbase +copy | server.getRemoteAddress()<br>server.getRemoteUserName()<br>server.getShortUserName() |                             |
| BiLSTM→LSTM +copy     | server.getUserName()<br>zkfcUgi.getUserName()<br>ugiUgi.getUserName()                |                             |
| Seq2tree +copy        | dfsConfigKeys.dfsAdmin<br>zkfc.getUserName()<br>zkfcUgi.getRemoteAddress()           |                             |

```
static String replaceSubstitution(
    String base, Pattern from, String to, boolean repeat) {
  Matcher match = from.matcher(base);
  if (repeat) {
    return match.replaceAll(to) ;
  } else {
    return match.replaceFirst(to);
  }
}
```

| Model                 | Prediction                                                                       |                            |
|-----------------------|----------------------------------------------------------------------------------|----------------------------|
| True ref:             | match.replaceAll(to)                                                             |                            |
| SLM (this work)       | match.toString()<br>match.replaceAll(to)<br>match.replaceAll(to, from)           | (9.0%)<br>(8.2%)<br>(6.5%) |
| Transformerbase +copy | match.replaceFirst(to)<br>replace.replaceFirst(to)<br>matcher.replaceFirst(to)   |                            |
| BiLSTM→LSTM +copy     | match.getFirst()<br>match.replaceFirst(to)<br>match.replaceFirst(to, to)         |                            |
| Seq2tree +copy        | match.replaceFirst(base)<br>match.replaceFirst(to)<br>match.replaceFirst(repeat) |                            |

```
public void responseReceived(ResponseReceivedEvent event) {
  RequestResult result = event.getRequestResult();
  Date startDate = result.getStartDate();
  Date stopDate = result.getStopDate();
  long elapsed = stopDate.getTime() - startDate.getTime();
  synchronized (this) {
    this.lastE2Elatency = elapsed;
  }
  if ( LOG.isDebugEnabled() ) {
    int statusCode = result.getStatusCode();
    String etag = result.getEtag();
    HttpURLConnection urlConnection =
        (HttpURLConnection) event.getConnectionObject();
    int contentLength = urlConnection.getContentLength();
    String requestMethod = urlConnection.getRequestMethod();
    long threadId = Thread.currentThread().getId();
    LOG.debug(String.format(
      "SelfThrottlingIntercept:: ResponseReceived:
      ... threadId=%d, Status=%d, Elapsed(ms)=%d,
      ... ETAG=%s, contentLength=%d, requestMethod=%s",
      threadId, statusCode, elapsed, etag, contentLength, requestMethod));
  }
}
```

| Model                 | Prediction                                                                                            |                              |
|-----------------------|-------------------------------------------------------------------------------------------------------|------------------------------|
| True ref:             | LOG.isDebugEnabled()                                                                                  |                              |
| SLM (this work)       | elapsed != null<br>LOG.isDebugEnabled()<br>!LOG.isDebugEnabled()                                      | (32.1%)<br>(29.0%)<br>(2.4%) |
| Transformerbase +copy | stopDate != null<br>result.hasStatusCode()<br>result.hasStatusCode() != elapsed                       |                              |
| BiLSTM→LSTM +copy     | result != null<br>elapsed > 0<br>result.getStatusCode() == workflowConstants.STATUS                   |                              |
| Seq2tree +copy        | event.getConnectionObject() instanceof HttpUrlConnection<br>startDate != null<br>LOG.isDebugEnabled() |                              |

```
private static boolean isNameResolved(InetAddress address) {
  String hostname = address.getHostName() ;
  String ip = address.getHostAddress();
  return !hostname.equals(ip) || NetUtils.isLocalAddress(address);
}
```

| Model                 | Prediction                                  |        |
|-----------------------|---------------------------------------------|--------|
| True ref:             | address.getHostName()                       |        |
|                       | address.getHostname()                       | (3.5%) |
| SLM (this work)       | address.getHostName()                       | (2.0%) |
|                       | inetAddress.getByName(address.getAddress()) | (0.7%) |
|                       | address.getHostAddress()                    |        |
| Transformerbase +copy | address.getLastElement().getValue()         |        |
|                       | address.getAddress()                        |        |
|                       | address.getHostAddress()                    |        |
| BiLSTM→LSTM +copy     | address.getPort()                           |        |
|                       | address.getAddress()                        |        |
|                       | address.getHostAddress()                    |        |
| Seq2tree +copy        | address.getPort()                           |        |
|                       | address.getAddress()                        |        |

```
private synchronized void initJournals(List<URI> dirs) {
  int minimumRedundantJournals = conf.getInt(
      DFSConfigKeys.DFS_NAMENODE_EDITS_DIR_MINIMUM_KEY,
      DFSConfigKeys.DFS_NAMENODE_EDITS_DIR_MINIMUM_DEFAULT);
  journalSet = new JournalSet(minimumRedundantJournals);
  for (URI u : dirs) {
    boolean required =
        FSNamesystem.getRequiredNamespaceEditsDirs(conf).contains(u);
    if ( u.getScheme() .equals(NNStorage.LOCAL_URI_SCHEME)) {
      StorageDirectory sd = storage.getStorageDirectory(u);
      if (sd != null) {
        journalSet.add(
            new FileJournalManager(conf, sd, storage),
            required, sharedEditsDirs.contains(u));
      }
    } else {
      journalSet.add(createJournal(u),
          required, sharedEditsDirs.contains(u));
    }
  }
  if (journalSet.isEmpty()) {
    LOG.error("No edits directories configured!");
  }
}
```

| Model                 | Prediction                                                  |                              |
|-----------------------|-------------------------------------------------------------|------------------------------|
| True ref:             | u.getScheme()                                               |                              |
| SLM (this work)       | u.getName()<br>u.getScheme()<br>u.getVersion()              | (27.4%)<br>(13.1%)<br>(8.2%) |
| Transformerbase +copy | journalSet.LOCAL URI SCHEME<br>u.getName()<br>Boolean.true  |                              |
| BiLSTM→LSTM +copy     | u.toString()<br>Boolean.true<br>u.getURI()                  |                              |
| Seq2tree +copy        | u.getScheme()<br>u.getName()<br>storage.getLocalUriScheme() |                              |

Figure 14. Java examples from our test set along with the predictions of our model and the baselines.

```
static EnumSet<FileAttribute> parse(String s) {
  if (s == null || s.length() == 0) {
    return EnumSet.allOf(FileAttribute.class);
  }
  EnumSet<FileAttribute> set = EnumSet.noneOf(FileAttribute.class);
  FileAttribute[] attributes = values();
  for (char c : s.toCharArray() ) {
    int i = 0;
    for (; i < attributes.length && c != attributes[i].symbol; i++) ;
    if (i < attributes.length) {
      if (!set.contains(attributes[i])) {
        set.add(attributes[i]);
      } else {
        throw new IllegalArgumentException("There are more than one '"
            + attributes[i].symbol + "' in " + s);
      }
    } else {
      throw new IllegalArgumentException("'" + c + "' in "
          + s + " is undefined.");
    }
  }
  return set;
}
```

| Model                 | Prediction                                                             |                              |
|-----------------------|------------------------------------------------------------------------|------------------------------|
| True ref:             | s.toCharArray()                                                        |                              |
| SLM (this work)       | s.toCharArray()<br>attributes[0].value<br>attributes[undefined].length | (22.4%)<br>(18.5%)<br>(4.6%) |
| Transformerbase +copy | s.split(" "<br>set.split(" ")<br>attributes.keySet()                   |                              |
| BiLSTM→LSTM +copy     | attributes.length<br>attributes[0]<br>attributes[0].next               |                              |
| Seq2tree +copy        | set.toArray()<br>s.toCharArray()<br>set.toCharArray()                  |                              |

```
public static Path[] stat2Paths(FileStatus[] stats) {
  if (stats == null)
    return null;
  Path[] ret = new Path[stats.length];
  for (int i = 0; i < stats.length; ++i) {
    ret[i] = stats[i].getPath() ;
  }
  return ret;
```
}

| Model                 | Prediction                                                          |                             |
|-----------------------|---------------------------------------------------------------------|-----------------------------|
| True ref:             | stats[i].getPath()                                                  |                             |
| SLM (this work)       | stats[i].getPath()<br>Path(stats[i])<br>new Path(stats[i], charset) | (25.2%)<br>(3.3%)<br>(2.5%) |
| Transformerbase +copy | stats[i]<br>stats[i].getPath()<br>new Path(stats[i])                |                             |
| BiLSTM→LSTM +copy     | stats[i]<br>new Path(stats[i])<br>stats[i].toString()               |                             |
| Seq2tree +copy        | stats[i]<br>new Path(stats[i])<br>stat(stats[i])                    |                             |

Figure 15. Java examples from our test set along with the predictions of our model and the baselines.

```
void ensureCurrentDirExists() throws IOException {
  for (
      Iterator<StorageDirectory> it = storage.dirIterator();
      it.hasNext(); ) {
    StorageDirectory sd = it.next();
    File curDir = sd.getCurrentDir();
    if ( !curDir.exists() && !curDir.mkdirs()) {
      throw new IOException("Could not create directory " + curDir);
    }
  }
}
```

| Model                 | Prediction                                            |                               |
|-----------------------|-------------------------------------------------------|-------------------------------|
| True ref:             | !curDir.exists()                                      |                               |
| SLM (this work)       | !curDir.exists()<br>curDir != null<br>curDir.exists() | (29.0%)<br>(25.8%)<br>(24.4%) |
| Transformerbase +copy | curDir != null<br>!curDir.exists()<br>curDir.exists() |                               |
| BiLSTM→LSTM +copy     | curDir != null<br>curDir.exists()<br>sd != null       |                               |
| Seq2tree +copy        | curDir != null<br>curDir.exists()<br>!curDir.exists() |                               |

```
public static byte[] getXAttr(final Map<?, ?> json, final String name)
    throws IOException {
  if (json == null) {
    return null;
  }
  Map<String, byte[]> xAttrs = toXAttrs(json);
  if (xAttrs != null) {
    return xAttrs.get(name) ;
  }
  return null;
}
```

| Model                 | Prediction                                 |                  |
|-----------------------|--------------------------------------------|------------------|
| True ref:             | xAttrs.get(name)                           |                  |
|                       | xAttrs.get(name)                           | (28.2%)          |
| SLM (this work)       | xAttrs.get(xAttrs)<br>xAttrs.toByteArray() | (5.8%)<br>(4.4%) |
|                       | xAttrs.get(name)                           |                  |
| Transformerbase +copy | xAttrs.toByteArray()                       |                  |
|                       | new byte[0]                                |                  |
|                       | xAttrs.getBytes()                          |                  |
| BiLSTM→LSTM +copy     | new byte[0]                                |                  |
|                       | xAttrs.toByteArray()                       |                  |
|                       | xAttrs.get(name)                           |                  |
| Seq2tree +copy        | xAttrs.get()                               |                  |
|                       | xAttrs.get(0)                              |                  |

Figure 16. Java examples from our test set along with the predictions of our model and the baselines.

```
private void setFlag(long flag) {
  long prev;
  do {
    prev = unsafe.getLongVolatile(null, this.slotAddress);
    if ( (prev & flag) != 0) {
      return;
    }
  } while (!unsafe.compareAndSwapLong(
              null, this.slotAddress, prev, prev | flag));
}
```

| Model                 | Prediction                                         |                |
|-----------------------|----------------------------------------------------|----------------|
| True ref:             | (prev & flag)                                      |                |
| SLM (this work)       | (prev & flag)                                      | (8.9%)         |
|                       | (prev & flagSlot)                                  | (5.4%)         |
|                       | unsafe.get(prev)                                   | (5.0%)         |
| Transformerbase +copy | (prev & flag)                                      |                |
|                       | (prev   flag)                                      |                |
|                       | unsafe.compareTo(prev)                             |                |
| BiLSTM→LSTM +copy     | prev                                               |                |
|                       | prev + 1                                           |                |
|                       | prev - 1                                           |                |
| Seq2tree +copy        | unsafe prev flag                                   | (Syntax error) |
|                       | (volatile prev unsafe.get())                       | (Syntax error) |
|                       | (volatile prev unsafe.getLongVolatile(null, prev)) | (Syntax error) |

```
public synchronized void setInput(byte[] b, int off, int len) {
  if (b == null) {
    throw new NullPointerException();
  }
  if (off < 0 || len < 0 || off > b.length - len) {
    throw new ArrayIndexOutOfBoundsException();
  }
  finished = false;
  if (len > uncompressedDirectBuf.remaining()) {
    this.userBuf = b;
    this.userBufOff = off;
    this.userBufLen = len;
  } else {
    ((ByteBuffer) uncompressedDirectBuf).put(b, off, len);
    uncompressedDirectBufLen = uncompressedDirectBuf.position();
  }
  bytesRead += len;
}
```

| Model                 | Predictions                                                                  |
|-----------------------|------------------------------------------------------------------------------|
| True ref:             | len < 0                                                                      |
| SLM (this work)       | len < 0<br>(41.3%)<br>off > b.length<br>(23.4%)<br>len > b.length<br>(14.1%) |
| Transformerbase +copy | off < 0<br>len < 0<br>b == null                                              |
| BiLSTM→LSTM +copy     | off < 0<br>len < 0<br>b == null                                              |
| Seq2tree +copy        | off < 0<br>len < 0<br>0 < off                                                |

Figure 17. Java examples from our test set along with the predictions of our model and the baselines.

```
private int readData(byte[] buf, int off, int len) throws IOException {
  int bytesRead = 0;
  while (bytesRead < len) {
    int n = IOUtils.wrappedReadForCompressedData(
         in, buf, off + bytesRead , len - bytesRead);
    if (n < 0) {
      return bytesRead;
    }
    bytesRead += n;
  }
  return len;
}
```

| Model                 | Prediction                                                  |                              |
|-----------------------|-------------------------------------------------------------|------------------------------|
| True ref:             | off + bytesRead                                             |                              |
| SLM (this work)       | bytesRead - bytesRead<br>off + bytesRead<br>off - bytesRead | (35.0%)<br>(14.1%)<br>(9.4%) |
| Transformerbase +copy | off - bytesRead<br>off + len<br>len - bytesRead             |                              |
| BiLSTM→LSTM +copy     | -bytesRead<br>bytesRead++<br>bytesRead - bytesRead          |                              |
| Seq2tree +copy        | compressed bytesRead<br>off + bytesRead<br>len - bytesRead  | (Syntax error)               |

```
private Path getPath(int curId, int limitPerDir, Type type) {
  if (curId <= 0) {
    return basePath;
  }
  String name = "";
  switch(type) {
    case FILE:
      name = FILE_PREFIX + new Integer(curId % limitPerDir).toString();
      break;
    case DIRECTORY:
      name = DIR_PREFIX + new Integer(curId % limitPerDir).toString();
      break;
  }
  Path base = getPath((curId / limitPerDir), limitPerDir, Type.DIRECTORY);
  return new Path(base, name) ;
}
```

| Model                 | Prediction                                                                                                            |
|-----------------------|-----------------------------------------------------------------------------------------------------------------------|
| True ref:             | new Path(base, name)                                                                                                  |
| SLM (this work)       | new Path(base, name)<br>(6.0%)<br>new Path(base, name, limitPerDir)<br>(2.9%)<br>new Path(base, name, type)<br>(2.8%) |
| Transformerbase +copy | new Path(base)<br>new Path(name)<br>getPath(base)                                                                     |
| BiLSTM→LSTM +copy     | new Path(base)<br>new File(base)<br>new Path(base.getPath())                                                          |
| Seq2tree +copy        | new Path(base)<br>new File(base, name)<br>new Path(base, name)                                                        |

Figure 18. Java examples from our test set along with the predictions of our model and the baselines.

```
private static IEnumerable<Token> OfSequence(
    this IEnumerable<Token> tokens, Token nameToken, TypeDescriptor info)
{
  var nameIndex = tokens.IndexOf(t => t.Equals(nameToken));
  if ( nameIndex >= 0 )
  {
    return info.NextValue.MapValueOrDefault(
        _ => info.MaxItems.MapValueOrDefault(
          n => tokens.Skip(nameIndex + 1).Take(n),
               tokens.Skip(nameIndex + 1).TakeWhile(v => v.IsValue())),
        tokens.Skip(nameIndex + 1).TakeWhile(v => v.IsValue()));
  }
  return new Token[] { };
}
```

| Model                               | Prediction                 |
|-------------------------------------|----------------------------|
| True ref:                           | nameIndex >= 0             |
|                                     | nameIndex >= 0<br>(22.6%)  |
| SLM (this work)                     | nameIndex == -1<br>(19.1%) |
|                                     | nameIndex > -1<br>(13.9%)  |
|                                     | !nameIndex                 |
| BiLSTM→LSTM +copy                   | nameIndex == -1            |
|                                     | nameIndex < 0              |
|                                     | nameIndex == 0             |
| GNN→NAG (Brockschmidt et al., 2019) | nameIndex > 0              |
|                                     | nameIndex < 0              |

```
public static IEnumerable<T[]> Group<T>(
    this IEnumerable<T> source, int groupSize)
{
  if (groupSize < 1)
  {
    throw new ArgumentOutOfRangeException(nameof(groupSize));
  }
  T[] group = new T[groupSize];
  int groupIndex = 0;
  foreach (var item in source)
  {
    group[groupIndex++] = item;
    if ( groupIndex == groupSize )
    {
      yield return group;
      group = new T[groupSize];
      groupIndex = 0;
    }
  }
}
```

| Model                               | Prediction                                                                 |                              |
|-------------------------------------|----------------------------------------------------------------------------|------------------------------|
| True ref:                           | groupIndex == groupSize                                                    |                              |
| SLM (this work)                     | groupIndex < 0<br>groupIndex == -1<br>groupIndex < groupIndex              | (21.4%)<br>(10.3%)<br>(5.3%) |
| BiLSTM→LSTM +copy                   | group.IsNullOrEmpty()<br>groupGroup[groupIndex++]<br>group.EndsWith(group) |                              |
| GNN→NAG (Brockschmidt et al., 2019) | groupIndex == 0<br>groupIndex == 1<br>groupIndex == groupSize              |                              |

Figure 19. C# examples from our test set of the restricted completion task along with the predictions of our model and the baselines.

```
internal static void AddLine(StringBuilder builder,
    string value, int maximumLength)
{
  if (builder == null)
  {
    throw new ArgumentNullException(nameof(builder));
  }
  if (value == null)
  {
    throw new ArgumentNullException(nameof(value));
  }
  if (maximumLength < 1)
  {
    throw new ArgumentOutOfRangeException(nameof(value));
  }
  value = value.Trim() ;
  builder.AppendWhen(builder.Length > 0, Environment.NewLine);
  do
  {
    var wordBuffer = 0;
    var words = value.Split(' ');
    for (var i = 0; i < words.Length; i++)
    {
      if (words[i].Length < (maximumLength - wordBuffer))
      {
        builder.Append(words[i]);
        wordBuffer += words[i].Length;
        if ((maximumLength - wordBuffer) > 1 && i != words.Length - 1)
        {
          builder.Append(" ");
          wordBuffer++;
        }
      }
      else if (words[i].Length >= maximumLength && wordBuffer == 0)
      {
        builder.Append(words[i].Substring(0, maximumLength));
        wordBuffer = maximumLength;
        break;
      }
      else break;
    }
    value = value.Substring(Math.Min(wordBuffer, value.Length));
    builder.AppendWhen(value.Length > 0, Environment.NewLine);
  }
  while (value.Length > maximumLength);
  builder.Append(value);
}
```

| Model             | Prediction                                                                                      |                               |
|-------------------|-------------------------------------------------------------------------------------------------|-------------------------------|
| True ref:         | value.Trim()                                                                                    |                               |
| SLM (this work)   | value.Trim()<br>value.Substring(0, maximumLength)<br>value.Replace(maximumLength, maximumLength | (16.0%)<br>(10.9%)<br>(10.7%) |
| BiLSTM→LSTM +copy | maximumLength - 1<br>value.Trim()<br>valueLength++                                              |                               |
| GNN→NAG           | value + <UNK><br>value + maximumLength<br>value.Substring(0, maximumLength)                     |                               |

![](_page_23_Figure_3.jpeg)

| return array.Select(item =>         | item.Trim() ).ToArray();                                 |                             |
|-------------------------------------|----------------------------------------------------------|-----------------------------|
| Model                               | Prediction                                               |                             |
| True ref:                           | item.Trim()                                              |                             |
| SLM (this work)                     | item.Trim()<br>item.ToUpperInvariant()<br>item.ToUpper() | (20.1%)<br>(3.5%)<br>(1.6%) |
| BiLSTM→LSTM +copy                   | item.Trim()<br>item.ToTrim()<br>item.]                   | (Syntax error)              |
| GNN→NAG (Brockschmidt et al., 2019) | item + <UNK><br>item + item<br>item + 1                  |                             |

```
public static string Camelize(this string input)
{
    var word = Pascalize(input);
    return word.Substring(0, 1) .ToLower() + word.Substring(1) ;
```
}

| Model             | Prediction                                                               |                                                                              |  |
|-------------------|--------------------------------------------------------------------------|------------------------------------------------------------------------------|--|
| True ref:         | word.Substring(0, 1)                                                     | word.Substring(1)                                                            |  |
| SLM (this work)   | word.Substring(0, 1)<br>word.Trim()<br>word.Substring(1)                 | word.Substring(1)<br>wordData.Substring(1)<br>word.Substring(0, 1)           |  |
| BiLSTM→LSTM +copy | input.Replace("&", " )<br>input.Replace(1, '')<br>input.Replace("&", "") | input.Replace("&", " <UNK> )<br>input + "." + input<br>input.Substring(0, 1) |  |
| GNN→NAG           | word.CombineWith(<UNK>)<br>word.Trim()<br>word.CombineWith(input)        | word.CombineWith(<UNK>)<br>word + <UNK><br>word.Replace(<UNK>, <UNK>)        |  |

Figure 21. C# examples from our test set of the restricted completion task along with the predictions of our model and the baselines.

```
public string Truncate(string value, int length, string truncationString,
    TruncateFrom truncateFrom = TruncateFrom.Right)
{
  if (value == null)
    return null;
  if (value.Length == 0)
    return value;
  if (truncationString == null)
    truncationString = string.Empty;
  if (truncationString.Length > length)
    return truncateFrom == TruncateFrom.Right ?
      value.Substring(0, length) : value.Substring(value.Length - length);
  var alphaNumericalCharactersProcessed = 0;
  if (value.ToCharArray().Count(char.IsLetterOrDigit) <= length)
    return value;
  if (truncateFrom == TruncateFrom.Left)
  {
    for (var i = value.Length - 1; i > 0; i--)
    {
      if (char.IsLetterOrDigit(value[i]))
        alphaNumericalCharactersProcessed++;
      if (alphaNumericalCharactersProcessed + truncationString.Length
          == length)
        return truncationString + value.Substring(i);
    }
  }
  for (var i = 0; i < value.Length - truncationString.Length; i++)
  {
    if (char.IsLetterOrDigit(value[i]))
      alphaNumericalCharactersProcessed++ ;
    if (alphaNumericalCharactersProcessed + truncationString.Length
        == length)
      return value.Substring(0, i + 1) + truncationString;
  }
  return value;
}
```

| Model             | Prediction                          |         |
|-------------------|-------------------------------------|---------|
| True ref:         | alphaNumericalCharactersProcessed++ |         |
|                   | alphaNumericalCharactersProcessed++ | (48.1%) |
| SLM (this work)   | iCount++                            | (5.8%)  |
|                   | iIndex++                            | (1.6%)  |
|                   | i++                                 |         |
| BiLSTM→LSTM +copy | truncation++                        |         |
|                   | alpha--                             |         |
|                   | alphaNumericalCharactersProcessed++ |         |
| GNN→NAG           | alphaNumericalCharactersProcessed-- |         |
|                   | --alphaNumericalCharactersProcessed |         |

Figure 22. C# examples from our test set of the restricted completion task along with the predictions of our model and the baselines.

```
public static int BinarySearch<TItem, TSearch>(
    this IList<TItem> list, TSearch value,
    Func<TSearch, TItem, int> comparer)
{
  if (list == null)
  {
    throw new ArgumentNullException("list");
  }
  if (comparer == null)
  {
    throw new ArgumentNullException("comparer");
  }
  var lower = 0;
  var upper = list.Count - 1;
  while (lower <= upper)
  {
    var middle = lower + (upper - lower) / 2;
    var comparisonResult = comparer(value, list[middle]);
    if ( comparisonResult < 0 )
    {
      upper = middle - 1;
    }
    else if ( comparisonResult > 0 )
    {
      lower = middle + 1;
    }
    else
    {
      return middle;
    }
  }
  return lower;
}
```

| Model             | Prediction                                                                 |                                                                             |
|-------------------|----------------------------------------------------------------------------|-----------------------------------------------------------------------------|
| True ref:         | comparisonResult < 0                                                       | comparisonResult > 0                                                        |
| SLM (this work)   | comparisonResult < 0<br>comparisonResult > 0<br>middle == comparisonResult | comparisonResult > 0<br>comparisonResult < 0<br>comparisonResult == 0       |
| BiLSTM→LSTM +copy | lowerResult == middle<br>lowerResult == 0<br>lower != middle               | lower < 0<br>lower + "."<br>lower != middle                                 |
| GNN→NAG           | comparisonResult == 0<br>comparisonResult > 0<br>comparisonResult < 0      | comparisonResult == 0<br>comparisonResult > 0<br>comparisonResult == middle |

Figure 23. C# examples from our test set of the restricted completion task along with the predictions of our model and the baselines.

```
public override string ToString()
{
  // use reflection to display all the properties that
  // ... have non default values
  StringBuilder result = new StringBuilder();
  var props = this.GetType().GetTypeInfo().DeclaredProperties;
  result.AppendLine("{");
  foreach (var prop in props)
  {
    if (prop.Name != "Content" && prop.Name != "Subtitle"
        && prop.Name != "Title" && prop.Name != "UniqueId")
    {
        object value = prop.GetValue(this);
        bool valueIsNull = value == null;
        object defaultValue = Common.GetDefault(prop.PropertyType);
        bool defaultValueIsNull = defaultValue == null;
        if ((valueIsNull != defaultValueIsNull)
            // one is null when the other isn't
          || ( !valueIsNull
               && (value.ToString() != defaultValue.ToString())))
            // both aren't null, so compare as strings
        {
          result.AppendLine(prop.Name + " : " + prop.GetValue(this));
        }
    }
  }
  result.AppendLine("}");
  return result.ToString();
}
```

| Model             | Prediction                                                                                   |                             |
|-------------------|----------------------------------------------------------------------------------------------|-----------------------------|
| True ref:         | !valueIsNull                                                                                 |                             |
| SLM (this work)   | !valueIsNull<br>!defaultValueIsNull<br>!valueIsNull.IsNullOrEmpty()                          | (52.4%)<br>(9.0%)<br>(3.2%) |
| BiLSTM→LSTM +copy | !defaultValueIsNull<br>(defaultValueIsNull    value)<br>(defaultValueIsNull    defaultValue) |                             |
| GNN→NAG           | !valueIsNull<br>!defaultValueIsNull<br>!!valueIsNull                                         |                             |

Figure 24. C# examples from our test set of the restricted completion task along with the predictions of our model and the baselines.

```
public TradierOrderResponse PlaceOrder(string accountId,
    TradierOrderClass classification,
    TradierOrderDirection direction,
    string symbol,
    decimal quantity,
    decimal price = 0,
    decimal stop = 0,
    string optionSymbol = "",
    TradierOrderType type = TradierOrderType.Market,
    TradierOrderDuration duration = TradierOrderDuration.GTC)
{
    //Compose the request:
    var request = new RestRequest("accounts/{accountId}/orders");
    request.AddUrlSegment("accountId", accountId.ToString());
    //Add data:
    request.AddParameter("class", GetEnumDescription(classification));
    request.AddParameter("symbol", symbol);
    request.AddParameter("duration", GetEnumDescription(duration));
    request.AddParameter("type", GetEnumDescription(type));
    request.AddParameter("quantity", quantity);
    request.AddParameter("side", GetEnumDescription(direction));
    //Add optionals:
    if (price > 0) request.AddParameter("price", Math.Round(price, 2));
    if (stop > 0) request.AddParameter("stop", Math.Round(stop, 2));
    if ( optionSymbol != "" )
        request.AddParameter("option_symbol", optionSymbol);
    //Set Method:
    request.Method = Method.POST;
    return Execute<TradierOrderResponse>(request,
        TradierApiRequestType.Orders);
```
}

| Model             | Prediction                     |                |
|-------------------|--------------------------------|----------------|
| True ref:         | optionSymbol != ""             |                |
| SLM (this work)   | optionSymbol != ""             | (5.5%)         |
|                   | optionSymbol == ""             | (4.4%)         |
|                   | optionSymbol.IsNullOrEmpty()   | (1.1%)         |
| BiLSTM→LSTM +copy | !stopSymbol                    |                |
|                   | stopSymbol != optionSymbol     |                |
|                   | (stopSymbol " && optionSymbol) | (Syntax error) |
| GNN→NAG           | optionSymbol == <UNK>          |                |
|                   | optionSymbol == symbol         |                |
|                   | optionSymbol != symbol         |                |

Figure 25. C# examples from our test set of the restricted completion task along with the predictions of our model and the baselines.

```
[Test, TestCaseSource("GetLeanDataLineTestParameters")]
public void GetSourceMatchesGenerateZipFilePath(
    LeanDataLineTestParameters parameters)
{
    var source = parameters.Data.GetSource(
        parameters.Config, parameters.Data.Time.Date, false);
    var normalizedSourcePath = new FileInfo(source.Source).FullName;
    var zipFilePath = LeanData.GenerateZipFilePath(
        Globals.DataFolder, parameters.Data.Symbol,
        parameters.Data.Time.Date,
        parameters.Resolution, parameters.TickType);
    var normalizeZipFilePath = new FileInfo(zipFilePath).FullName;
    var indexOfHash = normalizedSourcePath.LastIndexOf(
        "#", StringComparison.Ordinal);
    if (indexOfHash > 0)
    {
        normalizedSourcePath =
             normalizedSourcePath.Substring(0, indexOfHash) ;
    }
    Assert.AreEqual(normalizeZipFilePath, normalizedSourcePath);
}
```

| Model             | Prediction                                                                                                                                        |                             |
|-------------------|---------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------|
| True ref:         | normalizedSourcePath.Substring(0, indexOfHash)                                                                                                    |                             |
| SLM (this work)   | normalizedSourcePath.Substring(0, indexOfHash)<br>normalizedSourcePath.Substring(1)<br>normalizedSourcePath.Remove(indexOfHash)                   | (28.3%)<br>(8.8%)<br>(8.2%) |
| BiLSTM→LSTM +copy | indexOfHash + "<UNK>"<br>indexOfHash > normalizedOfHash<br>indexOfHash > 0                                                                        |                             |
| GNN→NAG           | normalizedSourcePath + normalizeZipFilePath<br>normalizedSourcePath + normalizedSourcePath<br>normalizedSourcePath + normalizeZipFilePath + <UNK> |                             |

Figure 26. C# examples from our test set of the restricted completion task along with the predictions of our model and the baselines.

### <span id="page-30-0"></span>References

- Aharoni, R. and Goldberg, Y. Towards string-to-tree neural machine translation. In *Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)*, pp. 132–140, 2017.
- Allamanis, M. The adverse effects of code duplication in machine learning models of code. In *Proceedings of the 2019 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software*, pp. 143–153. ACM, 2019.
- Allamanis, M., Tarlow, D., Gordon, A., and Wei, Y. Bimodal modelling of source code and natural language. In *International conference on machine learning*, pp. 2123–2132, 2015.
- Allamanis, M., Peng, H., and Sutton, C. A convolutional attention network for extreme summarization of source code. In *International conference on machine learning*, pp. 2091–2100, 2016.
- Allamanis, M., Brockschmidt, M., and Khademi, M. Learning to represent programs with graphs. In *International Conference on Learning Representations*, 2018.
- Alon, U. and Yahav, E. On the bottleneck of graph neural networks and its practical implications. *arXiv preprint arXiv:2006.05205*, 2020.
- Alon, U., Zilberstein, M., Levy, O., and Yahav, E. A general path-based representation for predicting program properties. In *Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation*, pp. 404–419, 2018.
- Alon, U., Brody, S., Levy, O., and Yahav, E. code2seq: Generating sequences from structured representations of code. In *International Conference on Learning Representations*, 2019a.
- Alon, U., Zilberstein, M., Levy, O., and Yahav, E. code2vec: Learning distributed representations of code. *Proceedings of the ACM on Programming Languages*, 3(POPL):1–29, 2019b.
- Amodio, M., Chaudhuri, S., and Reps, T. Neural attribute machines for program generation. *arXiv preprint arXiv:1705.09231*, 2017.
- Balog, M., Gaunt, A. L., Brockschmidt, M., Nowozin, S., and Tarlow, D. Deepcoder: Learning to write programs. In *International Conference on Learning Representations*, 2017.
- Bielik, P., Raychev, V., and Vechev, M. Phog: probabilistic model for code. In *International Conference on Machine Learning*, pp. 2933–2942, 2016.
- Brockschmidt, M., Allamanis, M., Gaunt, A. L., and Polozov, O. Generative code modeling with graphs. In *International Conference on Learning Representations*, 2019.
- Brody, S., Alon, U., and Yahav, E. Neural edit completion. *arXiv preprint arXiv:2005.13209*, 2020.
- Chen, X., Liu, C., and Song, D. Tree-to-tree neural networks for program translation. In *Advances in Neural Information Processing Systems*, pp. 2547–2557, 2018.
- Devlin, J., Uesato, J., Bhupatiraju, S., Singh, R., Mohamed, A.-r., and Kohli, P. Robustfill: Neural program learning under noisy i/o. In *International Conference on Machine Learning*, pp. 990–998, 2017.
- Dong, L. and Lapata, M. Coarse-to-fine decoding for neural semantic parsing. In *Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)*, pp. 731–742, 2018.
- Ellis, K., Nye, M., Pu, Y., Sosa, F., Tenenbaum, J., and Solar-Lezama, A. Write, execute, assess: Program synthesis with a repl. In *Advances in Neural Information Processing Systems*, pp. 9169–9178, 2019.
- Fernandes, P., Allamanis, M., and Brockschmidt, M. Structured neural summarization. In *International Conference on Learning Representations*, 2019.
- Gaunt, A. L., Brockschmidt, M., Kushman, N., and Tarlow, D. Differentiable programs with neural libraries. In *International Conference on Machine Learning*, pp. 1213–1222, 2017.
- <span id="page-31-0"></span>Green, C. Application of theorem proving to problem solving. In *Readings in Artificial Intelligence*, pp. 202–222. Elsevier, 1981.
- Gu, J., Lu, Z., Li, H., and Li, V. O. Incorporating copying mechanism in sequence-to-sequence learning. In *Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)*, pp. 1631–1640, 2016.
- Gulwani, S. Automating string processing in spreadsheets using input-output examples. In *Proceedings of the 38th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages*, pp. 317–330, 2011.
- Gulwani, S., Polozov, O., Singh, R., et al. Program synthesis. *Foundations and Trends® in Programming Languages*, 4 (1-2):1–119, 2017.
- Iyer, S., Konstas, I., Cheung, A., and Zettlemoyer, L. Mapping language to code in programmatic context. In *Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing*, pp. 1643–1652, 2018.
- Iyer, S., Cheung, A., and Zettlemoyer, L. Learning programmatic idioms for scalable semantic parsing. In *Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)*, pp. 5429–5438, 2019.
- Kingma, D. and Ba, J. Adam: A method for stochastic optimization. In *International Conference on Learning Representations*, 2015.
- Klein, G., Kim, Y., Deng, Y., Senellart, J., and Rush, A. M. Opennmt: Open-source toolkit for neural machine translation. In *Proceedings of ACL 2017, System Demonstrations*, pp. 67–72, 2017.
- Ling, W., Blunsom, P., Grefenstette, E., Hermann, K. M., Kocisk ˇ y, T., Wang, F., and Senior, A. Latent predictor networks ` for code generation. In *Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)*, pp. 599–609, 2016.
- Luong, M.-T., Pham, H., and Manning, C. D. Effective approaches to attention-based neural machine translation. In *Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing*, pp. 1412–1421, 2015.
- Maddison, C. and Tarlow, D. Structured generative models of natural source code. In *International Conference on Machine Learning*, pp. 649–657, 2014.
- Murali, V., Qi, L., Chaudhuri, S., and Jermaine, C. Neural sketch learning for conditional program generation. In *International Conference on Learning Representations*, 2018.
- Parisotto, E., Mohamed, A.-r., Singh, R., Li, L., Zhou, D., and Kohli, P. Neuro-symbolic program synthesis. In *International Conference on Learning Representations*, 2017.
- Pnueli, A. and Rosner, R. On the synthesis of a reactive module. In *Proceedings of the 16th ACM SIGPLAN-SIGACT symposium on Principles of programming languages*, pp. 179–190. ACM, 1989.
- Polozov, O. and Gulwani, S. Flashmeta: a framework for inductive program synthesis. In *Proceedings of the 2015 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications*, pp. 107– 126, 2015.
- Rabinovich, M., Stern, M., and Klein, D. Abstract syntax networks for code generation and semantic parsing. In *Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)*, pp. 1139–1149, 2017.
- Raychev, V., Bielik, P., Vechev, M., and Krause, A. Learning programs from noisy data. In *Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages*, pp. 761–774, 2016.
- Si, X., Yang, Y., Dai, H., Naik, M., and Song, L. Learning a meta-solver for syntax-guided program synthesis. In *International Conference on Learning Representations*, 2019.
- Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., and Polosukhin, I. Attention is all you need. In *Advances in Neural Information Processing Systems*, pp. 6000–6010, 2017.
- <span id="page-32-0"></span>Waldinger, R. J. and Lee, R. C. Prow: A step toward automatic program writing. In *Proceedings of the 1st international joint conference on Artificial intelligence*, pp. 241–252, 1969.
- Xiao, C., Dymetman, M., and Gardent, C. Sequence-based structured prediction for semantic parsing. In *Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)*, pp. 1341–1350, 2016.
- Yin, P. and Neubig, G. A syntactic neural model for general-purpose code generation. In *Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)*, pp. 440–450, 2017.
- Yin, P., Neubig, G., Allamanis, M., Brockschmidt, M., and Gaunt, A. L. Learning to represent edits. In *International Conference on Learning Representations*, 2019.
- Young, H., Bastani, O., and Naik, M. Learning neurosymbolic generative models via program synthesis. In *International Conference on Machine Learning*, pp. 7144–7153, 2019.
- Yu, T., Li, Z., Zhang, Z., Zhang, R., and Radev, D. Typesql: Knowledge-based type-aware neural text-to-sql generation. In *Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)*, pp. 588–594, 2018.
- Zhao, R., Bieber, D., Swersky, K., and Tarlow, D. Neural networks for modeling source code edits. *arXiv preprint arXiv:1904.02818*, 2019.