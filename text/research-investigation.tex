\chapter{Research Investigation}\label{chap:research-investigation}  % other option are Experimental Results, Research Exploration, Research Assessment

% TODO: use term "inlier" when discussing the gradient masking impact
% TODO: highlight that we extrapolate the results of inlier gradient masking to outlier

In this chapter we describe the research aspect of the thesis.  % TODO: add description 

% TODO: refer tiny paper and mention the reason of number differences

\section{Research Questions}

To investigate the nature of in-context learning capabilities of Code LLMs, we consider the following research questions:

\begin{sloppypar}
\begin{description}
    \item[RQ.A1]\phantomsection\label{rq:rq-a1} \textbf{\nameref{sec:composition-impact-on-inference}:} Does the quality improvement of code completion depend on the composition strategy employed during model inference?
    \item[RQ.A2]\phantomsection\label{rq:rq-a2} \textbf{\nameref{sec:fine-tuning-on-compositions}:} Does fine-tuning a pre-trained Code LLM with a specific context composer enhance the subsequent quality of code completion?
    \item[RQ.B1]\phantomsection\label{rq:rq-b1} \textbf{\nameref{sec:effect-of-context-extension}:} Does the repository-level pre-training step affect the in-context learning abilities of the model developed during earlier stages?
    \item[RQ.B2]\phantomsection\label{rq:rq-b2} \textbf{\nameref{sec:influence-of-composition-on-context-extension}:} Does the quality improvement of code completion depend on the context composition approach used during the repository-level pre-training step?
\end{description}
\end{sloppypar}

\section{Experimental Design}

In this section we describe the unified experimental design for all the four research questions while the specific details are deferred to the subsequent sections dedicated to each research question separately. % TODO

\subsection{Training Data}

The dataset utilized in this research was provided by the supporting company and is based on the methodology outlined in \citet{bogomolov2024}. The dataset was constructed by traversing the GitHub histories of Python repositories and applying permissive license filtering to sample completion files and their corresponding parent commits. Each data point consists of a pair: a list of Python completion files and a repository snapshot that captures the state of the repository at the time the completion files were added. The snapshot includes all text files except for the completion files themselves. To prevent contamination of the benchmark used in the evaluation, any repositories present in the benchmark were excluded from the training data.

The resulting corpus comprises 1,640 repositories, 160,801 commits, and 361,052 completion files. The completion files contain a total of 1.7 billion characters, while the repository snapshot files contain 4.8 trillion characters.

To delineate the scope of this work, it is important to note that the corpus described thus far was entirely provided by the company and was not generated by the author of this thesis. Conversely, the subsequent processing steps applied to this dataset represent the original contributions of the author.

% TODO: refer to composers 
% TODO: models
% TODO: hyperparams
% TODO: mention that composition is done based on completion file and not file prefix, highlight the difference with evaluation

\subsection{Training}

% TODO: split

\subsection{Evaluation}\label{sec:evaluation}

\section{Composition Impact on Inference}\label{sec:composition-impact-on-inference}

\section{Fine-Tuning on Compositions}\label{sec:fine-tuning-on-compositions}

\section{Effect of Context Extension}\label{sec:effect-of-context-extension}

\section{Influence of Composition on Context Extension}\label{sec:influence-of-composition-on-context-extension}



\section{Limitations and Future Work}
% scale different directions, ...

% TODO: if this section is too small just wrap it as a third paragraph of the conclusion
