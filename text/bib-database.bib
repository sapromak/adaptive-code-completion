% TODO: remove unused references

@misc{izadi2024,
  title         = {Language Models for Code Completion: A Practical Evaluation},
  author        = {Maliheh Izadi and Jonathan Katzy and Tim van Dam and Marc Otten and Razvan Mihai Popescu and Arie van Deursen},
  year          = {2024},
  eprint        = {2402.16197},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE},
  url           = {https://arxiv.org/abs/2402.16197}
}

@inproceedings{izadi2022,
  series     = {ICSE ’22},
  title      = {CodeFill: multi-token code completion by jointly learning from structure and naming sequences},
  url        = {http://dx.doi.org/10.1145/3510003.3510172},
  doi        = {10.1145/3510003.3510172},
  booktitle  = {Proceedings of the 44th International Conference on Software Engineering},
  publisher  = {ACM},
  author     = {Izadi, Maliheh and Gismondi, Roberta and Gousios, Georgios},
  year       = {2022},
  month      = may,
  collection = {ICSE ’22}
}

@misc{lu2021,
  title         = {CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation},
  author        = {Shuai Lu and Daya Guo and Shuo Ren and Junjie Huang and Alexey Svyatkovskiy and Ambrosio Blanco and Colin Clement and Dawn Drain and Daxin Jiang and Duyu Tang and Ge Li and Lidong Zhou and Linjun Shou and Long Zhou and Michele Tufano and Ming Gong and Ming Zhou and Nan Duan and Neel Sundaresan and Shao Kun Deng and Shengyu Fu and Shujie Liu},
  year          = {2021},
  eprint        = {2102.04664},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE},
  url           = {https://arxiv.org/abs/2102.04664}
}

@article{ciniselli2021,
  title     = {An Empirical Study on the Usage of Transformer Models for Code Completion},
  issn      = {2326-3881},
  url       = {http://dx.doi.org/10.1109/TSE.2021.3128234},
  doi       = {10.1109/tse.2021.3128234},
  journal   = {IEEE Transactions on Software Engineering},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  author    = {Ciniselli, Matteo and Cooper, Nathan and Pascarella, Luca and Mastropaolo, Antonio and Aghajani, Emad and Poshyvanyk, Denys and Di Penta, Massimiliano and Bavota, Gabriele},
  year      = {2021},
  pages     = {1–1}
}

@misc{wang2021,
  title         = {Code Completion by Modeling Flattened Abstract Syntax Trees as Graphs},
  author        = {Yanlin Wang and Hui Li},
  year          = {2021},
  eprint        = {2103.09499},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE},
  url           = {https://arxiv.org/abs/2103.09499}
}

@article{husein2025,
  title    = {Large language models for code completion: A systematic literature review},
  journal  = {Computer Standards & Interfaces},
  volume   = {92},
  pages    = {103917},
  year     = {2025},
  issn     = {0920-5489},
  doi      = {https://doi.org/10.1016/j.csi.2024.103917},
  url      = {https://www.sciencedirect.com/science/article/pii/S0920548924000862},
  author   = {Rasha Ahmad Husein and Hala Aburajouh and Cagatay Catal},
  keywords = {Code completion, Large language models, Deep learning, Transformers},
  abstract = {Code completion serves as a fundamental aspect of modern software development, improving developers' coding processes. Integrating code completion tools into an Integrated Development Environment (IDE) or code editor enhances the coding process and boosts productivity by reducing errors and speeding up code writing while reducing cognitive load. This is achieved by predicting subsequent tokens, such as keywords, variable names, types, function names, operators, and more. Different techniques can achieve code completion, and recent research has focused on Deep Learning methods, particularly Large Language Models (LLMs) utilizing Transformer algorithms. While several research papers have focused on the use of LLMs for code completion, these studies are fragmented, and there is no systematic overview of the use of LLMs for code completion. Therefore, we aimed to perform a Systematic Literature Review (SLR) study to investigate how LLMs have been applied for code completion so far. We have formulated several research questions to address how LLMs have been integrated for code completion-related tasks and to assess the efficacy of these LLMs in the context of code completion. To achieve this, we retrieved 244 papers from scientific databases using auto-search and specific keywords, finally selecting 23 primary studies based on an SLR methodology for in-depth analysis. This SLR study categorizes the granularity levels of code completion achieved by utilizing LLMs in IDEs, explores the existing issues in current code completion systems, how LLMs address these challenges, and the pre-training and fine-tuning methods employed. Additionally, this study identifies open research problems and outlines future research directions. Our analysis reveals that LLMs significantly enhance code completion performance across several programming languages and contexts, and their capability to predict relevant code snippets based on context and partial input boosts developer productivity substantially.}
}

@inproceedings{hindle2012,
  author    = {Hindle, Abram and Barr, Earl T. and Su, Zhendong and Gabel, Mark and Devanbu, Premkumar},
  title     = {On the naturalness of software},
  year      = {2012},
  isbn      = {9781467310673},
  publisher = {IEEE Press},
  abstract  = {Natural languages like English are rich, complex, and powerful. The highly creative and graceful use of languages like English and Tamil, by masters like Shakespeare and Avvaiyar, can certainly delight and inspire. But in practice, given cognitive constraints and the exigencies of daily life, most human utterances are far simpler and much more repetitive and predictable. In fact, these utterances can be very usefully modeled using modern statistical methods. This fact has led to the phenomenal success of statistical approaches to speech recognition, natural language translation, question-answering, and text mining and comprehension. We begin with the conjecture that most software is also natural, in the sense that it is created by humans at work, with all the attendant constraints and limitations---and thus, like natural language, it is also likely to be repetitive and predictable. We then proceed to ask whether a) code can be usefully modeled by statistical language models and b) such models can be leveraged to support software engineers. Using the widely adopted n-gram model, we provide empirical evidence supportive of a positive answer to both these questions. We show that code is also very repetitive, and in fact even more so than natural languages. As an example use of the model, we have developed a simple code completion engine for Java that, despite its simplicity, already improves Eclipse's completion capability. We conclude the paper by laying out a vision for future research in this area.},
  booktitle = {Proceedings of the 34th International Conference on Software Engineering},
  pages     = {837–847},
  numpages  = {11},
  location  = {Zurich, Switzerland},
  series    = {ICSE '12}
}

@misc{bhoopchand2016,
      title={Learning Python Code Suggestion with a Sparse Pointer Network}, 
      author={Avishkar Bhoopchand and Tim Rocktäschel and Earl Barr and Sebastian Riedel},
      year={2016},
      eprint={1611.08307},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      url={https://arxiv.org/abs/1611.08307}, 
}

@misc{peng2023,
      title={The Impact of AI on Developer Productivity: Evidence from GitHub Copilot}, 
      author={Sida Peng and Eirini Kalliamvakou and Peter Cihon and Mert Demirer},
      year={2023},
      eprint={2302.06590},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2302.06590}, 
}

@article{weber2024,
  author     = {Weber, Thomas and Brandmaier, Maximilian and Schmidt, Albrecht and Mayer, Sven},
  title      = {Significant Productivity Gains through Programming with Large Language Models},
  year       = {2024},
  issue_date = {June 2024},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {8},
  number     = {EICS},
  url        = {https://doi.org/10.1145/3661145},
  doi        = {10.1145/3661145},
  abstract   = {Large language models like GPT and Codex drastically alter many daily tasks, including programming, where they can rapidly generate code from natural language or informal specifications. Thus, they will change what it means to be a programmer and how programmers act during software development. This work explores how AI assistance for code generation impacts productivity. In our user study (N=24), we asked programmers to complete Python programming tasks supported by a) an auto-complete interface using GitHub Copilot, b) a conversational system using GPT-3, and c) traditionally with just the web browser. Aside from significantly increasing productivity metrics, participants displayed distinctive usage patterns and strategies, highlighting that the form of presentation and interaction affects how users engage with these systems. Our findings emphasize the benefits of AI-assisted coding and highlight the different design challenges for these systems.},
  journal    = {Proc. ACM Hum.-Comput. Interact.},
  month      = jun,
  articleno  = {256},
  numpages   = {29},
  keywords   = {github copilot, gpt, language models, programming, software development, user study}
}

@misc{bakal2025,
      title={Experience with GitHub Copilot for Developer Productivity at Zoominfo}, 
      author={Gal Bakal and Ali Dasdan and Yaniv Katz and Michael Kaufman and Guy Levin},
      year={2025},
      eprint={2501.13282},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2501.13282}, 
}

@misc{takerngsaksiri2024,
      title={Students' Perspective on AI Code Completion: Benefits and Challenges}, 
      author={Wannita Takerngsaksiri and Cleshan Warusavitarne and Christian Yaacoub and Matthew Hee Keng Hou and Chakkrit Tantithamthavorn},
      year={2024},
      eprint={2311.00177},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2311.00177}, 
}

@misc{giagnorio2025,
      title={Why Personalizing Deep Learning-Based Code Completion Tools Matters}, 
      author={Alessandro Giagnorio and Alberto Martin-Lopez and Gabriele Bavota},
      year={2025},
      eprint={2503.14201},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2503.14201}, 
}
